{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to My Notes","text":"CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main() {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main() {\n  cout &lt;&lt; \"Hello world!\" &lt;&lt;endl;\n  return 0;\n}\n</code></pre> <p>\ud83d\udd25 \ud83d\ude80</p>"},{"location":"dbms/","title":"Welcome to DBMS","text":"<p>Database Management System is a software or technology used to manage data from a database. Some popular databases are MySQL, Oracle, MongoDB, etc. DBMS provides many operations e.g. creating a database, Storing in the database, updating an existing database, delete from the database.</p> <p></p>"},{"location":"dbms/introduction/","title":"Introduction to DBMS","text":""},{"location":"dbms/introduction/#what-is-data","title":"What is Data?","text":"<p>Data is a collection of raw, unorganized facts and details like text, observations, figures, symbols, and descriptions of things etc.</p> <p>Data can be recorded and doesn\u2019t have any meaning unless processed.</p>"},{"location":"dbms/introduction/#types-of-data","title":"Types of Data","text":"<p>There are two types of Data:-</p> <ol> <li>Quantitative: Quantitative data refers to numerical information like weight, height, etc.</li> <li>Qualitative: Qualitative data refers to non-numeric information like opinions, perceptions, etc.</li> </ol>"},{"location":"dbms/introduction/#what-is-information","title":"What is Information?","text":"<p>Information is defined as structured, organized, and processed data, presented within a context that makes it relevant and useful to the person who needs it.</p>"},{"location":"dbms/introduction/#data-vs-information","title":"Data vs Information","text":"<ul> <li> <p>Data is a collection of facts, while information puts those facts into context.</p> </li> <li> <p>While data is raw and unorganized, information is organized.</p> </li> <li> <p>Data points are individual and sometimes unrelated. Information maps out that data to provide a big-picture view of how it all fits together.</p> </li> <li> <p>Data, on its own, is meaningless. When it\u2019s analyzed and interpreted, it becomes meaningful information.</p> </li> <li> <p>Data does not depend on information; however, information depends on data.</p> </li> <li> <p>Data isn\u2019t sufficient for decision-making, but you can make decisions based on information.</p> </li> </ul>"},{"location":"dbms/introduction/#what-is-a-database","title":"What is a Database?","text":"<p>Database is an electronic place/system where data is stored in a way that it can be easily accessed, managed, and updated.</p>"},{"location":"dbms/introduction/#what-is-dbms","title":"What is DBMS?","text":"<p>A database management system (DBMS) is a software system for creating and managing databases. A DBMS enables end users to create, protect, read, update and delete data in a database.</p> <p></p>"},{"location":"dbms/introduction/#dbms-vs-file-systems","title":"DBMS vs File Systems","text":""},{"location":"dbms/cap_theorem/","title":"Cap Theorem","text":""},{"location":"dbms/cap_theorem/#contents","title":"Contents","text":""},{"location":"dbms/cap_theorem/introduction/","title":"CAP Theorem in DBMS","text":"<p>In the world of distributed systems, where data needs to be stored and accessed across multiple servers or nodes, ensuring the system\u2019s reliability, performance, and consistency can be quite challenging. To address these challenges, computer scientist Eric Brewer introduced the CAP theorem, which has become a fundamental concept in the design and operation of distributed systems.</p> <p>The CAP theorem, also known as Brewer\u2019s theorem, was introduced by Eric Brewer in 2000 . The three letters in CAP theorem stands for :-</p> <ul> <li> <p>C :- Consistency</p> </li> <li> <p>A :- Availability</p> </li> <li> <p>P :- Partition Tolerance</p> </li> </ul> <p>The theorem articulates the inherent trade-offs that exist when designing distributed systems.</p> <p></p>"},{"location":"dbms/cap_theorem/theorem/","title":"CAP Theorem","text":""},{"location":"dbms/cap_theorem/theorem/#statement-of-cap-theorem","title":"Statement of CAP theorem","text":"<p>The CAP theorem states that it is not possible to guarantee all three of the desirable properties \u2014 <code>consistency</code>, <code>availability</code>, and <code>partition tolerance</code> at the same time in a distributed system with data replication.</p> <p>To understand it better let\u2019s understand these three letters (C A P) first.</p>"},{"location":"dbms/cap_theorem/theorem/#1-c-consistency","title":"1. C :- Consistency","text":"<p>In a distributed system, consistency means that all nodes or replicas in the system have the same data at the same time. When a client reads data, it receives the most recent write or an error. In other words, there is no divergence in the data observed by different nodes.</p> <p>Suppose we are working on a distributed system having client node and two database nodes say d1 and d2 . Now let\u2019s say we have generated an update request to d1 and at the same time we have generated a read request at d2 . So here due to replication of data between d1 and d2 we are able to access latest data . This is called consistency.</p> <p></p>"},{"location":"dbms/cap_theorem/theorem/#2-a-availability","title":"2. A :- Availability","text":"<p>Availability refers to the system\u2019s ability to respond to client requests, even in the presence of node failures or network partitions. An available system ensures that every request eventually receives a response, though it doesn\u2019t guarantee that the response contains the most recent data.</p> <p>In short availability ensures that the system is always available.</p>"},{"location":"dbms/cap_theorem/theorem/#3-p-partition-tolerance","title":"3. P :- Partition Tolerance","text":"<p>Partition tolerance deals with the system\u2019s ability to continue functioning even when network partitions occur. Network partitions can cause nodes to lose contact with one another, making communication and synchronization difficult.</p> <p>Let\u2019s consider above example to understand it better.</p> <p>Suppose somehow the connection between d1 and d2 breaks down now the replication of data will not occur hence consistency is not maintained but still both systems are generating output. This is partition tolerance. So even after connection breakdown the output is being generated by systems is partition tolerance.</p> <p></p> <p>CAP theorem says that we cannot have all three properties i.e. C A P at same time we can have at most two at once. So let\u2019s understand this.</p> <p>All possible combinations of consistency , availability and partition tolerance are :-</p> <ol> <li>CA (consistency + availability)</li> <li>AP (availability + partition tolerance)</li> <li>CP (consistency + partition tolerance)</li> </ol> <p>Now,</p>"},{"location":"dbms/cap_theorem/theorem/#1-ca-consistency-availability","title":"1. CA (consistency + availability)","text":"<p>Here complete system is consistent and is always available. If we break the connection between systems in order to make it partition tolerant we will lose consistency of system.</p>"},{"location":"dbms/cap_theorem/theorem/#2-ap-availability-partition-tolerance","title":"2. AP (availability + partition tolerance)","text":"<p>After breaking the connection between d1 and d2 our system becomes partition tolerant and is always available but consistency is not maintained.</p>"},{"location":"dbms/cap_theorem/theorem/#3-cp-consistency-partition-tolerance","title":"3. CP (consistency + partition tolerance)","text":"<p>To make above system consistent and partition tolerant we have to down the system in order to establish the connection between d1 and d2 again this will make our system unavailable for a while and after the connection has been established the system will not be partition tolerant.</p> <p></p>"},{"location":"dbms/cap_theorem/theorem/#why-is-the-cap-theorem-important","title":"Why is the CAP theorem important?","text":"<p>The CAP theorem is important because it forces developers to think carefully about the trade-offs they\u2019re making when building a distributed system. When designing a distributed system, you have to decide which two properties are most important for your use case.</p> <p>For example, if you\u2019re building a banking application, consistency is likely to be the most important property because you can\u2019t afford to have different account balances for different users. On the other hand, if you\u2019re building a social media application, availability is likely to be the most important property because users will expect the application to be up and running all the time.</p>"},{"location":"dbms/cap_theorem/theorem/#real-world-examples","title":"Real-World Examples","text":"<p>Let\u2019s look at a couple of real-world examples to illustrate the CAP theorem in action :-</p> <ul> <li> <p>Amazon DynamoDB :- DynamoDB is designed to provide high availability and partition tolerance. It replicates data across multiple Availability Zones (AZs) to ensure data durability and availability. However, during network partitions, it might not provide strong consistency by default.</p> </li> <li> <p>Google Spanner :- Google\u2019s Spanner database is an example of a CP system. It achieves strong consistency by using synchronized clocks and a globally distributed architecture. However, this comes at the cost of potential unavailability in the event of network partitions.</p> </li> </ul>"},{"location":"dbms/cap_theorem/theorem/#different-databases-bcoz-of-cap-theorem","title":"Different databases bcoz of CAP theorem","text":"<ul> <li>NoSQL databases are great for distributed networks. They allow for horizontal scaling, and they can quickly scale across multiple nodes. When deciding which NoSQL database to use, it\u2019s important to keep the CAP theorem in mind.</li> </ul>"},{"location":"dbms/cap_theorem/theorem/#so-rdbms-is-not-used-at-all-in-large-scale-systems","title":"So, RDBMS is not used at all in large-scale systems?","text":"<ul> <li> <p>Obviously, this is false statement. They are very old and mature DBs and been in the industry for years.</p> </li> <li> <p>Despite the CAP theorem's constraints, MySQL and PostgreSQL are indeed used at a very large scale in the real world. Here are some strategies employed.</p> </li> </ul> <p>Hybrid Approaches</p> <p>Read replicas: Using read replicas to handle high read traffic, while the primary node handles writes. This can improve availability and distribute the load but might introduce eventual consistency for reads. Multi-master replication: Allows writes on multiple nodes but comes with complex conflict resolution mechanisms to maintain consistency.</p> <p>Use Cases</p> <ul> <li> <p>Financial Systems: Often use CP configurations with strong consistency guarantees, such as synchronous replication. For example, a payment processing system might use PostgreSQL with synchronous replication to ensure that all transactions are consistent.</p> </li> <li> <p>Web Applications: Often use AP configurations with asynchronous replication to ensure high availability. For example, a social media platform might use MySQL with asynchronous replication and read replicas to handle high traffic volumes.</p> </li> </ul>"},{"location":"dbms/dbms_architecture/","title":"DBMS Architecture","text":""},{"location":"dbms/dbms_architecture/#contents","title":"Contents","text":""},{"location":"dbms/dbms_architecture/introduction/","title":"Introduction to DBMS Architecture","text":"<p>Database management systems are divided into multiple levels of abstraction for proper functioning. These modules/layers describe the functioning and the design of the DBMS.</p> <p>Since a database management system is not always directly accessible by the user or an application, we can maintain it with the help of various architectures based on how the user is connected to the database. These architectures follow a tier-based classification, i.e., the DBMS architecture is classified depending upon how many layers are present in the structure of the DBMS.</p> <p>Hence, an n-tier DBMS Architecture divides the whole DBMS into related but n independent layers or levels, i.e., a one-tier architecture divides the DBMS into a single layer, a two-tier DBMS architecture divides the DBMS into two layers, a three-tier in three layers, and so on.</p> <p>Now, let\u2019s look at the most common DBMS architectures:</p> <ul> <li> <p>Single Tier Architecture (One-Tier Architecture)</p> </li> <li> <p>Two-Tier Architecture</p> </li> <li> <p>Three-Tier Architecture</p> </li> </ul> <p></p>"},{"location":"dbms/dbms_architecture/three_level_architecture/","title":"Three Level Architecture","text":""},{"location":"dbms/dbms_architecture/three_level_architecture/#three-level-architecture_1","title":"Three Level Architecture","text":"<p>Three Level Architecture is a commonly used architectural approach in Database Management Systems (DBMS) for the design and development of applications that work with databases. The 3-level architecture divides an application\u2019s components into three layers. Each layer has its own set of responsibilities.</p> <p>DBMS 3-Level architecture divides the complete system into three inter-related but independent modules as shown below:</p> <p></p>"},{"location":"dbms/dbms_architecture/three_level_architecture/#physical-level","title":"Physical Level","text":"<p>This is the lowest level in the three level architecture.It is also known as the internal level. The physical level describes how data is actually stored in the database. In the lowest level, this data is stored in the external hard drives in the form of bits and at a little high level, it can be said that the data is stored in files and folders. The physical level also discusses compression and encryption techniques.</p>"},{"location":"dbms/dbms_architecture/three_level_architecture/#conceptual-level","title":"Conceptual Level","text":"<p>The conceptual level is also known as the logical level. It describes how the database appears to the users conceptually and the relationships between various data tables. The whole design of the database such as relationship among data, schema of data etc. are described in this level. Database constraints and security are also implemented in this level of architecture. This level is maintained by DBA (database administrator).</p>"},{"location":"dbms/dbms_architecture/three_level_architecture/#external-level","title":"External Level","text":"<p>This is the highest level in the three level architecture and closest to the user. It is also known as the view level. The external level only shows the relevant database content to the users in the form of views and hides the rest of the data. So different users can see the database as a different view as per their individual requirements.</p>"},{"location":"dbms/dbms_architecture/types_of_architecture/One_Tier_Architecture/","title":"One_Tier_Architecture","text":""},{"location":"dbms/dbms_architecture/types_of_architecture/One_Tier_Architecture/#single-tier-architecture","title":"Single Tier Architecture","text":"<ul> <li> <p>In this architecture, the database is directly available to the user. It means the user can directly sit on the DBMS and uses it.</p> </li> <li> <p>Any changes done here will directly be done on the database itself. It doesn't provide a handy tool for end users.</p> </li> <li> <p>The 1-Tier architecture is used for development of the local application, where programmers can directly communicate with the database for the quick response.</p> </li> </ul> <p></p>"},{"location":"dbms/dbms_architecture/types_of_architecture/One_Tier_Architecture/#when-single-tier-architecture-used","title":"When Single Tier Architecture Used?","text":"<ul> <li> <p>The data isn't changed frequently.</p> </li> <li> <p>No multiple users are accessing the database system.</p> </li> <li> <p>We need a direct and simple way to modify or access the database for application development.</p> </li> </ul>"},{"location":"dbms/dbms_architecture/types_of_architecture/One_Tier_Architecture/#example","title":"Example","text":"<p>In order to learn the Structure Query Language (SQL), we set up our SQL server and the database on our local system. This SQL server enables us to directly interact with the relational database and execute certain operations without requiring any network connection. This whole setup to learn SQL queries is an example of Single-Tier DBMS architecture.</p>"},{"location":"dbms/dbms_architecture/types_of_architecture/One_Tier_Architecture/#highlights","title":"Highlights","text":"<ol> <li> <p>Simplest DBMS architecture.</p> </li> <li> <p>All the components of DBMS, i.e., the server, database, and client, reside on a single system.</p> </li> <li> <p>The user can directly access the database.</p> </li> <li> <p>Used when data isn't changing frequently.</p> </li> <li> <p>Suitable for programmers, database designers, and single-user access.</p> </li> </ol>"},{"location":"dbms/dbms_architecture/types_of_architecture/Three_Tier_Architecture/","title":"Three_Tier_Architecture","text":""},{"location":"dbms/dbms_architecture/types_of_architecture/Three_Tier_Architecture/#three-tier-architecture","title":"Three Tier Architecture","text":"<ul> <li> <p>The 3-Tier architecture contains another layer between the client and server. In this architecture, the client can't directly communicate with the server.</p> </li> <li> <p>The application on the client end interacts with an application server which further communicates with the database system.</p> </li> <li> <p>The end-user has no idea about the existence of the database beyond the application server. The database also has no idea about any other user beyond the application. The 3-Tier architecture is used in the case of the large web application.</p> </li> </ul> <p></p>"},{"location":"dbms/dbms_architecture/types_of_architecture/Three_Tier_Architecture/#advantages-of-three-tier-architecture","title":"Advantages of Three Tier Architecture","text":"<ul> <li> <p>Scalability - Since the database server isn't aware of any users beyond the application layer and the application layer implements load balancing, there can be as many clients as you want.</p> </li> <li> <p>Data Integrity - Data corruption and bad requests can be avoided because of the checks performed in the application layer on each client reques.</p> </li> <li> <p>Security - The removal of the direct connection between the client and server systems via abstraction reduces unauthorized access to the database.</p> </li> </ul> <p>Note - In Three Tier DBMS Architecture, an additional layer (Application Layer) is added between the Client and the Server. This increases the number of layers present between the DBMS and the end-users, making the implementation of the DBMS structure complex and difficult to maintain.</p>"},{"location":"dbms/dbms_architecture/types_of_architecture/Three_Tier_Architecture/#highlights","title":"Highlights","text":"<ol> <li> <p>Most widely used DBMS architecture.</p> </li> <li> <p>Follows Client-Application-Server architecture.</p> </li> <li> <p>Enhanced security, data integrity, and scalability.</p> </li> <li> <p>Has complexity and maintenance issues because of the extra layer.</p> </li> </ol>"},{"location":"dbms/dbms_architecture/types_of_architecture/Two_Tier_Architecture/","title":"Two_Tier_Architecture","text":""},{"location":"dbms/dbms_architecture/types_of_architecture/Two_Tier_Architecture/#two-tier-architecture","title":"Two Tier Architecture","text":"<ul> <li> <p>The 2-Tier architecture is the same as the basic client-server. In the two-tier architecture, applications on the client end can directly communicate with the database on the server side. For this interaction, APIs like ODBC, and JDBC are used.</p> </li> <li> <p>The user interfaces and application programs are run on the client side.</p> </li> <li> <p>The server side is responsible to provide the functionalities like query processing and transaction management. To communicate with the DBMS, the client-side application establishes a connection with the server side.</p> </li> </ul> <p></p>"},{"location":"dbms/dbms_architecture/types_of_architecture/Two_Tier_Architecture/#advantages-of-two-tier-architecture","title":"Advantages of Two Tier Architecture","text":"<ul> <li> <p>Multiple users can use it at the same time. Hence, it can be used in an organization.</p> </li> <li> <p>It has high processing ability as the database functionality is handled by the server alone.</p> </li> <li> <p>Faster access to the database due to the direct connection and improved performance.</p> </li> <li> <p>Because of the two independent layers, it's easier to maintain.</p> </li> </ul>"},{"location":"dbms/dbms_architecture/types_of_architecture/Two_Tier_Architecture/#disadvantages-of-two-tier-dbms-architecture","title":"Disadvantages of Two-Tier DBMS Architecture","text":"<ol> <li> <p>Scalability - As the number of clients increases, the load on the server increases. Thereby declining the performance of the DBMS and, in turn, the client-side application.</p> </li> <li> <p>Security - The Direct connection between the client and server systems makes this architecture vulnerable to attacks.</p> </li> </ol>"},{"location":"dbms/dbms_architecture/types_of_architecture/Two_Tier_Architecture/#example","title":"Example","text":"<p>Consider a situation where you went to a bank to withdraw some cash. After entering the withdrawal amount and the account details on the withdrawal slip, the banker will go through the server-side database via his credential (API call) and will check whether there is enough balance present or not. This client-server model is an example of Two-Tier DBMS architecture.</p>"},{"location":"dbms/dbms_architecture/types_of_architecture/Two_Tier_Architecture/#highlights","title":"Highlights","text":"<ol> <li> <p>Similar to a client-server architecture.</p> </li> <li> <p>Faster access, Easier to maintain, and can handle multiple users simultaneously.</p> </li> <li> <p>Used when we wish to access DBMS via applications and APIs.</p> </li> <li> <p>Has scalability and security issues because of direct client-server connection.</p> </li> </ol>"},{"location":"dbms/entity_relationship/","title":"Entity Relationship Model","text":""},{"location":"dbms/entity_relationship/#contents","title":"Contents","text":""},{"location":"dbms/entity_relationship/eer_model/","title":"Extended ER Model (OR EER model)","text":""},{"location":"dbms/entity_relationship/eer_model/#why-eer-model","title":"Why EER model?","text":"<p>Using the ER model for bigger data creates a lot of complexity while designing a database model, So in order to minimize the complexity, we have to enhanced entity-relationship model.</p> <p>All the components of an ER diagram are included in an EER diagram, with the following additions that help us create and maintain detailed databases through high-level models and tools.</p> <ul> <li>Specialization</li> <li>Generalization</li> <li>Aggregation</li> </ul> <p>The below diagram is a representation of an Enhanced Entity-relationship model. As you can see, the below EER model is expanded upon ER models.</p> <p></p>"},{"location":"dbms/entity_relationship/eer_model/#sub-class-and-super-class","title":"Sub Class and Super Class","text":"<p>The link between subclasses and superclasses introduces the idea of inheritance. The 'd' symbol is used to indicate the relationship between subclasses and superclasses.</p> <p>Super Class</p> <p>A superclass is a type of entity that is connected to one or more subtypes. And, also note that a database entity cannot be created just by belonging to a superclass.</p> <p>For example: The superclass of shapes includes subgroups like Triangle, Circles, and Squares.</p> <p>Sub Class</p> <p>A subclass is a collection of objects with special characteristics. The traits and properties of a subclass are inherited from its superclass.</p> <p>For example: Triangles, Circles, and squares are the subclass of the Shape superclass.</p> <p></p>"},{"location":"dbms/entity_relationship/eer_model/#specialization","title":"Specialization","text":"<p>Specialization in the ER model is like categorizing entities based on common features.</p> <ul> <li> <p>A \"Supertype\" groups entities with shared attributes and relationships, while \"Subtypes\" have their own unique attributes and relationships. It's a way to organize data efficiently. It is a Top-Down approach.</p> </li> <li> <p>We have is-a relationship between superclass and subclass. </p> </li> </ul> <p></p>"},{"location":"dbms/entity_relationship/eer_model/#generalization","title":"Generalization","text":"<p>Generalization is like finding things that are alike and putting them into a big group to represent what they have in common. It helps make things simpler and organized. It is a Bottom-Up approach.</p> <ul> <li>We have is-a relationship between subclass and superclass. </li> </ul> <p></p> <p>Inheritance :- It is an important feature of generalization and specialization.</p> <ul> <li> <p>Attribute inheritance: allows lower level entities to inherit the attributes of higher level entities and vice versa.</p> </li> <li> <p>in diagram: Car entity is an inheritance of Vehicle entity ,So Car can acquire attributes of Vehicle example:car can acquire Model attribute of Vehicle.</p> </li> <li> <p>Participation inheritance: In participation inheritance, relationships involving higher level entity set also inherited by lower level entity and vice versa.</p> </li> <li> <p>in diagram: Vehicle entity has an relationship with Cycle entity ,So Cycle entity can acquire attributes of lower level entities i.e Car and Bus since it is inheritance of Vehicle.</p> </li> </ul> <p></p>"},{"location":"dbms/entity_relationship/eer_model/#aggregation","title":"Aggregation","text":"<p>Aggregation is like stacking things on top of each other to create a structure. It is used to create a hierarchical structure in data modeling, showing how a higher-level entity is composed of lower-level entities.</p> <ul> <li>Abstraction is employed to view relationships from a more general perspective, focusing on a higher-level entity.</li> </ul> <p></p>"},{"location":"dbms/entity_relationship/er_to_relational/","title":"ER Model to Relational Model","text":""},{"location":"dbms/entity_relationship/introduction/","title":"Introduction to ER Model","text":""},{"location":"dbms/entity_relationship/introduction/#what-is-er-model","title":"What is ER Model?","text":"<p>The Entity Relationship Diagram explains the relationship among the entities present in the database. ER models are used to model real-world objects like a person, a car, or a company and the relation between these real-world objects. In short, the ER Diagram is the structural format of the database.</p>"},{"location":"dbms/entity_relationship/introduction/#why-use-er-diagrams-in-dbms","title":"Why Use ER Diagrams In DBMS?","text":"<ul> <li> <p>ER diagrams are used to represent the E-R model in a database, which makes them easy to convert into relations (tables).</p> </li> <li> <p>These diagrams are very easy to understand and easy to create even for a naive user.</p> </li> <li> <p>It gives a standard solution for visualizing the data logically.</p> </li> </ul>"},{"location":"dbms/entity_relationship/introduction/#symbols-used-in-er-model","title":"Symbols Used in ER Model","text":""},{"location":"dbms/entity_relationship/introduction/#components-of-er-diagram","title":"Components of ER Diagram","text":"<p>ER Model consists of Entities, Attributes, and Relationships among Entities in a Database System.</p> <p></p>"},{"location":"dbms/entity_relationship/introduction/#entity","title":"Entity","text":"<p>An Entity may be an object with a physical existence \u2013 a particular person, car, house, or employee \u2013 or it may be an object with a conceptual existence \u2013 a company, a job, or a university course.</p>"},{"location":"dbms/entity_relationship/introduction/#entity-type","title":"Entity Type","text":"<p>It refers to the category that a particular entity belongs to.</p> <p></p> <p>Example</p> <ul> <li>A table named student in a university database.</li> <li>A table named employee in a company database.</li> </ul>"},{"location":"dbms/entity_relationship/introduction/#entity-set","title":"Entity Set","text":"<p>An entity set is a collection or set of all entities of a particular entity type at any point in time. The type of all the entities should be the same.</p> <p></p> <p>Example</p> <ul> <li>The collection of all the students from the student table at a particular instant of time is an example of an entity set.</li> </ul> <ol> <li>Strong Entity</li> </ol> <p>A Strong Entity is a type of entity that has a key Attribute. Strong Entity does not depend on other Entity in the Schema. It has a primary key, that helps in identifying it uniquely, and it is represented by a rectangle. These are called Strong Entity Types.</p> <ol> <li>Weak Entity</li> </ol> <p>An entity that cannot be uniquely identified by its own attributes and relies on the relationship with other entity is called weak entity. it is represented by a double rectangle.</p>"},{"location":"dbms/entity_relationship/introduction/#attributes","title":"Attributes","text":"<p>An entity is represented by a set of attributes, each entity has a value for each of its attributes.</p> <p>Example Student Entity has following attributes \u2192 <code>Student_ID, Name, Course, Batch, Contact number</code></p>"},{"location":"dbms/entity_relationship/introduction/#types-of-attributes","title":"Types of Attributes","text":"<ol> <li>Simple Attribute</li> </ol> <p>Attributes which can\u2019t be divided further.</p> <p>E.g.\u2192 <code>Customer\u2019s account number in a bank, Student\u2019s Roll number etc.</code></p> <ol> <li>Composite Attribute</li> </ol> <p>An attribute composed of many other attributes is called a composite attribute.</p> <p>E.g. \u2192 <code>Name of a person, can be divided into first-name, middle-name, last-name.</code></p> <ol> <li>Single-valued Attribute</li> </ol> <p>Only one value attribute.</p> <p>E.g. \u2192 <code>Student ID, loan-number for a loan.</code></p> <ol> <li>Multi-valued Attribute</li> </ol> <p>An attribute consisting of more than one value for a given entity.</p> <p>E.g. \u2192 <code>Phone_No (can be more than one for a given student).</code></p> <ol> <li>Derived Attribute</li> </ol> <p>An attribute that can be derived from other attributes is known as a derived attribute.</p> <p>E.g. \u2192 <code>Age (can be derived from DOB).</code></p> <ol> <li>NULL Value Attribute</li> </ol> <p>An attribute takes a null value when an entity does not have a value for it.</p> <p>E.g. \u2192 <code>person having no middle-name</code></p>"},{"location":"dbms/entity_relationship/relational_model/","title":"Relational Model","text":""},{"location":"dbms/entity_relationship/relational_model/#what-is-relational-model","title":"What is Relational Model?","text":"<p>The relational model represents how data is stored in Relational Databases. A relational database consists of a collection of tables, each of which is assigned a unique name. Consider a relation STUDENT with attributes ROLL_NO, NAME, ADDRESS, PHONE, and AGE shown in the table.</p> <ul> <li>Relational Model based DBMS systems, also known as RDBMS :- Oracle, IBM, MySQL.</li> </ul> <p></p>"},{"location":"dbms/entity_relationship/relational_model/#important-terminologies","title":"Important Terminologies","text":"<ul> <li> <p>Attribute: Each column in the relation is known as a attribute. Attributes are the properties that define an entity. e.g.; ROLL_NO, NAME, ADDRESS</p> </li> <li> <p>Tuple: Each row in the relation/table is known as a tuple.</p> </li> <li> <p>Degree: The number of attributes in the relation is known as the degree of the relation.The STUDENT relation defined above has degree 5.</p> </li> <li> <p>Cardinality: The number of tuples in a relation is known as cardinality. The STUDENT relation defined above has cardinality 4.</p> </li> <li> <p>Relation Schema: A relation schema defines the structure of the relation and represents the name of the relation with its attributes. e.g.; STUDENT (ROLL_NO, NAME, ADDRESS, PHONE, and AGE) is the relation schema for STUDENT.</p> </li> <li> <p>NULL Values: The value which is not known or unavailable is called a NULL value. It is represented by blank space. e.g.; PHONE of STUDENT having ROLL_NO 4 is NULL.</p> </li> <li> <p>Relation Key: These are basically the keys that are used to identify the rows uniquely or also help in identifying tables. e.g.; Primary Key, Candidate Key, Super Key, Foreign Key</p> </li> </ul>"},{"location":"dbms/entity_relationship/relational_model/#constraints-in-relational-model","title":"Constraints in Relational Model","text":"<p>While designing the Relational Model, we define some conditions which must hold for data present in the database are called Constraints. These constraints are checked before performing any operation (insertion, deletion, and updation ) in the database. If there is a violation of any of the constraints, the operation will fail.</p>"},{"location":"dbms/entity_relationship/relational_model/#domain-constraints","title":"Domain Constraints","text":"<p>These are attribute-level constraints. An attribute can only take values that lie inside the domain range. e.g.; If a constraint AGE&gt;0 is applied to STUDENT relation, inserting a negative value of AGE will result in failure.</p>"},{"location":"dbms/entity_relationship/relational_model/#key-integrity","title":"Key Integrity","text":"<p>Every relation in the database should have at least one set of attributes that defines a tuple uniquely. Those set of attributes is called keys. e.g.; ROLL_NO in STUDENT is key. No two students can have the same roll number. So a key has two properties: </p> <ul> <li>It should be unique for all tuples.</li> <li>It can\u2019t have NULL values.</li> </ul>"},{"location":"dbms/entity_relationship/relational_model/#referential-integrity","title":"Referential Integrity","text":"<p>When one attribute of a relation can only take values from another attribute of the same relation or any other relation, it is called referential integrity. Let us suppose we have 2 relations </p> <p></p> <p></p> <p>BRANCH_CODE of STUDENT can only take the values which are present in BRANCH_CODE of BRANCH which is called referential integrity constraint. The relation which is referencing another relation is called REFERENCING RELATION (STUDENT in this case) and the relation to which other relations refer is called REFERENCED RELATION (BRANCH in this case).</p>"},{"location":"dbms/entity_relationship/relational_model/#anomalies-in-the-relational-model","title":"Anomalies in the Relational Model","text":"<p>An anomaly is an irregularity or something which deviates from the expected or normal state. When designing databases, we identify three types of anomalies: Insert, Update, and Delete.</p>"},{"location":"dbms/entity_relationship/relational_model/#insertion-anomaly-in-referencing-relation","title":"Insertion Anomaly in Referencing Relation","text":"<p>We can\u2019t insert a row in REFERENCING RELATION if referencing attribute\u2019s value is not present in the referenced attribute value. e.g.; Insertion of a student with BRANCH_CODE \u2018ME\u2019 in STUDENT relation will result in an error because \u2018ME\u2019 is not present in BRANCH_CODE of BRANCH. </p>"},{"location":"dbms/entity_relationship/relational_model/#deletion-updation-anomaly-in-referenced-relation","title":"Deletion/ Updation Anomaly in Referenced Relation","text":"<p>We can\u2019t delete or update a row from REFERENCED RELATION if the value of REFERENCED ATTRIBUTE is used in the value of REFERENCING ATTRIBUTE. e.g; if we try to delete a tuple from BRANCH having BRANCH_CODE \u2018CS\u2019, it will result in an error because \u2018CS\u2019 is referenced by BRANCH_CODE of STUDENT, but if we try to delete the row from BRANCH with BRANCH_CODE CV, it will be deleted as the value is not been used by referencing relation.</p>"},{"location":"dbms/entity_relationship/relationships/","title":"Relationships","text":""},{"location":"dbms/entity_relationship/relationships/#relationship-type-and-relationship-set","title":"Relationship Type and Relationship Set","text":"<p>A Relationship Type represents the association between entity types. For example, \u2018Enrolled in\u2019 is a relationship type that exists between entity type Student and Course. In ER diagram, the relationship type is represented by a diamond and connecting the entities with lines.</p> <p></p> <p>A set of relationships of the same type is known as a relationship set. The following relationship set depicts S1 as enrolled in C2, S2 as enrolled in C1, and S3 as registered in C3.</p> <p></p>"},{"location":"dbms/entity_relationship/relationships/#degree-of-a-relationship","title":"Degree of a Relationship","text":"<p>The number of different entity sets participating in a relationship set is called the degree of a relationship.</p>"},{"location":"dbms/entity_relationship/relationships/#1-unary-relationship","title":"1. Unary Relationship","text":"<p>When there is only ONE entity set participating in a relation, the relationship is called a unary relationship. For example, one person is married to only one person.</p> <p></p>"},{"location":"dbms/entity_relationship/relationships/#2-binary-relationship","title":"2. Binary Relationship","text":"<p>When there are TWO entities set participating in a relationship, the relationship is called a binary relationship. For example, a Student is enrolled in a Course.</p> <p></p>"},{"location":"dbms/entity_relationship/relationships/#3-ternary-relationship","title":"3. Ternary Relationship","text":"<p>When there are n entities set participating in a relation, the relationship is called an n-ary relationship.</p>"},{"location":"dbms/entity_relationship/relationships/#cardinality","title":"Cardinality","text":"<p>The number of times an entity of an entity set participates in a relationship set is known as cardinality.</p>"},{"location":"dbms/entity_relationship/relationships/#1-one-to-one","title":"1. One-to-One","text":"<p>When each entity in each entity set can take part only once in the relationship, the cardinality is one-to-one.</p> <p>E.g. \u2192 <code>Citizen has Aadhar Card</code></p>"},{"location":"dbms/entity_relationship/relationships/#2-one-to-many","title":"2. One-to-Many","text":"<p>In one-to-many mapping as well where each entity can be related to more than one entity.</p> <p>E.g. \u2192 <code>Citizen has Vehicle</code></p>"},{"location":"dbms/entity_relationship/relationships/#3-many-to-one","title":"3. Many-to-One","text":"<p>When entities in one entity set can take part only once in the relationship set and entities in other entity sets can take part more than once in the relationship set, cardinality is many to one.</p> <p>E.g. \u2192 <code>Course taken by Professor</code></p>"},{"location":"dbms/entity_relationship/relationships/#4-many-to-many","title":"4. Many-to-Many","text":"<p>When entities in all entity sets can take part more than once in the relationship cardinality is many to many.</p> <p>E.g. \u2192 <code>A student can take more than one course and one course can be taken by many students</code></p>"},{"location":"dbms/entity_relationship/relationships/#participation-constraint","title":"Participation Constraint","text":"<p>Participation Constraint is applied to the entity participating in the relationship set.  </p>"},{"location":"dbms/entity_relationship/relationships/#1-total-participation","title":"1. Total Participation","text":"<p>Each entity in the entity set must participate in the relationship. If each student must enroll in a course, the participation of students will be total. Total participation is shown by a double line in the ER diagram.</p>"},{"location":"dbms/entity_relationship/relationships/#2-partial-participation","title":"2. Partial Participation","text":"<p>The entity in the entity set may or may NOT participate in the relationship. If some courses are not enrolled by any of the students, the participation in the course will be partial.</p> <p>The diagram depicts the \u2018Enrolled in\u2019 relationship set with Student Entity set having total participation and Course Entity set having partial participation. </p> <p></p> <p>Using Set, it can be represented as, </p> <p></p>"},{"location":"dbms/indexing/","title":"Indexing in DBMS","text":""},{"location":"dbms/indexing/#contents","title":"Contents","text":""},{"location":"dbms/indexing/introduction/","title":"Introduction to Indexing","text":""},{"location":"dbms/indexing/introduction/#what-is-indexing-in-dbms","title":"What is Indexing in DBMS?","text":"<p>Indexing is used to quickly retrieve particular data from the database. Formally we can define Indexing as a technique that uses data structures to optimize the searching time of a database query in DBMS. Indexing reduces the number of disks required to access a particular data by internally creating an index table.</p> <p>Indexing is achieved by creating Index-table or Index.</p> <p>Index usually consists of two columns which are a key-value pair. The two columns of the index table(i.e., the key-value pair) contain copies of selected columns of the tabular data of the database.</p> <p></p> <p>Here, Search Key contains the copy of the Primary Key or the Candidate Key of the database table. Generally, we store the selected Primary or Candidate keys in a sorted manner so that we can reduce the overall query time or search time(from linear to binary).</p> <p>Data Reference contains a set of pointers that holds the address of the disk block. The pointed disk block contains the actual data referred to by the Search Key. Data Reference is also called Block Pointer because it uses block-based addressing.</p>"},{"location":"dbms/indexing/introduction/#indexing-attributes","title":"Indexing Attributes","text":"<p>Let's discuss the various indexing attributes:</p>"},{"location":"dbms/indexing/introduction/#standard-b-tree-and-bitmap","title":"Standard (B-tree) and Bitmap","text":"<p>B-tree-indexing is one of the most popular and commonly used indexing techniques. B-tree in DBMS is a type of tree data structure that contains 2 things namely: Index Key and its corresponding disk address. Index Key refers to a certain disk address and that disk further contains rows or tuples of data.</p> <p>On the other hand, Bitmap indexing uses strings to store the address of the tuples or rows. A bitmap is a mapping from one system to the other such as integers to bits.</p> <p>Bitmap has an advantage over B-tress as bitmap performs faster retrieval of certain data (Bitmap is made according to a certain data, hence retrieves faster). Bitmaps are also more compact than B-trees.</p> <p>There is a drawback with bit mapping, bit mapping requires more overhead during tuple operations on the table. Hence, bit maps are mainly used in data warehouse environments.</p> <p></p> <p></p>"},{"location":"dbms/indexing/types_of_indexes/","title":"Types of Indexes","text":""},{"location":"dbms/indexing/types_of_indexes/#types-of-indexes_1","title":"Types of Indexes","text":"<p>we divide indexing mainly into three types</p> <p></p>"},{"location":"dbms/indexing/types_of_indexes/#single-level-indexing","title":"Single Level Indexing","text":"<p>It is somewhat like the index (or the table of contents) found in a book. Index of a book contains topic names along with the page number similarly the index table of the database contains keys and their corresponding block address.</p> <p>Single Level Indexing is further divided into three categories:</p> <p>The indexing or the index table created using Primary keys is known as Primary Indexing. It is defined on ordered data. As the index is comprised of primary keys, they are unique, not null, and possess one to one relationship with the data blocks.</p> <p></p> Characteristics of Primary Indexing <ul> <li>Search Keys are unique.</li> <li>Search Keys are in sorted order.</li> <li>Search Keys cannot be null as it points to a block of data.</li> <li>Fast and Efficient Searching.</li> </ul> <ul> <li> </li> </ul> <p>In dense indexing, the index table contains records for every search key value of the database. This makes searching faster but requires a lot more space. It is like primary indexing but contains a record for every search key.</p> <p></p> <ul> <li> </li> </ul> <p>Sparse indexing consumes lesser space than dense indexing, but it is a bit slower as well. We do not include a search key for every record despite that we store a Search key that points to a block. The pointed block further contains a group of data. Sometimes we have to perform double searching this makes sparse indexing a bit slower.</p> <p></p>"},{"location":"dbms/indexing/types_of_indexes/#primary-indexing","title":"Primary Indexing","text":""},{"location":"dbms/indexing/types_of_indexes/#dense-indexing","title":"Dense Indexing","text":""},{"location":"dbms/indexing/types_of_indexes/#sparse-indexing","title":"Sparse Indexing","text":""},{"location":"dbms/indexing/types_of_indexes/#cluster-indexing","title":"Cluster Indexing","text":"<p>Clustered Indexing is used when there are multiple related records found at one place. It is defined on ordered data. The important thing to note here is that the index table of clustered indexing is created using non-key values which may or may not be unique. To achieve faster retrieval, we group columns having similar characteristics. The indexes are created using these groups and this process is known as Clustering Index.</p> <p></p> Characteristics of Clustered Indexing <ul> <li>Search Keys are non-key values.</li> <li>Search Keys are sorted.</li> <li>Search Keys cannot be null.</li> <li>Search Keys may or may not be unique.</li> <li>Requires extra work to create indexing.</li> </ul>"},{"location":"dbms/indexing/types_of_indexes/#secondary-indexing","title":"Secondary Indexing","text":"<p>It is a two-level indexing technique used to reduce the mapping size of the primary index. The secondary index points to a certain location where the data is to be found but the actual data is not sorted like in the primary indexing. Secondary Indexing is also known as non-clustered Indexing.</p> <p></p> Characteristics of Secondary Indexing <ul> <li>Search Keys are Candidate Keys.</li> <li>Search Keys are sorted but actual data may or may not be sorted.</li> <li>Requires more time than primary indexing.</li> <li>Search Keys cannot be null.</li> <li>Faster than clustered indexing but slower than primary indexing.</li> </ul>"},{"location":"dbms/indexing/types_of_indexes/#advantages-of-indexing","title":"Advantages of Indexing","text":"<ul> <li>Faster access and retrieval of data.</li> <li>IO is less.</li> </ul>"},{"location":"dbms/indexing/types_of_indexes/#limitations-of-indexing","title":"Limitations of Indexing","text":"<ul> <li>Additional space to store index table</li> <li>Indexing Decrease performance in INSERT, DELETE, and UPDATE query.</li> </ul>"},{"location":"dbms/indexing/types_of_indexes/#faqs-on-indexing-in-dbms","title":"FAQs on Indexing in DBMS","text":"Q1. What is Indexing in DBMS? <p>Indexing in DBMS is a technique that uses data structures to optimize the searching time of a database query. It helps in faster query results and quick data retrieval from the database. Indexing makes database performance better. It also consumes lesser space in the main memory.</p> Q2. Is indexing similar to hashing? <p>Indexing:</p> <ul> <li> <p>Purpose: Indexing is used to speed up the retrieval of data from a database or data structure, typically by creating a smaller, more efficient reference system to access the data.</p> </li> <li> <p>Method: An index is usually a sorted list of keys (or other identifiers) that allows for faster searching using algorithms like binary search. For example, database indexes use B-trees or other structures to optimize search operations.</p> </li> <li> <p>Search Time: Typically reduces search time from \ud835\udc42(\ud835\udc5b) to \ud835\udc42(log \ud835\udc5b) when using binary search or similar methods.</p> </li> <li> <p>Use Case: Indexing is commonly used in databases, text searching (like for keywords), and large datasets where quick lookup is necessary.</p> </li> </ul> <p>Hashing:</p> <ul> <li> <p>Purpose: Hashing is used to quickly map data (keys) to a location (bucket) where values are stored. It\u2019s a way to uniquely identify data for fast access.</p> </li> <li> <p>Method: Hashing uses a hash function to convert a key (e.g., a string, number) into a fixed-size integer (hash code), which is then used to locate the data in a hash table.</p> </li> <li> <p>Search Time: Ideally, hashing provides constant-time search, i.e., \ud835\udc42(1) assuming no hash collisions (where multiple keys hash to the same location).</p> </li> <li> <p>Use Case: Commonly used in hash maps, dictionaries, or hash tables where fast insertions, deletions, and lookups are necessary.</p> </li> </ul> Q3. What are the types of Indexing in DBMS? <p>Indexing in DBMS is of the following types:</p> <ul> <li>Primary Index</li> <li>Clustering Index</li> <li>Sparsing Index</li> </ul>"},{"location":"dbms/master_slave_architecture/","title":"Master-Slave Architecture","text":""},{"location":"dbms/master_slave_architecture/#contents","title":"Contents","text":""},{"location":"dbms/master_slave_architecture/master_slave_db/","title":"Master-Slave Database Architecture","text":"<p>\"<code>Data is the new Oil</code>\", with rising Data - The accessibility, readability, and backup of the data are major concerns.</p>"},{"location":"dbms/master_slave_architecture/master_slave_db/#what-is-master-slave-database-configuration","title":"What is Master-Slave Database Configuration?","text":"<p>Master-Slave Database Configuration in simple words is dividing our master databases into multiple slave databases. The Slave database serves as a backup for the master database.</p> <p>The master database is the primary storage of the data, where all the writing operations of the data request are performed whereas the reading operation is spread across multiple slave databases relative to the master database. This enhances the reliability of the databases to a great extent. </p> <p></p> <ul> <li>We have one master node, to which we perform write operation.</li> <li>Master node is connected with multiple slave nodes.</li> <li>If the system prefers consistency, then it will first update the master node, then perform update on slave nodes, and then mark the transaction as successful.</li> <li>Else, if the availability matters more, then it will defer the updation for some time.</li> <li>DB replication will take care of distributing data from Master machine to Slaves machines. This can be synchronous or asynchronous depending upon the system's need.</li> </ul> <ul> <li>Its a Pattern 3 in Database Scaling Pattern. (Command Query Responsibility Segregation)</li> </ul>"},{"location":"dbms/master_slave_architecture/master_slave_db/#what-if-a-update-request-comes-at-a-slave-node","title":"What if a update request comes at a slave node?","text":"<ul> <li>Simply ignore the request.</li> <li>If we are updating the db, then we need some way to propagate the updation to master node.</li> <li>But, this architecture won't be called Master-slave architecture.</li> </ul>"},{"location":"dbms/master_slave_architecture/master_slave_db/#tip-in-master-slave-architecture","title":"Tip in Master-Slave Architecture","text":"<p><code>Write-&gt;Master</code>, <code>Read=&gt;Slave</code></p> <ul> <li>Perform write operation to Master node.</li> <li>Perform read operation on Slave node.</li> </ul>"},{"location":"dbms/master_slave_architecture/master_slave_db/#advantages","title":"Advantages","text":"<ul> <li>BackUP (even if master node goes down, we can still read data)</li> <li>Scale out read operations, reduces latency</li> <li>availability</li> <li>reliable</li> <li>parallelly execute multiple incoming requests (since, multiple read nodes)</li> </ul>"},{"location":"dbms/no_sql/","title":"NoSQL in DBMS","text":""},{"location":"dbms/no_sql/#contents","title":"Contents","text":""},{"location":"dbms/no_sql/introduction/","title":"Introduction to NoSQL","text":""},{"location":"dbms/no_sql/introduction/#what-is-a-nosql-database","title":"What is a NoSQL database?","text":"<p>NoSQL is a type of database management system (DBMS) that is designed to handle and store large volumes of unstructured and semi-structured data. Unlike traditional relational databases that use tables with pre-defined schemas to store data, NoSQL databases use flexible data models that can adapt to changes in data structures and are capable of scaling horizontally to handle growing amounts of data.</p> <ol> <li>They are schema free.</li> <li>Data structures used are not tabular, they are more flexible, has the ability to adjust dynamically.</li> <li>Can handle huge amount of data (big data).</li> <li>Most of the NoSQL are open sources and has the capability of horizontal scaling.</li> <li>It just stores data in some format other than relational.</li> </ol>"},{"location":"dbms/no_sql/introduction/#history-of-nosql","title":"History of NoSQL","text":"<p>History of NoSQL</p> <ul> <li>In 2000s, hardware was really expensive, so to store data in DB, we were required to minimize space and store them effectively. This lead to development of least redundancy and normalization concepts.</li> <li>Over time, hardware prices dropped and now space is not a big concern, but serving customer without latency is the real challenge.</li> <li>To tackle this, new kind of DBs emerged with the intention to minimize the latency and maximize scalability, be it at the cost of data redundancy.</li> <li>These DBs were NoSQL (<code>No only SQL</code>).</li> <li>Cloud computing also rose in popularity, and developers began using public clouds to host their applications and data. They wanted the ability to distribute data across multiple servers and regions to make their applications resilient, to scale out out instead of scale up, and to intelligently geo-place their data. Some NoSQL databases like MongoDB provide these capabilities.</li> </ul>"},{"location":"dbms/no_sql/introduction/#nosql-db-advantages","title":"NoSQL DB advantages","text":"<ul> <li>Flexible Schema</li> <li>Horizontal scaling (<code>scale out</code>).<ul> <li>This is difficult with relational databases due to the difficulty in spreading out related data across nodes. With non-relational databases, this is made simpler since collections are self-contained and not coupled relationally. This allows them to be distributed across nodes more simply, as queries do not have to \u201cjoin\u201d them together across nodes.</li> </ul> </li> <li>Scaling horizontally is achieved through Sharding OR Replica-sets.</li> <li>High availability</li> <li>Easy insert and read operations<ul> <li>Queries in NoSQL databases can be faster than SQL databases. Why? Data in SQL databases is typically normalized, so queries for a single object or entity require you to join data from multiple tables. As your tables grow in size, the joins can become expensive. However, data in NoSQL databases is typically stored in a way that is optimized for queries.</li> <li>The rule of thumb when you use MongoDB is data that is accessed together should be stored together. Queries typically do not require joins, so the queries are very fast.</li> <li>But difficult delete or update operations.</li> </ul> </li> <li>Caching mechanism</li> <li>NoSQL use case is more for cloud application</li> </ul>"},{"location":"dbms/no_sql/introduction/#nosql-db-disadvantages","title":"NoSQL DB Disadvantages \u26a0\ufe0f","text":"<ol> <li>Data Redundancy</li> <li>Since data models in NoSQL databases are typically <code>optimized for queries and not for reducing data duplication</code>, NoSQL databases can be larger than SQL databases. Storage is currently so cheap that most consider this a minor drawback and some NoSQL databases also support compression to reduce the storage footprint.</li> <li>Update &amp; Delete operations are costly.</li> <li>All type of NoSQL Data model doesn\u2019t fulfil all of your application needs</li> <li>Depending on the NoSQL database type you select, you may not be able to achieve all of your use cases in a single database. For example, graph databases are excellent for analyzing relationships in your data but may not provide what you need for everyday retrieval of the data such as range queries. When selecting a NoSQL database, consider what your use cases will be and if a general purpose database like MongoDB would be a better option.</li> <li>Doesn\u2019t support ACID properties in general (<code>mongodb exception</code>).</li> <li>Doesn\u2019t support data entry with consistency constraints. But, is eventually consistent.</li> </ol>"},{"location":"dbms/no_sql/introduction/#when-to-use-nosql","title":"When to use NoSQL?","text":"<ol> <li>When a huge amount of data needs to be stored and retrieved.</li> <li>The relationship between the data you store is not that important</li> <li>The data changes over time and is not structured.</li> <li>Support of Constraints and Joins is not required at the database level</li> <li>The data is growing continuously and you need to scale the database regularly to handle the data.</li> <li>Modern application paradigms like micro-services and real-time streaming.</li> </ol>"},{"location":"dbms/no_sql/introduction/#nosql-db-misconceptions","title":"NoSQL DB Misconceptions","text":"Relationship data is best suited for relational databases! <p>A common misconception is that NoSQL databases or non-relational databases don\u2019t store relationship data well. NoSQL databases can store relationship data \u2014 they just store it differently than relational databases do.</p> <ul> <li>In fact, when compared with relational databases, many find modelling relationship data in NoSQL databases to be easier than in relational databases, because related data doesn\u2019t have to be split between tables. NoSQL data models allow related data to be nested within a single data structure.</li> </ul> NoSQL databases don't support ACID transactions <p>Another common misconception is that NoSQL databases don't support ACID transactions.</p> <ul> <li>Some NoSQL databases like MongoDB do, in fact, support ACID transactions.</li> </ul>"},{"location":"dbms/no_sql/introduction/#types-of-nosql-data-models","title":"Types of NoSQL data models","text":"<ul> <li>Key-Value store</li> </ul> <ul> <li>use cases: <code>user preferences</code>, and <code>user profiles</code>.</li> <li>e.g., Oracle NoSQL, Amazon DynamoDB, MongoDB also supports Key-Value store, Redis.</li> </ul> <ul> <li>Column-Oriented / Columnar / C-Store / Wide-Column</li> </ul> <ul> <li>The data is stored such that each row of a column will be next to other rows from that same column.</li> <li>While a relational database stores data in rows and reads data row by row, a column store is organized as a set of columns.</li> <li>This means that when you want to run analytics on a small number of columns, you can read those columns directly without consuming memory with the unwanted data.</li> <li>Columns are often of the same type and benefit from more efficient compression, making reads even faster.</li> <li>Columnar databases can quickly aggregate the value of a given column (adding up the total sales for the year, for example).</li> <li>Use cases include analytics.</li> <li>e.g., Cassandra, RedShift, Snowflake.</li> </ul> <ul> <li>Document based store</li> </ul> <ul> <li>store data in documents similar to JSON</li> <li>Use cases include e-commerce platforms, trading platforms, and mobile app development across industries.</li> <li><code>Supports ACID</code> properties hence, suitable for Transactions.</li> <li>e.g., MongoDB, CouchDB.</li> </ul> <ul> <li>Graph based models</li> </ul> <ul> <li>A graph database focuses on the relationship between data elements. Each element is stored as a node (such as a person in a social media graph). The connections between elements are called links or relationships. In a graph database, connections are first-class elements of the database, stored directly. In relational databases, links are implied, using data to express the relationships.</li> <li>A graph database is optimized to capture and search the connections between data elements, overcoming the overhead associated with JOINing multiple tables in SQL.</li> <li>Very few real-world business systems can survive solely on graph queries. As a result graph databases are usually run alongside other more traditional databases.</li> <li>Use cases include fraud detection, social networks, and knowledge graphs.</li> <li>e.g., Neo4J</li> </ul>"},{"location":"dbms/no_sql/sql_vs_nosql/","title":"SQL Vs NoSQL","text":""},{"location":"dbms/no_sql/sql_vs_nosql/#sql-structured-query-language-databases","title":"SQL (Structured Query Language) Databases","text":"<ul> <li> <p>Structured Data: SQL databases store data in tables (like a spreadsheet) with rows and columns. Each row represents a record, and each column represents a field (e.g., name, age, address).</p> </li> <li> <p>Schema-based: They follow a predefined schema, meaning the structure of the data (like what fields exist and their types) must be defined upfront. All data must fit into this structure.</p> </li> <li> <p>Relational: They are also called relational databases because data can be linked between different tables through relationships (using foreign keys).</p> </li> <li> <p>Examples: MySQL, PostgreSQL, Oracle, SQL Server.</p> </li> <li> <p>Use Case: Ideal for applications that require complex queries, structured data, and strong consistency, like financial systems, inventory management, and enterprise applications.</p> </li> </ul>"},{"location":"dbms/no_sql/sql_vs_nosql/#nosql-not-only-sql-databases","title":"NoSQL (Not Only SQL) Databases","text":"<ul> <li> <p>Unstructured or Semi-structured Data: NoSQL databases store data in a more flexible way, often using documents, key-value pairs, graphs, or wide-column stores.</p> <ul> <li> <p>Document-based: Data is stored as documents (usually in JSON or BSON format) that can have varying structures (e.g., some documents might have different fields).</p> </li> <li> <p>Key-value: Data is stored as key-value pairs, like a dictionary.</p> </li> </ul> </li> <li> <p>Schema-less: No predefined schema is required. Data can be added without needing to define a strict structure, allowing for greater flexibility in handling different types of data.</p> </li> <li> <p>Non-relational: Relationships between data are less strict, or sometimes nonexistent, compared to SQL.</p> </li> <li> <p>Examples: MongoDB, Cassandra, Redis, CouchDB.</p> </li> <li> <p>Use Case: Ideal for applications that handle large volumes of unstructured or semi-structured data, need high scalability, or deal with frequently changing data, like social media, real-time analytics, or IoT data.</p> </li> </ul>"},{"location":"dbms/no_sql/sql_vs_nosql/#sql-vs-nosql_1","title":"SQL Vs NoSQL","text":"<p>ACID compliant in MongoDB</p> <ul> <li>Most NoSQL aren't ACID compliant, but MongoDB is acid compliant.</li> </ul> <pre><code>s.start_transaction()\n    orders.insert_one(order, session=s)\n    stock.update_one(item, stockUpdate, session=s)\ns.commit_transaction()\n</code></pre>"},{"location":"dbms/normalization/","title":"Normalization","text":""},{"location":"dbms/normalization/#contents","title":"Contents","text":""},{"location":"dbms/normalization/introduction/","title":"Introduction to Normalization","text":""},{"location":"dbms/normalization/introduction/#what-is-a-normalization","title":"What is a Normalization?","text":"<p>Normalization is the process of organizing the data and the attributes of a database. It is performed to reduce the data redundancy in a database and to ensure that data is stored logically.</p> <p>Data redundancy in DBMS means having the same data but at multiple places. It is necessary to remove data redundancy because it causes anomalies in a database which makes it very hard for a database administrator to maintain it.</p>"},{"location":"dbms/normalization/introduction/#why-do-we-need-normalization","title":"Why Do We Need Normalization?","text":"<p>Normalization is used to reduce data redundancy. It provides a method to remove the following anomalies from the database and bring it to a more consistent state:</p> <p></p> <p>Updation / Update Anomaly</p> <p>In the above table, if Shivani changes her branch from Computer Science to Electronics, then we will have to update all the rows. If we miss any row, then Shivani will have more than one branch, which will create the update anomaly in the table.</p> <p>Insertion Anomaly</p> <p>If we add a new row for student Ankit who is not a part of any club, we cannot insert the row into the table as we cannot insert null in the column of stu_club. This is called insertion anomaly.</p> <p>Deletion Anomaly</p> <p>If we remove the photography club from the college, then we will have to delete its row from the table. But it will also delete the table of Gopal and his details. So, this is called deletion anomaly and it will make the database inconsistent.</p> <ul> <li>Due to these anomalies, DB size increases, and DB performance slows down.</li> <li>To rectify these anomalies, we use <code>Normalization</code>.</li> </ul>"},{"location":"dbms/normalization/introduction/#normal-forms","title":"Normal Forms","text":"<p>There are four types of normal forms that are usually used in relational databases.</p> <p></p>"},{"location":"dbms/normalization/normal_forms/bcnf/","title":"Normal Forms","text":""},{"location":"dbms/normalization/normal_forms/bcnf/#boyce-codd-normal-form-bcnf","title":"Boyce-Codd Normal Form (BCNF)","text":"<p>Boyce-Codd Normal Form(BCNF) is an advanced version of 3NF as it contains additional constraints compared to 3NF.</p> <ul> <li> <p>For a relational table to be in Boyce-Codd normal form, it must satisfy the following rules:</p> <ol> <li>The table must be in the third normal form.</li> <li>For every non-trivial functional dependency <code>X -&gt; Y</code>, X is the superkey of the table. That means X cannot be a non-prime attribute if Y is a prime attribute.</li> </ol> </li> <li> <p>A superkey is a set of one or more attributes that can uniquely identify a row in a database table.</p> </li> </ul> <p>Let us take an example of the following <code>EmployeeProjectLead</code> table to understand how to normalize the table to the BCNF:</p> <p></p> Explanation <p>The above table satisfies all the normal forms till 3NF, but it violates the rules of BCNF because the candidate key of the above table is <code>{Employee Code, Project ID}</code>. For the non-trivial functional dependency, <code>Project Leader -&gt; Project ID</code>, Project ID is a prime attribute but Project Leader is a non-prime attribute. This is not allowed in BCNF.</p> <p>To convert the given table into BCNF, we decompose it into two tables:</p> <p></p> <p>Thus, we\u2019ve converted the <code>EmployeeProjectLead</code> table into BCNF by decomposing it into <code>EmployeeProject</code> and <code>ProjectLead</code> tables.</p>"},{"location":"dbms/normalization/normal_forms/first_normal_form/","title":"Normal Forms","text":""},{"location":"dbms/normalization/normal_forms/first_normal_form/#first-normal-form-1nf","title":"First Normal Form (1NF)","text":"<p>A relation is in 1NF if every attribute is a single-valued attribute or it does not contain any multi-valued or composite attribute, i.e., every attribute is an atomic attribute. If there is a composite or multi-valued attribute, it violates the 1NF. To solve this, we can create a new row for each of the values of the multi-valued attribute to convert the table into the 1NF.</p> <p>Let\u2019s take an example of a relational table <code>EmployeeDetail</code> that contains the details of the employees of the company.</p> <p></p> <p>To convert this table into 1NF, we make new rows with each Employee Phone Number as a new row as shown below:</p> <p></p>"},{"location":"dbms/normalization/normal_forms/second_normal_form/","title":"Normal Forms","text":""},{"location":"dbms/normalization/normal_forms/second_normal_form/#second-normal-form-2nf","title":"Second Normal Form (2NF)","text":"<p>The normalization of 1NF relations to 2NF involves the elimination of partial dependencies. A partial dependency in DBMS exists when any non-prime attributes, i.e., an attribute not a part of the primary key, is not fully functionally dependent on one of the primary keys.</p> <ul> <li> <p>For a relational table to be in second normal form, it must satisfy the following rules:</p> <ol> <li>The table must be in first normal form.</li> <li>It must not contain any partial dependency, i.e., all non-prime attributes are fully functionally dependent on the primary key.</li> </ol> </li> <li> <p>If a partial dependency exists, we can divide the table to remove the partially dependent attributes and move them to some other table where they fit in well.</p> </li> </ul> <p>Let us take an example of the following <code>EmployeeProjectDetail</code> table to understand what is partial dependency and how to normalize the table to the second normal form:</p> <p></p> Explanation <p>In the above table, the prime attributes of the table are <code>Employee Code</code> and <code>Project ID</code>. We have partial dependencies in this table because <code>Employee Name</code> can be determined by <code>Employee Code</code> and <code>Project Name</code> can be determined by <code>Project ID</code>. Thus, the above relational table violates the rule of 2NF.</p> <p>To remove partial dependencies from this table and normalize it into second normal form, we can decompose the <code>EmployeeProjectDetail</code> table into the following three tables:</p> <p></p> <p></p> <p></p> <p>Thus, we\u2019ve converted the <code>EmployeeProjectDetail</code> table into 2NF by decomposing it into <code>EmployeeDetail</code>, <code>ProjectDetail</code> and <code>EmployeeProject</code> tables. The above tables satisfy the following two rules of 2NF as they are in 1NF and every non-prime attribute is fully dependent on the primary key.</p>"},{"location":"dbms/normalization/normal_forms/third_normal_form/","title":"Normal Forms","text":""},{"location":"dbms/normalization/normal_forms/third_normal_form/#third-normal-form-3nf","title":"Third Normal Form (3NF)","text":"<p>The normalization of 2NF relations to 3NF involves the elimination of transitive dependencies in DBMS.</p> <ul> <li> <p>For a relational table to be in third normal form, it must satisfy the following rules:</p> <ol> <li>The table must be in the second normal form.</li> <li>No transitivity dependency exists.<ul> <li>If a non-primary attribute can be defined using another non-primary attribute then it is called a transitive dependency.</li> </ul> </li> </ol> </li> </ul> <p>Let us take an example of the following <code>EmployeeDetail</code> table to understand what is transitive dependency and how to normalize the table to the third normal form:</p> <p></p> Explanation <p>In the above table, the prime attribute of the table is <code>Employee Code</code> and non-prime attributes are <code>Employee Name</code> , <code>Employee Zipcode</code> and <code>Employee City</code>. We have transitive dependencies in this table because <code>Employee City</code> can be determined by <code>Employee Zipcode</code> and both <code>Employee City</code> and <code>Employee Zipcode</code> are non-prime attribute. Thus, the above relational table violates the rule of 3NF.</p> <p>To remove transitive dependency from this table and normalize it into the third normal form, we can decompose the <code>EmployeeDetail</code> table into the following two tables:</p> <p></p> <p>Thus, we\u2019ve converted the <code>EmployeeDetail</code> table into 3NF by decomposing it into <code>EmployeeDetail</code> and <code>EmployeeLocation</code> tables as they are in 2NF and they don\u2019t have any transitive dependency.</p>"},{"location":"dbms/scaling_db/","title":"Scaling Databases","text":""},{"location":"dbms/scaling_db/#contents","title":"Contents","text":""},{"location":"dbms/scaling_db/clustering_partitioning/","title":"Clustering &amp; Partitioning","text":""},{"location":"dbms/scaling_db/clustering_partitioning/#clustering","title":"Clustering","text":"<p>Clustering refers to grouping multiple servers or nodes to work together as a single system. In the context of databases, clustering is used to distribute data and workload across multiple servers, allowing the system to handle larger datasets and more users.</p> <p>Purpose</p> <ul> <li> <p>Scalability: By distributing data and requests across multiple servers, clustering allows systems to handle larger loads and improve performance.</p> </li> <li> <p>High Availability: Clustering can also be used to ensure that if one node fails, others can take over, improving fault tolerance.</p> </li> </ul> <p>How It Works</p> <ul> <li> <p>In a cluster, data is often sharded (split into smaller pieces) and distributed across different nodes.</p> </li> <li> <p>Each node may handle a portion of the data and workload, enabling the system to process larger datasets and handle more requests.</p> </li> <li> <p>Clustering is about horizontal scaling, meaning you can add more machines to handle increased load.</p> </li> </ul> <p>Example</p> <p>In a sharded cluster (like MongoDB), data is split into smaller chunks (shards), and each node holds only a portion of the total data. Requests are distributed across the cluster to balance the load.</p>"},{"location":"dbms/scaling_db/clustering_partitioning/#partitioning","title":"Partitioning","text":"<ul> <li> <p>A big problem can be solved easily when it is chopped into several smaller sub-problems. That is what the partitioning technique does.</p> </li> <li> <p>It divides a big database containing data metrics and indexes into smaller and handy slices of data called partitions.</p> </li> <li> <p>The partitioned tables are directly used by SQL queries without any alteration.</p> </li> <li> <p>Once the database is partitioned, the data definition language can easily work on the smaller partitioned slices, instead of handling the giant database altogether.</p> </li> <li> <p>This is how partitioning cuts down the problems in managing large database tables.</p> </li> </ul> <p>Partitioning is the process of dividing a large database or table into smaller, more manageable pieces called partitions. Each partition contains a subset of the data, making it easier to manage, query, and maintain.</p> <p>Relational V/s NOSQL DB on partitioning</p> <ul> <li>When we horizontally scale our machines/servers, we know that it gives us a challenging time dealing with relational databases as it\u2019s quite tough to maintain the relations.</li> <li>For performing joins, we will be required to fetch data from multiple servers and then perform join, which will be time-consuming.</li> <li>If instead, we used NOSQL DB, data that will be required together will be stored together. Also, we don't care much about normalization in NOSQL, which eventually leads to better performance and availability.</li> </ul>"},{"location":"dbms/scaling_db/clustering_partitioning/#vertical-partitioning","title":"Vertical Partitioning","text":"<ul> <li>Slicing relation vertically / column-wise.</li> <li>Need to access different servers to get complete tuples.</li> </ul>"},{"location":"dbms/scaling_db/clustering_partitioning/#horizontal-partitioning","title":"Horizontal Partitioning","text":"<ul> <li>Slicing relation horizontally / row-wise.</li> <li>Independent chunks of data tuples are stored in different servers.</li> </ul>"},{"location":"dbms/scaling_db/clustering_partitioning/#when-partitioning-is-applied","title":"When Partitioning is Applied?","text":"<ul> <li>Dataset become much huge that managing and dealing with it become a tedious task.</li> <li>the number of requests are enough larger that the single DB server is taking huge time and hence the system's response time become high.</li> </ul>"},{"location":"dbms/scaling_db/clustering_partitioning/#benefits-of-partitioning","title":"Benefits of Partitioning","text":"<ul> <li> <p>Improved Query Performance :- SQL queries can target specific partitions rather than scanning the entire table. This reduces the amount of data the database engine has to process, leading to faster query execution.</p> </li> <li> <p>Easier Data Management :- Maintenance tasks like backups, archiving, and deleting old data become simpler because these operations can be done on individual partitions instead of the entire database.</p> </li> <li> <p>Reduced Index Size :- Since partitions hold smaller portions of data, the indexes on each partition are also smaller, making index scans and lookups faster.</p> </li> <li> <p>Parallel Processing :- Some databases support processing partitions in parallel, meaning multiple partitions can be read or written simultaneously. This improves the overall throughput of queries and operations.</p> </li> <li> <p>Scalability :- As data grows, partitioning allows the system to handle more data without significantly degrading performance. It makes it easier to manage the continuous growth of large datasets.</p> </li> </ul>"},{"location":"dbms/scaling_db/clustering_partitioning/#scaling-up-vs-scaling-out","title":"Scaling Up Vs Scaling Out","text":"<ul> <li>Scaling up =&gt; Vertical scaling (adding more resources (ram, cpu, etc.))</li> <li>Scaling out =&gt; horizontal scaling (adding more servers)</li> </ul>"},{"location":"dbms/scaling_db/clustering_partitioning/#distributed-database","title":"Distributed database","text":"<ul> <li>A single logical database that is spread across multiple locations (servers) and logically interconnected by network.</li> <li>This is the product of applying DB optimization techniques like, <code>Clustering</code>, <code>Partitioning</code> &amp; <code>Sharding</code>.</li> </ul> <p>Why is it needed?</p> <ul> <li>Dataset become much huge that managing and dealing with it become a tedious task.</li> <li>the number of requests are enough larger that the single DB server is taking huge time and hence the system's response time become high.</li> </ul>"},{"location":"dbms/scaling_db/db_scaling_pattern/","title":"Database Scaling Patterns","text":"<ul> <li>step by step manner, when to choose which scaling option</li> </ul>"},{"location":"dbms/scaling_db/db_scaling_pattern/#case-study","title":"Case Study","text":""},{"location":"dbms/scaling_db/db_scaling_pattern/#pattern-1","title":"Pattern 1","text":""},{"location":"dbms/scaling_db/db_scaling_pattern/#pattern-2","title":"Pattern 2","text":""},{"location":"dbms/scaling_db/db_scaling_pattern/#pattern-3","title":"Pattern 3","text":""},{"location":"dbms/scaling_db/db_scaling_pattern/#pattern-4","title":"Pattern 4","text":""},{"location":"dbms/scaling_db/db_scaling_pattern/#pattern-5","title":"Pattern 5","text":""},{"location":"dbms/scaling_db/db_scaling_pattern/#pattern-6","title":"Pattern 6","text":""},{"location":"dbms/scaling_db/db_scaling_pattern/#pattern-7","title":"Pattern 7","text":""},{"location":"dbms/scaling_db/introduction/","title":"Introduction to Scaling Databases","text":""},{"location":"dbms/scaling_db/introduction/#what-is-database-scaling","title":"What is database scaling?","text":"<p>When thinking about a software system\u2019s scalability, we must consider the performance of one of the most common system resources :- a database. Databases play a crucial role in the overall performance of any system that is dependent on the retrieval and storage of information. If a database is responding to too many requests or runs out of storage capacity, a system may perform poorly (e.g., slow response speed). This is why it is important to consider database scaling to accommodate a system\u2019s growing data storage and performance needs.</p> <p>Database Scaling is the process of adding or removing from a database\u2019s pool of resources to support changing demand. A database can be scaled up or down to accommodate the needs of the application that it\u2019s supporting.</p>"},{"location":"dbms/scaling_db/sharding_replication/","title":"Sharding &amp; Replication","text":""},{"location":"dbms/scaling_db/sharding_replication/#sharding","title":"Sharding","text":"<p>let\u2019s explore database sharding. It is the process of splitting a single (usually large) dataset into various smaller chunks (known as shards) that are stored across multiple databases. Sharding is considered to be a horizontal scaling solution since it increases the number of database instances in a system.</p> <p>For example, we wanted to shard a large dataset of clothing inventory for an e-commerce application, it might look like this :-</p> <p></p> <p>Note how the inventory table was broken up and spread across multiple machines hosting a database. In this case, the table was broken up by the size value, with all items of a particular size in its own database instance (aka a shard).</p> <p>Now, we have a general overview of the concept of sharding, let\u2019s explore the distinct advantages and disadvantages:</p> <p>Advantages</p> <ul> <li> <p>Increase in storage capacity: By increasing the number of shards, the overall total storage capacity of a system is increased.</p> </li> <li> <p>Increased Availability: Even if one shard goes offline, the majority of shards will still be available to retrieve and store data. This means only a portion of the overall dataset will be unavailable.</p> </li> </ul> <p>Disadvantages</p> <ul> <li> <p>Query overhead: A database that has been sharded must have an independent machine or service that can properly route database queries to the appropriate shard. This increases latency and expense on every operation because if the query requires data from multiple shards, the router must query each shard and then merge the data.</p> </li> <li> <p>Administration complexity: A database that has been sharded requires more upkeep and maintenance since there are now multiple machines with their own databases.</p> </li> <li> <p>Increased cost: There is an inherent increase in cost because sharding requires more machines as well as computing power.</p> </li> </ul>"},{"location":"dbms/scaling_db/sharding_replication/#replication","title":"Replication","text":"<p>A replica set is a group of database servers (nodes) that store copies of the same data. The purpose of a replica set is to provide <code>redundancy</code> and <code>high availability</code>.</p> <p>How It Works:</p> <ul> <li> <p>In a replica set, there is typically one primary node and one or more secondary nodes.</p> </li> <li> <p><code>Primary Node</code> Handles all write operations. The changes are replicated to the secondary nodes.</p> </li> <li> <p><code>Secondary Nodes</code> Act as backups, and if the primary node fails, one of the secondary nodes automatically becomes the new primary (called <code>failover</code>).</p> </li> </ul> <p>Replication is a scaling strategy where identical copies of a database are created on additional machines. If we return to our clothing inventory database, here is what the database architecture would look like using the replication strategy:</p> <p></p> <p>Now, we have a general overview of the concept of replication, let\u2019s explore the distinct advantages and disadvantages:</p> <p>Advantages</p> <ul> <li> <p>Decreased load: Due to data being replicated, queries can be spread across multiple databases. This reduces the likelihood that any single database will be overwhelmed with queries.</p> </li> <li> <p>Increased Availability: With the same data being replicated on multiple servers; replication ensures that if one database goes down, the entire system can still be fully functional.</p> </li> </ul> <p>Disadvantages</p> <ul> <li> <p>Increased write complexity: Write-focused queries (i.e., saving data to the database) increase complexity because the data must be copied to every replicated database instance to make sure each database stays in sync.</p> </li> <li> <p>Potential Data inconsistency: Data that has been replicated that is either incorrect or out of date can lead to other machines part of the system being out of sync.</p> </li> </ul>"},{"location":"dbms/sql_/","title":"Structured Query Language(SQL)","text":""},{"location":"dbms/sql_/#contents","title":"Contents","text":""},{"location":"dbms/sql_/introduction/","title":"Introduction to SQL","text":""},{"location":"dbms/sql_/introduction/#what-is-a-database","title":"What is a Database?","text":"<p>Database is an electronic place/system where data is stored in a way that it can be easily accessed, managed, and updated.</p>"},{"location":"dbms/sql_/introduction/#what-is-dbms","title":"What is DBMS?","text":"<p>A database management system (DBMS) is a software system for creating and managing databases. A DBMS enables end users to create, protect, read, update and delete data in a database.</p>"},{"location":"dbms/sql_/introduction/#what-is-rdbms","title":"What is RDBMS?","text":"<ul> <li>RDBMS (Relational Database Management System) is a DBMS based on the concept of tables (also called relations).</li> <li>Data is organized into tables (also known as relations) with rows (records) and columns (attributes).</li> <li>Eg - MySQL, PostgreSQL, Oracle etc.</li> </ul>"},{"location":"dbms/sql_/introduction/#types-of-databases","title":"Types of Databases","text":""},{"location":"dbms/sql_/introduction/#relational-database","title":"Relational Database","text":"<p>A relational database stores data in a table composed of rows and columns. The table represents an object or entity, such as users, customers, orders, etc.</p>"},{"location":"dbms/sql_/introduction/#non-relational-database","title":"Non-Relational database","text":"<p>Non-relational databases different from relational databases because they do not store data in tabular form.</p> <p></p>"},{"location":"dbms/sql_/introduction/#what-is-sql","title":"What is SQL?","text":"<p>SQL is Structured Query Language used to store, manipulate and retrieve data from RDBMS.</p> <p>Note 1. It is not a database, it is a language used to interact with database. 2. SQL keywords are NOT case sensitive. Eg:- select is the same as SELECT in SQL.</p> <p>We use SQL for CRUD Operations :- 1. CREATE - To create databases, tables etc... 2. READ - To read data present in the database. 3. UPDATE - Modify already inserted data. 4. DELETE - Delete database, table or specific data point/tuple/row or multiple rows.</p>"},{"location":"dbms/sql_/introduction/#sql-vs-mysql","title":"SQL v/s MySQL","text":"<p>SQL is a language used to perform CRUD operations in Relational DB, while MySQL is a RDBMS that uses SQL.</p>"},{"location":"dbms/transaction_and_acid/","title":"Transactions &amp; ACID properties in DBMS","text":""},{"location":"dbms/transaction_and_acid/#contents","title":"Contents","text":""},{"location":"dbms/transaction_and_acid/acid/","title":"ACID properties in DBMS","text":""},{"location":"dbms/transaction_and_acid/acid/#what-are-acid-properties","title":"What are ACID Properties?","text":"<p>ACID properties are a set of properties that guarantee reliable processing of transactions in a database management system (DBMS). Transactions are a sequence of database operations that are executed as a single unit of work, and the ACID properties ensure that transactions are processed reliably and consistently in a DBMS.</p> <p></p> <ul> <li>The Atomicity property ensures that a transaction is either executed completely or not at all.</li> <li>The Consistency property ensures that the database remains in a consistent state before and after a transaction.</li> <li>The Isolation property ensures that multiple transactions can run concurrently without interfering with each other.</li> <li>The Durability property ensures that the results of a committed transaction are permanent and cannot be lost due to system failure.</li> </ul> <p>Together, these properties ensure that transactions are processed reliably and consistently in a DBMS, which is essential for the integrity and accuracy of data in a database.</p>"},{"location":"dbms/transaction_and_acid/acid/#1-atomicity","title":"1. Atomicity","text":"<p>The term atomicity means if any operation on the data is conducted, it should either be executed completely or not at all. It also implies that the operation should not be interrupted or just half completed. When performing operations on a transaction, the operation should be completed totally rather than partially. If any of the operations aren\u2019t completed fully, the transaction gets aborted.</p>"},{"location":"dbms/transaction_and_acid/acid/#2-consistency","title":"2. Consistency","text":"<p>This ACID Property will verify the total sum of seats left in the train + sum of seats booked by users = total the number of seats present in the train. After each transaction, consistency is checked to ensure nothing has gone wrong.</p>"},{"location":"dbms/transaction_and_acid/acid/#3-isolation","title":"3. Isolation","text":"<p>This property ensures that multiple transactions can occur concurrently without leading to the inconsistency of the database state. Transactions occur independently without interference. Changes occurring in a particular transaction will not be visible to any other transaction until that particular change in that transaction is written to memory or has been committed.</p>"},{"location":"dbms/transaction_and_acid/acid/#4-durability","title":"4. Durability","text":"<p>The durability property states that once the execution of a transaction is completed, the modifications and updates on the database gets written on and stored in the disk. These persist even after the occurrence of a system failure. Such updates become permanent and get stored in non-volatile memory. Thus, the effects of this transaction are never lost.</p>"},{"location":"dbms/transaction_and_acid/acid_vs_base/","title":"ACID vs BASE","text":"<ul> <li><code>ACID</code>: Atomicity, Consistency, Isolation, Durability</li> <li><code>BASE</code>: Basically available, soft-state &amp; eventually consistent</li> </ul>"},{"location":"dbms/transaction_and_acid/acid_vs_base/#base-compliant-dbs","title":"BASE compliant DBs","text":"<ul> <li>Basically Available: The system guarantees availability according to the CAP theorem, but without strict guarantees on immediate consistency.</li> <li>Soft state: The state of the system may change over time, even without input (due to eventual consistency).</li> <li>Eventual consistency: The system will become consistent over time, given that no new updates are made. It is not immediately consistent. Changes will be reflected over time (obviously withing acceptable range).</li> </ul>"},{"location":"dbms/transaction_and_acid/acid_vs_base/#acid-base","title":"ACID &amp; BASE","text":"<ul> <li>Most RDBMS (or SQL DBs) are ACID compliant.</li> <li>Whereas, NoSQL (not only SQL) are BASE compliant. (though, <code>MongoDB is acid compliant</code> too)</li> </ul>"},{"location":"dbms/transaction_and_acid/acid_vs_base/#difference-bw-the-two","title":"Difference b/w the two","text":""},{"location":"dbms/transaction_and_acid/acid_vs_base/#when-to-use-which-one","title":"When to use which one?","text":"<p>ACID V/S BASE compliant DBs</p> <ul> <li>For financial &amp; banking systems, where atomicity, consistency and durability is more preferred over availability, ACID compliant DBs should be preferred.</li> </ul> <ul> <li>For social media apps, where availability matters over slight delay in the updated value (<code>comments on a post being reflected after some seconds</code>), BASE compliant DBs should be preferred.</li> </ul>"},{"location":"dbms/transaction_and_acid/implement_atomicity_and_durability/","title":"Implement Atomicity &amp; Durability in Transactions","text":"<p>Atomicity: By this property, we mean that the entire transaction takes place at once or it does not take place at all. There is no midway. This means that transactions do not occur partially. Either all the changes made by a transaction are committed to the database or none of them are committed.</p> <p>Durability: By this property, we mean that once a transaction has completed execution its effects persist even in case of system failure. The changes made by the transaction should be stored permanently in the system.</p>"},{"location":"dbms/transaction_and_acid/implement_atomicity_and_durability/#methods-to-implement-atomicity-and-durability","title":"Methods to Implement Atomicity and Durability","text":""},{"location":"dbms/transaction_and_acid/implement_atomicity_and_durability/#1-shadow-copy-scheme","title":"1. Shadow Copy Scheme","text":"<p>This scheme is based on making copies of the Database. These copies of Databases are also known as Shadow Copies. Suppose there is an active transaction T1. Now, A pointer called Db_pointer is maintained on the disk, which points to the current copy of the Database. The transaction T1 that want to update the Database will first create a complete copy of the Database. All further operations are done on new copy and leave that original copy untouched.</p> <p>If at any point transaction T1 is aborted, then system delete new copy and the old copy is not affected. It remain untouched.</p> <p>if Transaction T1 success then OS (Operating System) will make sure that all the pages of new copy of Database are written in the disk. Database system update Db_pointer to point to the new copy of Database. Now, new copy will become current copy of Database. Also old copy of Database will be deleted. Transaction T1 is said to committed only if updated Db-pointer is written on disk.</p> <p>How Atomicity is Maintained in Shadow Copy Scheme?</p> <p>If transaction T1 fails any time before Db_pointer is updated, the old content of Database are not affected. Transaction T1 abort can be done by deleting the new copy of Database. So, here either all changes are reflected or none. In this way Atomicity is maintained in this scheme.</p> <p>How Durability is Maintained in Shadow Copy Scheme?</p> <p>Let\u2019s suppose, system fails at any time before the updated pointer is written to disk. When system start again, it will try to read the Database pointer (Db_pointer) and thus see the original content of Database. No effects of Transaction T1 will be visible. Transaction T1 is assumed to be successful only when Db_pointer is updated. If system fails after Db_pointer update then before that all the pages of new copy were written on disk. So, When system start again then it will read the new Database copy.</p> <p></p>"},{"location":"dbms/transaction_and_acid/implement_atomicity_and_durability/#2-log-based-recovery-method","title":"2. Log-Based recovery method","text":"<ul> <li>log is a sequence of records.</li> <li>Log of each transaction is maintained in some stable storage so that if any failure occurs, then it can be recovered from there.</li> <li>If any operation is performed on the database, then it will be recorded in the log.</li> <li>But the process of storing the logs should be done before the actual transaction is applied in the database.</li> <li>Stable storage is a classification of computer data storage technology that guarantees atomicity for any given write operation and allows software to be written that is robust against some hardware and power failures.</li> </ul> <p>There are two types of log-based recovery methods, these are :-</p> <p>1. Deferred DB Modifications</p> <p>In this method, We ensure Atomicity by recording all the updates or modifications in the log but we deferr the execution of all the write operations until the final action of Transation T1 has been executed or T1 has been committed. Then information in log is used to execute deffered writed when Transaction T1 is completed. If system crashes before completion of T1 or if T1 is aborted then the information in the logs is ignored. If Transaction T1 is completed then the records associated to it in its log file are used to execute the deferred writes. We will perform redo if failure occure duing updation.</p> <p>Example: Consider a Transaction where we are transferring 50 rupees from A(having Rs 2000) to B(having Rs 3000) then in deferred modification its log will be maintained as</p> <p></p> <p>2. Immediate DB modifications</p> <p>In this method, Database modifications to be done to Database while Transaction T1 is in active state. Database modifications written by active Transaction T1 called uncommitted modifications. When any of system crash or failure occure then system uses old value field of the logs to restore the modified values. Update take place only after log records in a stable storage. If system fails before T1 completes or if T1 is aborted then old value field in log table is used to undo T1. If T1 completes and then system crashes then new value field in log table is used to redo T1.</p> <p>Example: Consider a Transaction where we are transferring 50 rupees from A(having Rs 2000) to B(having Rs 3000) then in deferred modification its log will be maintained as</p> <p></p>"},{"location":"dbms/transaction_and_acid/implement_atomicity_and_durability/#difference-between-the-two-deferred-vs-immediate","title":"Difference between the two (<code>Deferred Vs Immediate</code>)","text":"<ul> <li>Deferred logs what it will do, and but the updates to DB are not done immediately, but rather stored in buffer. Once the whole process is over, it will go one by one over the logs, and actually execute. If before the update were committed, system crashed, means, nothing could be updated in DB. In that case, it will restart executing the logs.</li> </ul> <ul> <li>Immediate logs will log what it will do, then does that, and proceeds like this. If the system crashes before the execution could finish or commit, when the system will restart, it will backtrack the logs and undo the operations. In case it logged committed, but before committing, system crashed, it will redo the operations based on logs.</li> </ul> <ul> <li>Deferred only read the current state, whereas Immediate logs also store the previous and new value (helpful in case of backtrack (rollup)).</li> </ul>"},{"location":"dbms/transaction_and_acid/transaction/","title":"Transaction in DBMS","text":""},{"location":"dbms/transaction_and_acid/transaction/#what-is-transaction-in-dbms","title":"What is Transaction in DBMS?","text":"<p>Transactions in Database Management Systems (DBMS) are sets of operations performed to modify data, including insertion, updates, or deletions.These transactions have various states indicating their progress and required actions. They ensure data consistency even during system failures, demonstrating a key advantage of DBMS.</p>"},{"location":"dbms/transaction_and_acid/transaction/#operations-in-transaction","title":"Operations in Transaction","text":"<p>A certain set of operations takes place when a transaction is done that is used to perform some logical set of operations. For example: When we go to withdraw money from ATM, we encounter the following set of operations:</p> <ol> <li>Transaction Initiated</li> <li>You have to insert an ATM card</li> <li>Select your choice of language</li> <li>Select whether savings or current account</li> <li>Enter the amount to withdraw</li> <li>Entering your ATM pin</li> <li>Transaction processes</li> <li>You collect the cash</li> <li>You press finish to end transaction</li> </ol> <p>The above mentioned are the set of operations done by you. But in the case of a transaction in DBMS there are three major operations that are used for a transaction to get executed in an efficient manner. These are:</p> <ol> <li>Read/ Access Data </li> <li>Write/ Change Data </li> <li>Commit</li> </ol> <p>  Let's understand the above three sets of operations in a transaction with a real-life example of transferring money from Account1 to Account2.</p> <p>Initial balance in both the banks before the start of the transaction</p> <p><code>Account1 - \u20b9 5000 Account2 - \u20b9 2000</code></p> <p>This data before the start of the transaction is stored in the secondary memory (Hard disk) which once initiated is bought to the primary memory (RAM) of the system for faster and better access.</p> <p>Now for a transfer of \u20b9 500 from Account1 to Account2 to occur, the following set of operations will take place.</p> <p><code>Read (Account1) --&gt; 5000 Account1 = Account1 - 500 Write (Account1) --&gt; 4500 Read (Account2) --&gt; 2000 Account2 = Account2 + 500 Write (Account2) --&gt; 2500 commit</code></p> <p>The COMMIT statement permanently saves the changes made by the current transaction. When a transaction is successful, COMMIT is applied. If the system fails before a COMMIT is applied, the transaction reaches its previous state after ROLLBACK.</p> <p>After commit operation the transaction ends and updated values of Account1 = \u20b9 4500 and Account2 = \u20b9 2500. Every single operation that occurs before the commit is said to be in a partially committed state and is stored in the primary memory (RAM). After the transaction is committed, the updated data is accepted and updated in the secondary memory (Hard Disk).</p> <p>If in some case, the transaction failed anywhere before committing, then that transaction gets aborted and have to start from the beginning as it can\u2019t be continued from the previous state of failure. This is known as Roll Back. :::</p>"},{"location":"dbms/transaction_and_acid/transaction/#transaction-states-in-dbms","title":"Transaction States in DBMS","text":"<p>During the lifetime of a transaction, there are a lot of states to go through. These states update the operating system about the current state of the transaction and also tell the user about how to plan further processing of the transaction.</p> <p></p> <p>The ROLLBACK statement undo the changes made by the current transaction. A transaction cannot undo changes after COMMIT execution.</p>"},{"location":"dbms/transaction_and_acid/transaction/#following-are-the-different-types-of-transaction-states","title":"Following are the different types of transaction States :","text":"<ol> <li> <p>Active State: When the operations of a transaction are running then the transaction is said to be active state.</p> </li> <li> <p>Partially Committed:  If all the read and write operations are performed without any error then it progresses to the partially committed state.</p> </li> <li> <p>Failed State: If any operation during the transaction fails due to some software or hardware issues, then it goes to the failed state.</p> </li> <li> <p>Aborted State: If the transaction fails during its execution, it goes from failed state to aborted state and because in the previous states all the changes were only made in the main memory, these uncommitted changes are either deleted or rolled back. The transaction at this point can restart and start afresh from the active state.</p> </li> <li> <p>Committed State: We can say that a transaction is committed in case it actually executes all of its operations successfully. In such a case, all of its effects are now established permanently on the DB system.</p> </li> <li> <p>Terminated State: This is the final stage of a transaction's life cycle. The transaction finally enters the terminated state when its life cycle is completed after having been in the committed or aborted stage.</p> </li> </ol>"},{"location":"dbms/types_of_db/","title":"Types of Databases","text":""},{"location":"dbms/types_of_db/#contents","title":"Contents","text":""},{"location":"dbms/types_of_db/introduction/","title":"Introduction to Types of Databases","text":"<p>Every company relies on data, making its management essential. Data can be both Structured and Unstructured. Efficient data handling ensures that data is securely stored, accessed, and modified as needed, supporting smooth business operations.</p>"},{"location":"dbms/types_of_db/introduction/#what-is-dbms","title":"What is DBMS?","text":"<p>A Database Management System (DBMS) is software designed to store, organize, and manage data efficiently. It consists of two key components:</p> <ul> <li>The database is a collection of interconnected data.</li> <li>The management system ensures proper handling of data.</li> </ul> <p>DBMS can be classified into two main types</p> <ul> <li>Relational Database Management System <code>(RDBMS)</code></li> <li>Non-Relational Database Management System <code>(NoSQL or Non-SQL)</code></li> </ul>"},{"location":"dbms/types_of_db/introduction/#types-of-databases","title":"Types of Databases","text":"<p>There are several types of databases :-</p> <ul> <li>Relational databases</li> <li>Object-oriented databases</li> <li>NoSQL databases</li> <li>Hierarchical databases</li> <li>Network databases</li> <li>Cloud Database</li> <li>Centralized Database  etc...</li> </ul>"},{"location":"dbms/types_of_db/db_types/centralized/","title":"Centralized Databases","text":""},{"location":"dbms/types_of_db/db_types/centralized/#centralized-databases_1","title":"Centralized Databases","text":"<p>A centralized database is a type of database that is stored, located as well as maintained at a single location and it is more secure when the user wants to fetch the data from the Centralized Database.</p> <p>Advantages</p> <ul> <li>Data Security</li> <li>Reduced Redundancy</li> <li>Consistency</li> </ul> <p>Disadvantages</p> <ul> <li>The size of the centralized database is large which increases the response and retrieval time.</li> <li>It is not easy to modify, delete and update.</li> </ul>"},{"location":"dbms/types_of_db/db_types/cloud/","title":"Cloud Databases","text":""},{"location":"dbms/types_of_db/db_types/cloud/#cloud-databases_1","title":"Cloud Databases","text":"<p>A cloud database is used where data requires a virtual environment for storing and executing over the cloud platforms and there are so many cloud computing services for accessing the data from the databases (like SaaS, Paas, etc).</p> <p>There are some names of cloud platforms are :-</p> <ul> <li>Amazon Web Services (AWS)</li> <li>Google Cloud Platform (GCP)</li> <li>Microsoft Azure</li> <li>ScienceSoft, etc.</li> </ul>"},{"location":"dbms/types_of_db/db_types/hierarchical/","title":"Hierarchical Databases","text":""},{"location":"dbms/types_of_db/db_types/hierarchical/#hierarchical-databases_1","title":"Hierarchical Databases","text":"<ul> <li>As the name suggests, the hierarchical database model is most appropriate for use cases in which the main focus of information gathering is based on a concrete hierarchy, such as several individual employees reporting to a single department at a company.</li> <li>The schema for hierarchical databases is defined by its tree-like organization, in which there is typically a root \u201cparent\u201d directory of data stored as records that links to various other subdirectory branches, and each subdirectory branch, or child record, may link to various other subdirectory branches.</li> <li>The hierarchical database structure dictates that, while a parent record can have several child records, each child record can only have one parent record. Data within records is stored in the form of fields, and each field can only contain one value. Retrieving hierarchical data from a hierarchical database architecture requires traversing the entire tree, starting at the root node.</li> <li>Since the disk storage system is also inherently a hierarchical structure, these models can also be used as physical models.</li> <li>The key advantage of a hierarchical database is its ease of use. The one-to-many organization of data makes traversing the database simple and fast, which is ideal for use cases such as website drop-down menus or computer folders in systems like Microsoft Windows OS. Due to the separation of the tables from physical storage structures, information can easily be added or deleted without affecting the entirety of the database. And most major programming languages offer functionality for reading tree structure databases.</li> <li>The major disadvantage of hierarchical databases is their inflexible nature. The one-to-many structure is not ideal for complex structures as it cannot describe relationships in which each child node has multiple parents nodes. Also the tree-like organization of data requires top-to-bottom sequential searching, which is time consuming, and requires repetitive storage of data in multiple different entities, which can be redundant.</li> <li>e.g., IBM IMS.</li> </ul>"},{"location":"dbms/types_of_db/db_types/network/","title":"Network Databases","text":""},{"location":"dbms/types_of_db/db_types/network/#network-databases_1","title":"Network Databases","text":"<ul> <li>Extension of Hierarchical databases</li> <li>The child records are given the freedom to associate with multiple parent records.</li> <li>Organized in a Graph structure.</li> <li>Can handle complex relations.</li> <li>Maintenance is tedious.</li> <li>M:N links may cause slow retrieval.</li> <li>Not much web community support.</li> <li>e.g., Integrated Data Store (IDS), IDMS (Integrated Database Management System), Raima Database Manager, TurboIMAGE etc.</li> </ul>"},{"location":"dbms/types_of_db/db_types/no_sql/","title":"NoSQL Databases","text":""},{"location":"dbms/types_of_db/db_types/no_sql/#nosql-databases_1","title":"NoSQL Databases","text":"<ol> <li>NoSQL databases (aka \"not only SQL\") are non-tabular databases and store data differently than relational tables. NoSQL databases come in a variety of types based on their data model. The main types are document, key-value, wide-column, and graph. They provide flexible schemas and scale easily with large amounts of data and high user loads.</li> <li>They are schema free.</li> <li>Data structures used are not tabular, they are more flexible, has the ability to adjust dynamically.</li> <li>Can handle huge amount of data (big data).</li> <li>Most of the NoSQL are open sources and has the capability of horizontal scaling.</li> <li>It just stores data in some format other than relational.</li> </ol>"},{"location":"dbms/types_of_db/db_types/object_oriented/","title":"Object Oriented Databases","text":""},{"location":"dbms/types_of_db/db_types/object_oriented/#object-oriented-databases_1","title":"Object Oriented Databases","text":"<ol> <li>The object-oriented data model, is based on the object-oriented-programming paradigm, which is now in wide use. Inheritance, object-identity, and encapsulation (information hiding), with methods to provide an interface to objects, are among the key concepts of object-oriented programming that have found applications in data modelling. The object-oriented data model also supports a rich type system, including structured and collection types. While inheritance and, to some extent, complex types are also present in the E-R model, encapsulation and object-identity distinguish the object-oriented data model from the E-R model.</li> <li>Sometimes the database can be very complex, having multiple relations. So, maintaining a relationship between them can be tedious at times.<ul> <li>In Object-oriented databases data is treated as an object.</li> <li>All bits of information come in one instantly available object package instead of multiple tables.</li> </ul> </li> </ol> <p>Advantages</p> <ul> <li>Data storage and retrieval is easy and quick.</li> <li>Can handle complex data relations and more variety of data types that standard relational databases.</li> <li>Relatively friendly to model the advance real world problems</li> <li>Works with functionality of OOPs and Object Oriented languages.</li> </ul> <p>Disadvantages</p> <ul> <li>High complexity causes performance issues like read, write, update and delete operations are slowed down.</li> <li>Not much of a community support as isn\u2019t widely adopted as relational databases.</li> <li>Does not support views like relational databases.</li> <li>e.g., <code>ObjectDB</code>, <code>GemStone</code> etc.</li> </ul>"},{"location":"dbms/types_of_db/db_types/relational/","title":"Relational Databases","text":""},{"location":"dbms/types_of_db/db_types/relational/#relational-databases_1","title":"Relational Databases","text":"<ol> <li>Based on Relational Model.</li> <li>Relational databases are quite popular, even though it was a system designed in the 1970s. Also known as relational database management systems (RDBMS), relational databases commonly use Structured Query Language (SQL) for operations such as creating, reading, updating, and deleting data. Relational databases store information in discrete tables, which can be JOINed together by fields known as foreign keys. For example, you might have a User table which contains information about all your users, and join it to a Purchases table, which contains information about all the purchases they\u2019ve made.</li> <li><code>MySQL</code>, <code>Microsoft SQL Server</code>, and <code>Oracle</code> are types of relational databases.</li> <li>they are ubiquitous, having acquired a steady user base since the 1970s</li> <li>they are highly optimized for working with structured data.</li> <li>they provide a stronger guarantee of data normalization</li> <li>they use a well-known querying language through SQL</li> <li>Scalability issues (Horizontal Scaling).</li> <li>Data become huge, system become more complex.</li> </ol>"},{"location":"dsa/","title":"Welcome to DSA","text":"<p>Data Structures and Algorithms (DSA) is a fundamental part of Computer Science that teaches you how to think and solve complex problems systematically.</p> <p></p>"},{"location":"dsa/Heaps_PriorityQueues/","title":"Heaps/Priority Queues","text":""},{"location":"dsa/Heaps_PriorityQueues/#contents","title":"Contents","text":""},{"location":"dsa/Heaps_PriorityQueues/heap_sort/","title":"Heap Sort","text":""},{"location":"dsa/Heaps_PriorityQueues/heap_sort/#heap-sort-data-structures","title":"Heap Sort \u2013 Data Structures","text":"<p>Heap sort is a comparison-based sorting technique based on Binary Heap data structure. It is similar to the selection sort where we first find the minimum element and place the minimum element at the beginning. Repeat the same process for the remaining elements.</p>"},{"location":"dsa/Heaps_PriorityQueues/heap_sort/#heap-sort-algorithm","title":"Heap Sort Algorithm","text":"<ul> <li>Build a heap from the given input array.</li> <li>Repeat the following steps until the heap contains only one element:<ul> <li>Swap the root element of the heap (which is the largest element) with the last element of the heap.</li> <li>Remove the last element of the heap (which is now in the correct position).</li> <li>Heapify the remaining elements of the heap.</li> </ul> </li> <li>The sorted array is obtained by reversing the order of the elements in the input array.</li> </ul>"},{"location":"dsa/Heaps_PriorityQueues/heap_sort/#code","title":"Code","text":"<pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nvoid heapify(int arr[], int N, int i){\n\n    // Initialize largest as root\n    int largest = i;\n\n    // left = 2*i + 1\n    int l = 2 * i + 1;\n\n    // right = 2*i + 2\n    int r = 2 * i + 2;\n\n    // If left child is larger than root\n    if (l &lt; N &amp;&amp; arr[l] &gt; arr[largest])\n        largest = l;\n\n    // If right child is larger than largest\n    if (r &lt; N &amp;&amp; arr[r] &gt; arr[largest])\n        largest = r;\n\n    // If largest is not root\n    if (largest != i){\n        swap(arr[i], arr[largest]);\n\n        // Recursively heapify the affected sub-tree\n        heapify(arr, N, largest);\n    }\n}\n\nvoid heapSort(int arr[], int N){\n\n    // Build heap (rearrange array)\n    for (int i = N / 2 - 1; i &gt;= 0; i--){\n        heapify(arr, N, i);\n    }\n\n    for (int i = N - 1; i &gt; 0; i--){\n        swap(arr[i],arr[0]);\n        heapify(arr, i, 0);\n    }\n\n}\n\nvoid printArray(int arr[], int N){\n    for (int i = 0; i &lt; N; ++i)\n        cout &lt;&lt; arr[i] &lt;&lt; \" \";\n    cout &lt;&lt; endl;\n}\n\nint main(){\n\n    int arr[] = { 12, 11, 13, 5, 6, 7 };\n    int N = 6;\n\n    heapSort(arr, N);\n\n    cout &lt;&lt; \"Sorted array is \\n\";\n    printArray(arr, N);\n}\n</code></pre>"},{"location":"dsa/Heaps_PriorityQueues/introduction/","title":"Introduction to Heaps/Priority Queues","text":""},{"location":"dsa/Heaps_PriorityQueues/introduction/#what-is-heap-data-structure","title":"What is Heap Data Structure?","text":"<p>A Heap is a complete binary tree data structure that satisfies the heap property: for every node, the value of its children is less than or equal to its own value.\\</p> <p>Heaps are usually used to implement priority queues, where the smallest (or largest) element is always at the root of the tree.</p> <p></p>"},{"location":"dsa/Heaps_PriorityQueues/introduction/#types-of-heaps","title":"Types of Heaps","text":"<p>There are two main types of heaps:</p> <ul> <li>Max Heap: The root node contains the maximum value, and the values decrease as you move down the tree.</li> <li>Min Heap: The root node contains the minimum value, and the values increase as you move down the tree.</li> </ul>"},{"location":"dsa/Heaps_PriorityQueues/introduction/#heap-data-structure-applications","title":"Heap Data Structure Applications","text":"<p>Heaps have various applications, like:</p> <ul> <li>Heaps are commonly used to implement priority queues, where elements are retrieved based on their priority (maximum or minimum value).</li> <li>Heapsort is a sorting algorithm that uses a heap to sort an array in ascending or descending order.</li> <li>Heaps are used in graph algorithms like Dijkstra\u2019s algorithm and Prim\u2019s algorithm for finding the shortest paths and minimum spanning trees.</li> </ul>"},{"location":"dsa/Heaps_PriorityQueues/introduction/#operations-supported-by-heap","title":"Operations Supported by Heap:","text":"<p>Operations supported by min \u2013 heap and max \u2013 heap are same. The difference is just that min-heap contains minimum element at root of the tree and max \u2013 heap contains maximum element at the root of the tree.</p>"},{"location":"dsa/Heaps_PriorityQueues/introduction/#heapify","title":"Heapify:","text":"<p>It is the process to rearrange the elements to maintain the property of heap data structure. It is done when a certain node creates an imbalance in the heap due to some operations on that node. It takes O(log N) to balance the tree. </p> <ul> <li>For max-heap, it balances in such a way that the maximum element is the root of that binary tree and </li> <li>For min-heap, it balances in such a way that the minimum element is the root of that binary tree.</li> </ul>"},{"location":"dsa/Heaps_PriorityQueues/introduction/#insertion","title":"Insertion:","text":"<p>If we insert a new element into the heap since we are adding a new element into the heap so it will distort the properties of the heap so we need to perform the heapify operation so that it maintains the property of the heap.</p> <p>This operation also takes O(logN) time.</p> <p></p> Insertion code for max-heap <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nclass Heap{\n    public:\n\n    int arr[100];\n    int size = 0;\n\n    Heap(){\n        arr[0] = -1;\n    }\n\n    void insert(int val){\n\n        size++;\n        int index = size;\n        arr[index] = val;\n\n        while(index &gt; 1){\n            int parent = index/2;\n            if(arr[parent] &lt; arr[index]){\n                swap(arr[parent],arr[index]);\n                index = parent;\n            }\n            else{\n                return;\n            }\n        }\n    }\n\n    void print(){\n        for(int i = 1 ; i &lt;= size ; i++){\n            cout&lt;&lt;arr[i]&lt;&lt;\" \";\n        }\n        cout&lt;&lt;endl;\n    }\n\n};\n\nint main(){\n\n    Heap h;\n\n    h.insert(8);\n    h.insert(4);\n    h.insert(5);\n    h.insert(1);\n    h.insert(2);\n    h.insert(10);\n\n    h.print();\n\n}\n</code></pre>"},{"location":"dsa/Heaps_PriorityQueues/introduction/#deletion","title":"Deletion:","text":"<p>If we delete the element from the heap it always deletes the root element of the tree and replaces it with the last element of the tree.</p> <p>Since we delete the root element from the heap it will distort the properties of the heap so we need to perform heapify operations so that it maintains the property of the heap. </p> <p>It takes O(logN) time.</p> <p></p> Deletion code for max-heap <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nclass Heap{\n    public:\n\n    int arr[100];\n    int size;\n\n    Heap(){\n        arr[0] = -1;\n        size = 0;\n    }\n\n    void insert(int val){\n\n        size++;\n        int index = size;\n        arr[index] = val;\n\n        while(index &gt; 1){\n            int parent = index/2;\n            if(arr[parent] &lt; arr[index]){\n                swap(arr[parent],arr[index]);\n                index = parent;\n            }\n            else{\n                return;\n            }\n        }\n    }\n\n    void deletion(){\n        if(size == 0){\n            cout&lt;&lt;\"Nothing to delete...\"&lt;&lt;endl;\n            return;\n        }\n\n        swap(arr[size],arr[1]);\n        size--;\n\n        int idx = 1;\n        while(idx &lt; size){\n            int leftIdx = 2*idx;\n            int rightIdx = 2*idx+1;\n            if(leftIdx &lt; size &amp;&amp; arr[idx] &lt; arr[leftIdx]){\n                swap(arr[idx],arr[leftIdx]);\n                idx = leftIdx;\n            }\n            else if(rightIdx &lt; size &amp;&amp; arr[idx] &lt; arr[rightIdx]){\n                swap(arr[idx],arr[rightIdx]);\n                idx = rightIdx;\n            }\n            else{\n                return;\n            }\n        }\n    }\n\n    void print(){\n        for(int i = 1 ; i &lt;= size ; i++){\n            cout&lt;&lt;arr[i]&lt;&lt;\" \";\n        }\n        cout&lt;&lt;endl;\n    }\n\n};\n\nint main(){\n\n    Heap h;\n\n    h.insert(15);\n    h.insert(5);\n    h.insert(7);\n    h.insert(2);\n    h.insert(3);\n\n    h.deletion();\n\n    h.print();\n\n}\n</code></pre>"},{"location":"dsa/Heaps_PriorityQueues/introduction/#getmax-for-max-heap-or-getmin-for-min-heap","title":"getMax (For max-heap) or getMin (For min-heap):","text":"<p>It finds the maximum element or minimum element for max-heap and min-heap respectively and as we know minimum and maximum elements will always be the root node itself for min-heap and max-heap respectively. It takes O(1) time.</p>"},{"location":"dsa/Heaps_PriorityQueues/priority_queue/","title":"Priority Queue","text":""},{"location":"dsa/Heaps_PriorityQueues/priority_queue/#priority-queue-in-c-standard-template-library-stl","title":"Priority Queue in C++ Standard Template Library (STL)","text":"<p>A C++ priority queue is a type of container adapter, specifically designed such that the first element of the queue is either the greatest or the smallest of all elements in the queue, and elements are in non-increasing or non-decreasing order (hence we can see that each element of the queue has a priority {fixed order}).</p>"},{"location":"dsa/Heaps_PriorityQueues/priority_queue/#how-to-create-a-max-heap-for-the-priority-queue","title":"How to create a max heap for the priority queue?","text":"<pre><code>priority_queue&lt;int&gt; pq;\n</code></pre>"},{"location":"dsa/Heaps_PriorityQueues/priority_queue/#how-to-create-a-min-heap-for-the-priority-queue","title":"How to create a min heap for the priority queue?","text":"<pre><code>priority_queue &lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; pq;\n</code></pre>"},{"location":"dsa/Heaps_PriorityQueues/priority_queue/#operations-on-priority-queue-with-complexities","title":"Operations on Priority Queue With Complexities","text":""},{"location":"dsa/Heaps_PriorityQueues/question/","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Convert Min Heap to Max Heap <ul> <li>Convert Min Heap to Max Heap (gfg)</li> </ul> <pre><code>class Solution{\n    public:\n    void heapify(vector&lt;int&gt; &amp;arr , int N , int i){\n\n        int large = i;\n        int left = 2*i+1;\n        int right = 2*i+2;\n\n        if(left &lt; N &amp;&amp; arr[left] &gt; arr[large]){\n            large = left;\n        }\n        if(right &lt; N &amp;&amp; arr[right] &gt; arr[large]){\n            large = right;\n        }\n\n        if(large != i){\n            swap(arr[large],arr[i]);\n            heapify(arr,N,large);\n        }\n    }\n\n    void convertMinToMaxHeap(vector&lt;int&gt; &amp;arr, int N){\n\n        for(int i = N/2-1 ; i &gt;= 0 ; i--){\n            heapify(arr,N,i);\n        }\n\n    }\n\n};\n</code></pre> Task Scheduler <ul> <li>Task Scheduler (leetcode)</li> </ul> <pre><code>class Solution {\n    public:\n    int leastInterval(vector&lt;char&gt;&amp; tasks, int n) {\n\n        map&lt;char,int&gt; mp;\n        for(auto it : tasks){\n            mp[it]++;\n        }\n\n        priority_queue&lt;int&gt; pq;\n        for(auto it : mp){\n            pq.push(it.second);\n        }\n\n        int ans = 0;\n        while(!pq.empty()){\n\n            vector&lt;int&gt; rem;\n            for(int i = 1 ; i &lt;= n+1 ; i++){\n                if(!pq.empty()){\n                    rem.push_back(pq.top()-1);\n                    pq.pop();\n                }\n            }\n\n            for(auto it : rem){\n                if(it &gt; 0){\n                    pq.push(it);\n                }\n            }\n\n            if(pq.empty()){\n                // only zeros are present in the \"rem\" vector.\n                ans += rem.size();\n            }\n            else{\n                ans += n+1;\n            }\n        }\n        return ans;\n    }\n};\n</code></pre> Maximum Sum Combinations <ul> <li>Task Scheduler (interviewbit)</li> </ul> <p>Bruteforce</p> <pre><code>vector&lt;int&gt; Solution::solve(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B, int C) {\n\n    priority_queue&lt;int&gt; pq;\n    vector&lt;int&gt; ans;\n    int n = A.size();\n    int m = B.size();\n\n    for(int i = 0 ; i &lt; n ; i++){\n\n        for(int j = 0 ; j &lt; m ; j++){\n            int sum = A[i]+B[j];\n            pq.push(sum);\n        }\n    }\n\n    while(C &gt; 0){\n        ans.push_back(pq.top());\n        pq.pop();\n        C--;\n    }\n\n    return ans;\n}\n</code></pre> <p>Optimal</p> <pre><code>vector&lt;int&gt; Solution::solve(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B, int C) {\n\n    priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; pq;\n    sort(A.begin(), A.end(), greater&lt;int&gt;());\n    sort(B.begin(), B.end(), greater&lt;int&gt;());\n    int N = A.size();\n\n    for(int i=0; i&lt;C; i++){\n        pq.push(A[i] + B[i]);\n    }\n\n    vector&lt;int&gt; ans(C);\n    for(int i=0; i&lt;N; i++){\n        for(int j=0; j&lt;N; j++){\n            if(i==j)\n                continue;\n            if(A[i] + B[j] &gt; pq.top())\n            {\n                pq.pop();\n                pq.push(A[i] + B[j]);\n            }\n            else\n                break;\n        }\n    }\n    for(int i=C-1; i&gt;=0; i--){\n        ans[i] = pq.top();\n        pq.pop();\n    }\n    return ans;\n}\n</code></pre> Design Twitter <ul> <li>Design Twitter (leetcode)</li> </ul> <pre><code>class Twitter {\npublic:\n\n    map&lt;int,set&lt;int&gt;&gt; friends;\n    priority_queue&lt;vector&lt;int&gt;&gt; tweets;\n    int cnt = 0;\n\n    Twitter() {\n\n    }\n\n    void postTweet(int userId, int tweetId) {\n        tweets.push({cnt++,tweetId,userId});\n    }\n\n    vector&lt;int&gt; getNewsFeed(int userId) {\n        vector&lt;int&gt;ans;\n        priority_queue&lt;vector&lt;int&gt;&gt;userFeed = tweets;\n        int n = 0;\n        while(!userFeed.empty() &amp;&amp; n &lt; 10){\n            auto topTweet = userFeed.top(); // tweetId, userId\n            userFeed.pop();\n            if(topTweet[2] == userId || friends[userId].count(topTweet[2])){\n                ans.push_back(topTweet[1]);\n                n++;\n            }\n        }\n        return ans;\n    }\n\n    void follow(int followerId, int followeeId) {\n        friends[followerId].insert(followeeId);\n    }\n\n    void unfollow(int followerId, int followeeId) {\n        friends[followerId].erase(followeeId);\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/Heaps_PriorityQueues/question/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Does array represent Heap (gfg)</p> </li> <li> <p>Kth Largest Element in an Array (leetcode)</p> </li> <li> <p>Kth Smallest (gfg)</p> </li> <li> <p>Merge k Sorted Arrays (gfg)</p> </li> <li> <p>Merge k Sorted Lists (leetcode)</p> </li> <li> <p>Replace elements by its rank in the array (gfg)</p> </li> <li> <p>Hand of Straights (leetcode)</p> </li> <li> <p>Kth Largest Element in a Stream (leetcode)</p> </li> <li> <p>Top K Frequent Elements (leetcode)</p> </li> <li> <p>Find Median from Data Stream (leetcode)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/binary_search/","title":"Binary Search","text":""},{"location":"dsa/binary_search/#contents","title":"Contents","text":""},{"location":"dsa/binary_search/introduction/","title":"Introduction to Binary Search","text":""},{"location":"dsa/binary_search/introduction/#what-is-binary-search-algorithm","title":"What is Binary Search Algorithm?","text":"<p>Binary search is a search algorithm used to find the position of a target value within a sorted array. It works by repeatedly dividing the search interval in half until the target value is found or the interval is empty. The search interval is halved by comparing the target element with the middle value of the search space.</p> <p></p>"},{"location":"dsa/binary_search/introduction/#conditions-to-apply-binary-search-algorithm","title":"Conditions to apply Binary Search Algorithm :","text":"<ul> <li>The data structure must be sorted.</li> <li>Access to any element of the data structure takes constant time.</li> </ul>"},{"location":"dsa/binary_search/introduction/#how-to-implement-binary-search-algorithm","title":"How to Implement Binary Search Algorithm?","text":"<p>The Binary Search Algorithm can be implemented in the following two ways</p> <ul> <li>Iterative Binary Search Algorithm</li> <li>Recursive Binary Search Algorithm</li> </ul>"},{"location":"dsa/binary_search/introduction/#iterative-binary-search-algorithm","title":"Iterative Binary Search Algorithm","text":"<pre><code>int binarySearch(int arr[], int low, int high, int target){\n\n    while (low &lt;= high) {\n\n        int mid = low + (high - low) / 2;\n\n        // Check if target is present at mid\n        if (arr[mid] == target)\n            return mid;\n\n        // If target greater, ignore left half\n        if (arr[mid] &lt; target)\n            low = mid + 1;\n\n        // If target is smaller, ignore right half\n        else\n            high = mid - 1;\n    }\n\n    // If we reach here, then element was not present\n    return -1;\n}\n</code></pre>"},{"location":"dsa/binary_search/introduction/#recursive-binary-search-algorithm","title":"Recursive Binary Search Algorithm","text":"<pre><code>int binarySearch(int arr[], int low, int high, int target){\n\n    //Base case\n    if (low &gt; high) return -1;\n\n    // Perform the steps\n    int mid = (low + high) / 2;\n\n    if (arr[mid] == target){\n        return mid;\n    }\n    else if (target &gt; arr[mid])\n        return binarySearch(arr, mid + 1, high, target);\n\n    return binarySearch(arr, low, mid - 1, target);\n\n}\n</code></pre>"},{"location":"dsa/binary_search/introduction/#time-complexity","title":"Time Complexity","text":"<ul> <li>Best Case :- O(1)</li> <li>Average Case :- O(log N)</li> <li>Worst Case :- O(log N)</li> </ul>"},{"location":"dsa/binary_search/introduction/#space-complexity","title":"Space Complexity","text":"<ul> <li>Auxiliary Space :- O(1)</li> </ul>"},{"location":"dsa/binary_search/categorize_bs/bs_on_1d_array/","title":"Binary Search On 1D Arrays","text":""},{"location":"dsa/binary_search/categorize_bs/bs_on_1d_array/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> <ul> <li>Both Lower Bound and Upper Bound is very important. \ud83e\udd47 \ud83e\udd47</li> </ul> Implement Lower Bound <p>What is Lower Bound?</p> <ul> <li> <p>The lower bound algorithm finds the first or the smallest index in a sorted array where the value at that index is greater than or equal to a given key i.e. x.</p> </li> <li> <p>The lower bound is the smallest index, ind, where arr[ind] &gt;= x. But if any such index is not found, the lower bound algorithm returns n i.e. size of the given array.</p> </li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nint lowerBound(vector&lt;int&gt; arr, int n, int x) {\n    int low = 0, high = n - 1;\n    int ans = n;\n\n    while (low &lt;= high) {\n        int mid = (low + high) / 2;\n        // maybe an answer\n        if (arr[mid] &gt;= x) {\n            ans = mid;\n            //look for smaller index on the left\n            high = mid - 1;\n        }\n        else {\n            low = mid + 1; // look on the right\n        }\n    }\n    return ans;\n}\n\nint main(){\n\n    vector&lt;int&gt; arr = {3, 5, 8, 15, 19};\n    int n = 5, x = 9;\n    int ind = lowerBound(arr, n, x);\n    cout &lt;&lt; \"The lower bound is the index: \" &lt;&lt; ind &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre> Implement Upper Bound <p>What is Upper Bound?</p> <ul> <li> <p>The upper bound algorithm finds the first or the smallest index in a sorted array where the value at that index is greater than the given key i.e. x.</p> </li> <li> <p>The upper bound is the smallest index, where arr[ind] &gt; x.</p> </li> <li> <p>But if any such index is not found, the upper bound algorithm returns n i.e. size of the given array. The main difference between the lower and upper bound is in the condition. For the lower bound the condition was arr[ind] &gt;= x and here, in the case of the upper bound, it is arr[ind] &gt; x.</p> </li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nint upperBound(vector&lt;int&gt; &amp;arr, int x, int n) {\n    int low = 0, high = n - 1;\n    int ans = n;\n\n    while (low &lt;= high) {\n        int mid = (low + high) / 2;\n        // maybe an answer\n        if (arr[mid] &gt; x) {\n            ans = mid;\n            //look for smaller index on the left\n            high = mid - 1;\n        }\n        else {\n            low = mid + 1; // look on the right\n        }\n    }\n    return ans;\n}\n\nint main(){\n\n    vector&lt;int&gt; arr = {3, 5, 8, 9, 15, 19};\n    int n = 6, x = 9;\n    int ind = upperBound(arr, x, n);\n    cout &lt;&lt; \"The upper bound is the index: \" &lt;&lt; ind &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre> Single Element in a Sorted Array <ul> <li>Single Element in a Sorted Array (leetcode)</li> </ul> <p>Resolving edge cases:</p> <ul> <li>If n == 1: This means the array size is 1. If the array contains only one element, we will return that element only.</li> <li>If arr[0] != arr[1]: This means the very first element of the array is the single element. So, we will return arr[0].</li> <li>If arr[n-1] != arr[n-2]: This means the last element of the array is the single element. So, we will return arr[n-1].</li> </ul> <p></p> <ul> <li> <p>By observing the above image, we can clearly notice a striking distinction between the index sequences of the left and right halves of the single element in the array.</p> <ul> <li> <p>The index sequence of the duplicate numbers in the left half is always (even, odd). That means one of the following conditions will be satisfied if we are in the left half.</p> </li> <li> <p>The index sequence of the duplicate numbers in the right half is always (odd, even). That means one of the following conditions will be satisfied if we are in the right half.</p> </li> </ul> </li> <li> <p>Now, we can easily identify the left and right halves, just by checking the sequence of the current index, i, like the following:</p> <ul> <li>If (i % 2 == 0 and arr[i] == arr[i+1]) or (i%2 == 1 and arr[i] == arr[i-1]), we are in the left half.</li> <li>If (i % 2 == 0 and arr[i] == arr[i-1]) or (i%2 == 1 and arr[i] == arr[i+1]), we are in the right half.</li> </ul> </li> <li> <p>Note: In our case, the index i refers to the index \u2018mid\u2019.</p> </li> <li> <p>How to eliminate the halves:</p> <ul> <li> <p>If we are in the left half of the single element, we have to eliminate this left half (i.e. low = mid+1). Because our single element appears somewhere on the right side.</p> </li> <li> <p>If we are in the right half of the single element, we have to eliminate this right half (i.e. high = mid-1). Because our single element appears somewhere on the left side.</p> </li> </ul> </li> <li> <p>Now, we have resolved the problems and we can use the binary search accordingly.</p> </li> </ul> <pre><code>class Solution {\n  public:\n    int singleNonDuplicate(vector&lt;int&gt;&amp; nums) {\n\n        int n = nums.size();\n        if(n == 1){\n            return nums[0];\n        }\n        if(nums[0] != nums[1]){\n            return nums[0];\n        }\n        if(nums[n-1] != nums[n-2]){\n            return nums[n-1];\n        }\n\n        int low = 1;\n        int high = n-2;\n        while(low &lt;= high){\n            int mid = (low + high)/2;\n            if(nums[mid] != nums[mid-1] &amp;&amp; nums[mid] != nums[mid+1]){\n                return nums[mid];\n            }\n            else if(mid%2 == 0 &amp;&amp; nums[mid] == nums[mid+1] || mid%2 == 1 &amp;&amp; nums[mid] == nums[mid-1]){\n                low = mid+1;\n            }\n            else{\n                high = mid-1;\n            }\n        }\n\n        return -1;\n    }\n};\n</code></pre> Find Peak Element <ul> <li>Find Peak Element (leetcode)</li> </ul> <p>What is a peak element?</p> <ul> <li>A peak element in an array refers to the element that is greater than both of its neighbors. Basically, if arr[i] is the peak element, arr[i] &gt; arr[i-1] and arr[i] &gt; arr[i+1].</li> </ul> <p>The steps are as follows:</p> <ul> <li> <p>If n == 1: This means the array size is 1. If the array contains only one element, we will return that index i.e. 0.</p> </li> <li> <p>If arr[0] &gt; arr[1]: This means the very first element of the array is the peak element. So, we will return the index 0.</p> </li> <li> <p>If arr[n-1] &gt; arr[n-2]: This means the last element of the array is the peak element. So, we will return the index n-1.</p> </li> <li> <p>Place the 2 pointers i.e. low and high: Initially, we will place the pointers excluding index 0 and n-1 like this: low will point to index 1, and high will point to index n-2 i.e. the second last index.</p> </li> <li> <p>Calculate the mid: mid = (low+high) / 2</p> </li> <li> <p>Check if arr[mid] is the peak element:</p> <ul> <li> <p>If arr[mid] &gt; arr[mid-1] and arr[mid] &gt; arr[mid+1]: If this condition is true for arr[mid], we can conclude arr[mid] is the peak element. We will return the index mid.</p> </li> <li> <p>If arr[mid] &gt; arr[mid-1]: This means we are in the left half and we should eliminate it as our peak element appears on the right. So, we will do this :- low = mid+1.</p> </li> <li> <p>Otherwise, we are in the right half and we should eliminate it as our peak element appears on the left. So, we will do this :- high = mid-1.</p> </li> </ul> </li> </ul> <pre><code>class Solution {\n   public:\n    int findPeakElement(vector&lt;int&gt;&amp; nums) {\n\n        int n = nums.size();\n        if(n == 1){\n            return 0;\n        }\n        if(nums[0] &gt; nums[1]){\n            return 0;\n        }\n        if(nums[n-1] &gt; nums[n-2]){\n            return n-1;\n        }\n\n        int low = 1;\n        int high = n-2;\n        while(low &lt;= high){\n            int mid = (low + high)/2;\n            if(nums[mid] &gt; nums[mid-1] &amp;&amp; nums[mid] &gt; nums[mid+1]){\n                return mid;\n            }\n            else if(nums[mid] &gt; nums[mid-1]){\n                low = mid+1;\n            }\n            else{\n                high = mid-1;\n            }\n        }\n\n        return -1;\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/binary_search/categorize_bs/bs_on_1d_array/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Binary Search (leetcode)</p> </li> <li> <p>Floor in a Sorted Array (gfg)</p> </li> <li> <p>Ceil The Floor (gfg)</p> </li> <li> <p>Search Insert Position (leetcode)</p> </li> <li> <p>Find First and Last Position of Element in Sorted Array (leetcode)</p> </li> <li> <p>Number of occurrence (gfg)</p> </li> </ul> <ul> <li>Search in Rotated Sorted Array (leetcode)</li> </ul> <p>The steps are as follows:</p> <ul> <li> <p>Check if arr[mid] == target :- If it is, return the index mid.</p> </li> <li> <p>Identify the sorted half, check where the target is located, and then eliminate one half accordingly:</p> <ul> <li> <p>If arr[low] &lt;= arr[mid]: This condition ensures that the left part is sorted</p> <ul> <li>If arr[low] &lt;= target &amp;&amp; target &lt;= arr[mid]: It signifies that the target is in this sorted half. So, we will eliminate the right half (high = mid-1).</li> <li>Otherwise, the target does not exist in the sorted half. So, we will eliminate this left half by doing low = mid+1.</li> </ul> </li> <li> <p>Otherwise, if the right half is sorted:</p> <ul> <li>If arr[mid] &lt;= target &amp;&amp; target &lt;= arr[high]: It signifies that the target is in this sorted right half. So, we will eliminate the left half (low = mid+1).</li> <li>Otherwise, the target does not exist in this sorted half. So, we will eliminate this right half by doing high = mid-1.</li> </ul> </li> </ul> </li> </ul> <ul> <li> <p>Search in Rotated Sorted Array II (leetcode)</p> </li> <li> <p>However, in the current problem, the array may contain duplicates. Consequently, the previous approach will not work when arr[low] = arr[mid] = arr[high].</p> </li> <li> <p>Hence in the previous question add check if arr[low] = arr[mid] = arr[high]: If this condition is satisfied, we will just increment the low pointer and decrement the high pointer by one step. We will not perform the later steps until this condition is no longer satisfied. So, we will continue to the next iteration from this step.</p> </li> <li> <p>And rest are as same as previous one.</p> </li> </ul> <ul> <li>Find Minimum in Rotated Sorted Array (leetcode)</li> </ul> <p>The steps are as follows:</p> <ul> <li> <p>Place the 2 pointers i.e. low and high</p> </li> <li> <p>Calculate the mid: mid = (low+high) / 2</p> </li> <li> <p>Identify the sorted half, and after picking the leftmost element, eliminate that half.</p> <ul> <li> <p>If arr[low] &lt;= arr[mid]: This condition ensures that the left part is sorted. So, we will pick the leftmost element i.e. arr[low]. Now, we will compare it with 'ans' and update 'ans' with the smaller value (i.e., min(ans, arr[low])). Now, we will eliminate this left half(i.e. low = mid+1).</p> </li> <li> <p>Otherwise, if the right half is sorted:  This condition ensures that the right half is sorted. So, we will pick the leftmost element i.e. arr[mid]. Now, we will compare it with 'ans' and update 'ans' with the smaller value (i.e., min(ans, arr[mid])). Now, we will eliminate this right half(i.e. high = mid-1).</p> </li> </ul> </li> <li> <p>This process will be inside a loop and the loop will continue until low crosses high. Finally, we will return the \u2018ans\u2019 variable that stores the minimum element.</p> </li> </ul> <ul> <li>Find out how many times has an array been rotated (gfg)</li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/binary_search/categorize_bs/bs_on_2d_array/","title":"Binary Search On 2D Arrays","text":""},{"location":"dsa/binary_search/categorize_bs/bs_on_2d_array/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Row with max 1s <ul> <li>Row with max 1s (gfg)</li> </ul> <pre><code>class Solution{\n    public:\n    int lower_bound(vector&lt;int&gt; &amp;arr , int n , int k){\n\n        int low = 0;\n        int high = n-1;\n        int ans = n;\n        while(low &lt;= high){\n            int mid = (low + high)/2;\n            if(arr[mid] &gt;= k){\n                ans = mid;\n                high = mid-1;\n            }\n            else{\n                low = mid+1;\n            }\n        }\n        return ans;\n    }\n\n    int rowWithMax1s(vector&lt;vector&lt;int&gt; &gt; arr, int n, int m) {\n\n        int ans = -1;\n        int maxi = 0;\n\n        for(int i = 0 ; i &lt; n ; i++){\n\n            int cnt_1 = m - lower_bound(arr[i] , m , 1);\n            if(cnt_1 &gt; maxi){\n                maxi = cnt_1;\n                ans = i;\n            }\n        }\n\n        return ans;\n    }\n\n};\n</code></pre> Find a Peak Element II <ul> <li>Find a Peak Element II (leetcode)</li> </ul> <pre><code>class Solution {\n    public:\n    int solver(vector&lt;vector&lt;int&gt;&gt;&amp; mat , int col){\n        int maxi = 0;\n        int ans = 0;\n        for(int i = 0 ; i &lt; mat.size() ; i++){\n            if(mat[i][col] &gt; maxi){\n                maxi = mat[i][col];\n                ans = i;\n            }\n        }\n        return ans;\n    }\n\n    vector&lt;int&gt; findPeakGrid(vector&lt;vector&lt;int&gt;&gt;&amp; mat) {\n\n        int low = 0;\n        int high = mat[0].size()-1;\n\n        while(low &lt;= high){\n            int mid = (low+high)/2;\n            int max_ele_row = solver(mat , mid);\n            int left = mid-1 &gt;= 0 ? mat[max_ele_row][mid-1] : -1;\n            int right = mid+1 &lt; mat[0].size() ? mat[max_ele_row][mid+1] : -1;\n\n            if(mat[max_ele_row][mid] &gt; left &amp;&amp; mat[max_ele_row][mid] &gt; right){\n                return {max_ele_row,mid};\n            }\n            else if(left &gt; mat[max_ele_row][mid]){\n                high = mid-1;\n            }\n            else{\n                low = mid+1;\n            }\n        }\n        return {-1,-1};\n    }\n};\n</code></pre> Median in a row-wise sorted Matrix <ul> <li>Median in a row-wise sorted Matrix (leetcode)</li> </ul> <ul> <li>For video take a look of take_u_forward channel.</li> </ul> <pre><code>class Solution{\n    public:\n    int upperBound(vector&lt;int&gt; &amp;arr, int x, int n) {\n        int low = 0, high = n - 1;\n        int ans = n;\n\n        while (low &lt;= high) {\n            int mid = (low + high) / 2;\n            if (arr[mid] &gt; x) {\n                ans = mid;\n                high = mid - 1;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        return ans;\n    }\n\n    int countSmallEqual(vector&lt;vector&lt;int&gt;&gt; &amp;matrix, int m, int n, int x) {\n        int cnt = 0;\n        for (int i = 0; i &lt; n; i++) {\n            cnt += upperBound(matrix[i], x, m);\n        }\n        return cnt;\n    }\n\n    int median(vector&lt;vector&lt;int&gt;&gt; &amp;matrix, int R, int C){\n\n        int low = INT_MAX, high = INT_MIN;\n        int m = matrix[0].size();\n        int n = matrix.size();\n\n        for (int i = 0; i &lt; n; i++) {\n            low = min(low, matrix[i][0]);\n            high = max(high, matrix[i][m - 1]);\n        }\n\n        int req = (n * m) / 2;\n        while (low &lt;= high) {\n            int mid = (low + high) / 2;\n            int smallEqual = countSmallEqual(matrix, m, n, mid);\n            if (smallEqual &lt;= req) low = mid + 1;\n            else high = mid - 1;\n        }\n        return low;\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/binary_search/categorize_bs/bs_on_2d_array/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Search a 2D Matrix (leetcode)</p> </li> <li> <p>Search a 2D Matrix II (leetcode)</p> </li> <li> <p>Median in a row-wise sorted Matrix (gfg)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/binary_search/categorize_bs/bs_on_answers/","title":"Binary Search On Answers","text":""},{"location":"dsa/binary_search/categorize_bs/bs_on_answers/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Find square root of a number in log n <ul> <li>Find square root of a number in log n (gfg)</li> </ul> <p>Always Remember \ud83e\udd47</p> <ul> <li> <p>The primary objective of the Binary Search algorithm is to efficiently determine the appropriate half to eliminate, thereby reducing the search space by half. It does this by determining a specific condition that ensures that the target is not present in that half.</p> </li> <li> <p>Now, we are not given any sorted array on which we can apply binary search. But, if we observe closely, we can notice that our answer space i.e. [1, n] is sorted. So, we will apply binary search on the answer space.</p> </li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nlong long int floorSqrt(long long int x){\n\n    long long ans = 1;\n    long long low = 1;\n    long long high = x;\n    while(low &lt;= high){\n\n        long long mid = (low + high)/2;\n\n        if(mid*mid &lt;= x){\n            ans = mid;\n            low = mid+1;\n        }\n        else{\n            high = mid-1;\n        }\n    }\n\n    return ans;\n}\n</code></pre> Aggressive cows <ul> <li>Aggressive cows </li> </ul> <p>Algorithm:</p> <ul> <li> <p>First, we will sort the given stalls[] array.</p> </li> <li> <p>Place the 2 pointers i.e. low and high: Initially, we will place the pointers. The pointer low will point to 1 and the high will point to (stalls[n-1]-stalls[0]). As the \u2018stalls[]\u2019 is sorted, \u2018stalls[n-1]\u2019 refers to the maximum, and \u2018stalls[0]\u2019 is the minimum element.</p> </li> <li> <p>Calculate the \u2018mid\u2019: mid = (low+high) / 2 </p> </li> <li> <p>Eliminate the halves based on the boolean value returned by canWePlace(): We will pass the potential distance, represented by the variable 'mid', to the \u2018canWePlace()' function. This function will return true if it is possible to place all the cows with a minimum distance of \u2018mid\u2019.</p> <ul> <li> <p>If the returned value is true: On satisfying this condition, we can conclude that the number \u2018mid\u2019 is one of our possible answers. But we want the maximum number. So, we will eliminate the left half and consider the right half(i.e. low = mid+1).</p> </li> <li> <p>Otherwise, the value mid is greater than the distance we want. This means the numbers greater than \u2018mid\u2019 should not be considered and the right half of \u2018mid\u2019 consists of such numbers. So, we will eliminate the right half and consider the left half(i.e. high = mid-1).</p> </li> </ul> </li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nbool canWePlace(vector&lt;int&gt; &amp;stalls, int dist, int cows){\n    int n = stalls.size(); //size of array\n    int cntCows = 1; //no. of cows placed\n    int last = stalls[0]; //position of last placed cow.\n    for (int i = 1; i &lt; n; i++) {\n        if (stalls[i] - last &gt;= dist) {\n            cntCows++; //place next cow.\n            last = stalls[i]; //update the last location.\n        }\n        if (cntCows &gt;= cows) return true;\n    }\n    return false;\n}\nint aggressiveCows(vector&lt;int&gt; &amp;stalls, int k){\n    int n = stalls.size(); //size of array\n    //sort the stalls[]:\n    sort(stalls.begin(), stalls.end());\n\n    int low = 1, high = stalls[n - 1] - stalls[0];\n    int ans = 0;\n    //apply binary search:\n    while (low &lt;= high) {\n        int mid = (low + high) / 2;\n        if (canWePlace(stalls, mid, k) == true) {\n            ans = mid;\n            low = mid + 1;\n        }\n        else high = mid - 1;\n    }\n    return ans;\n}\n\nint main(){\n\n    vector&lt;int&gt; stalls = {0, 3, 4, 7, 10, 9};\n    int k = 4;\n    int ans = aggressiveCows(stalls, k);\n    cout &lt;&lt; \"The maximum possible minimum distance is: \" &lt;&lt; ans &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre> Book Allocation Problem <ul> <li> <p>Book Allocation Problem (Code 360)</p> </li> <li> <p>Split Array Largest Sum (leetcode)</p> </li> <li> <p> Painter's Partition Problem (Code 360)</p> </li> </ul> <p>Algorithm:</p> <ul> <li> <p>If m &gt; n: In this case, book allocation is not possible and so, we will return -1.</p> </li> <li> <p>Place the 2 pointers i.e. low and high: Initially, we will place the pointers. The pointer low will point to max(arr[]) and the high will point to sum(arr[]).</p> </li> <li> <p>Calculate the \u2018mid\u2019: mid = (low+high) / 2</p> </li> <li> <p>Eliminate the halves based on the number of students returned by countStudents(): We will pass the potential number of pages, represented by the variable 'mid', to the \u2018countStudents()' function. This function will return the number of students to whom we can allocate the books.</p> <ul> <li> <p>If students &gt; m: On satisfying this condition, we can conclude that the number \u2018mid\u2019 is smaller than our answer. So, we will eliminate the left half and consider the right half(i.e. low = mid+1).</p> </li> <li> <p>Otherwise, the value mid is one of the possible answers. But we want the minimum value. So, we will eliminate the right half and consider the left half(i.e. high = mid-1).</p> </li> </ul> </li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nbool countStudents(vector&lt;int&gt; &amp;arr, int pages , int m) {\n    int n = arr.size(); //size of array.\n    int students = 1;\n    long long sum = 0;\n    for (int i = 0; i &lt; n; i++) {\n        sum += arr[i];\n        if(sum &gt; pages){\n            students++;\n            sum = arr[i];\n        }\n    }\n\n    if(students &gt; m){\n        return true;\n    }\n    return false;\n}\n\nint findPages(vector&lt;int&gt;&amp; arr, int n, int m) {\n    //book allocation impossible:\n    if (m &gt; n) return -1;\n\n    int low = *max_element(arr.begin(), arr.end());\n    int high = accumulate(arr.begin(), arr.end(), 0);\n\n    while (low &lt;= high) {\n        int mid = (low + high) / 2;\n        if (countStudents(arr, mid , m) == true) {\n            low = mid + 1;\n        }\n        else {\n            high = mid - 1;\n        }\n    }\n    return low;\n}\n\nint main(){\n\n    vector&lt;int&gt; arr = {25, 46, 28, 49, 24};\n    int n = 5;\n    int m = 4;\n    int ans = findPages(arr, n, m);\n    cout &lt;&lt; \"The answer is: \" &lt;&lt; ans &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/binary_search/categorize_bs/bs_on_answers/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Find Nth root of M (gfg)</p> </li> <li> <p>Koko Eating Bananas (leetcode)</p> </li> <li> <p>Minimum Number of Days to Make m Bouquets (leetcode)</p> </li> <li> <p>Find the Smallest Divisor Given a Threshold (leetcode)</p> </li> <li> <p>Capacity To Ship Packages Within D Days (leetcode)</p> </li> <li> <p>Kth Missing Positive Number (leetcode)</p> </li> <li> <p>Median of Two Sorted Arrays (leetcode)</p> </li> <li> <p>K-th element of two Arrays (gfg)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/binary_search_tree/","title":"Binary Search Tree","text":""},{"location":"dsa/binary_search_tree/#contents","title":"Contents","text":""},{"location":"dsa/binary_search_tree/introduction/","title":"Introduction to Binary Search Tree","text":""},{"location":"dsa/binary_search_tree/introduction/#what-is-binary-search-tree","title":"What is Binary Search Tree?","text":"<p>Binary Search Tree (BST) is a special type of binary tree in which the left child of a node has a value less than the node\u2019s value and the right child has a value greater than the node\u2019s value. This property is called the BST property and it makes it possible to efficiently search, insert, and delete elements in the tree.</p> <p></p>"},{"location":"dsa/binary_search_tree/introduction/#properties-of-binary-search-tree","title":"Properties of Binary Search Tree:","text":"<ul> <li> <p>The left subtree of a node contains only nodes with values lesser than the node\u2019s value.</p> </li> <li> <p>The right subtree of a node contains only nodes with values greater than the node\u2019s value.</p> </li> <li> <p>This means everything to the left of the root is less than the value of the root and everything to the right of the root is greater than the value of the root. Due to this performing, a binary search is very easy.</p> </li> <li> <p>The left and right subtree each must also be a binary search tree.  </p> </li> </ul>"},{"location":"dsa/binary_search_tree/introduction/#basic-operations-on-binary-search-tree","title":"Basic Operations on Binary Search Tree:","text":""},{"location":"dsa/binary_search_tree/introduction/#1-searching-a-node-in-bst","title":"1. Searching a node in BST","text":"<p>Searching in BST means to locate a specific node in the data structure. In Binary search tree, searching a node is easy because of its a specific order.</p> <pre><code>Node* search(Node* root, int key){\n\n    if (root == NULL || root-&gt;key == key)\n        return root;\n\n    // Key is greater than root's key\n    if (root-&gt;key &lt; key)\n        return search(root-&gt;right, key);\n\n    // Key is smaller than root's key\n    return search(root-&gt;left, key);\n}\n</code></pre>"},{"location":"dsa/binary_search_tree/introduction/#2-insert-a-node-into-a-bst","title":"2. Insert a node into a BST","text":"<p>A new key is always inserted at the leaf. Start searching a key from the root till a leaf node. Once a leaf node is found, the new node is added as a child of the leaf node.</p> <pre><code>Node* search(Node* root, int key){\n\n     if (node == NULL)\n        return new Node(key);\n\n    // Otherwise, recur down the tree\n    if (key &lt; node-&gt;key){\n        node-&gt;left = insert(node-&gt;left, key);\n    }\n    else if (key &gt; node-&gt;key){\n        node-&gt;right = insert(node-&gt;right, key);\n    }\n\n    // Return the node pointer\n    return node;\n}\n</code></pre>"},{"location":"dsa/binary_search_tree/questions/","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Lowest Common Ancestor of a Binary Search Tree <ul> <li>Lowest Common Ancestor of a Binary Search Tree (leetcode)</li> </ul> <pre><code>class Solution {\n    public:\n    TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {\n\n        if(root == NULL){\n            return NULL;\n        }\n\n        if(p -&gt;val &lt; root -&gt;val &amp;&amp; q -&gt;val &lt; root -&gt;val){\n            return lowestCommonAncestor(root -&gt;left , p , q);\n        }\n        else if(p -&gt;val &gt; root -&gt;val &amp;&amp; q -&gt;val &gt; root -&gt;val){\n            return lowestCommonAncestor(root -&gt;right , p , q);\n        }\n        else{\n            return root;\n        }\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/binary_search_tree/questions/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Search in a Binary Search Tree (leetcode)</p> </li> <li> <p>Minimum element in BST (gfg)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/binary_tree/","title":"Binary Tree","text":""},{"location":"dsa/binary_tree/#contents","title":"Contents","text":""},{"location":"dsa/binary_tree/introduction/","title":"Introduction to Binary Tree","text":""},{"location":"dsa/binary_tree/introduction/#what-is-binary-tree","title":"What is Binary Tree?","text":"<p>Binary tree is a non-linear data structure in which each node can have at most two children which are referred to as the left child and the right child.</p>"},{"location":"dsa/binary_tree/introduction/#types-of-binary-tree","title":"Types of Binary Tree","text":"<ol> <li> <p>Full Binary Tree</p> <ul> <li>A full binary tree is a binary tree with either zero or two child nodes for each node.</li> </ul> </li> <li> <p>Complete Binary Tree</p> <ul> <li>A complete binary tree is a special type of binary tree where all the levels of the tree are filled completely except the lowest level nodes which are filled from as left as possible.</li> </ul> </li> <li> <p>Perfect Binary Tree</p> <ul> <li>All leaf nodes are at the same depth. In a perfect binary tree, all leaf nodes are at the maximum depth of the tree. This means that the tree is completely filled with no gaps.</li> </ul> </li> <li> <p>Balanced Binary Tree</p> <ul> <li>A binary tree is balanced if the height of the tree is O(Log n) where n is the number of nodes.</li> </ul> </li> </ol> <p></p>"},{"location":"dsa/binary_tree/introduction/#representation-of-binary-tree","title":"Representation of Binary Tree","text":"<p>Each node in a Binary Tree has three parts:</p> <ul> <li>Data</li> <li>Pointer to the left child</li> <li>Pointer to the right child</li> </ul> <p></p>"},{"location":"dsa/binary_tree/introduction/#implementation","title":"Implementation","text":"See the code <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Node{\n\n    public:\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x){\n        this -&gt;data = x;\n        this -&gt;left = NULL;\n        this -&gt;right = NULL;\n    }\n};\n\nNode* Construct_tree(vector&lt;int&gt; arr){\n\n    if(arr.empty()){\n        return NULL;\n    }\n\n    queue&lt;Node*&gt; q;\n    int index = 1;\n\n    Node* root = new Node(arr[0]);\n    q.push(root);\n\n    while(!q.empty()){\n\n        Node* t = q.front();\n        q.pop();\n\n        if(index &lt; arr.size() &amp;&amp; arr[index] != -1){\n            Node* ln = new Node(arr[index]);\n            t -&gt;left = ln;\n            q.push(t -&gt;left);\n        }\n        index++;\n\n        if(index &lt; arr.size() &amp;&amp; arr[index] != -1){\n            Node* rn = new Node(arr[index]);\n            t -&gt;right = rn;\n            q.push(t -&gt;right);\n        }\n        index++;\n    }\n\n    return root;\n}\n\nvoid display(Node* root){\n\n    if(root == NULL){\n        return;\n    }\n\n    string str = \"\";\n    str += root -&gt;left == NULL ? \".\" : to_string(root -&gt;left -&gt;data) + \"\";\n    str += \"&lt;--\" + to_string(root -&gt;data) + \"--&gt;\";\n    str += root -&gt;right == NULL ? \".\" : to_string(root -&gt;right -&gt;data) + \"\";\n\n    cout&lt;&lt;str&lt;&lt;endl;\n\n    display(root -&gt;left);\n    display(root -&gt;right);\n}\n\n\nint main(){\n\n    vector&lt;int&gt; arr = {50, 25, 75, 12, 37, 62, 87, -1, -1, 30, -1, -1, 70, -1, -1};\n\n    Node* root = Construct_tree(arr);\n    display(root);\n\n    cout&lt;&lt;endl;\n\n}\n</code></pre> <p>GFG Practice question link is below \ud83e\udd48 \ud83e\udd47</p> <ul> <li>Binary Tree Representation (gfg)</li> </ul>"},{"location":"dsa/binary_tree/questions/","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Binary Tree Maximum Path Sum <ul> <li>Binary Tree Maximum Path Sum (leetcode)</li> </ul> <p>Algorithm / Intuition</p> <ul> <li> <p>To find the diameter of a binary tree, we can think of every node as a potential Curving Point of the path along which we find the sum. The maximum sum of a path through a turning point (like a curve) can be found by adding the maximum sum achievable in the left subtree, the right subtree, and the value of the turning point.</p> <p></p> <ul> <li> <p>Base Case: When the current node is null which indicates the end of a path or a lead node, we return the maximum path sum as 0.</p> </li> <li> <p>Recursive Function:</p> <ul> <li>Calculate the maximum path sum for the left and right subtrees by making recursive calls to the left and right child of the current node.</li> <li>Calculate the maximum path sum when the current node serves as the turning point: Maximum Path Sum when Current Node is Turning Point = Maximum Path Sum of Left Subtree + Maximum Path Sum of Right Subtree + Current Value of Node</li> <li>Update the overall maximum path sum (maxi) by considering the sum of the current node and the left and right subtree sums.</li> <li>Return the maximum sum considering only one branch (either left or right) along with the value of the current node as the maximum sum up until this node.</li> </ul> </li> </ul> </li> </ul> <pre><code>class Solution {\n    public:\n    int solver(TreeNode* root , int &amp;maxi){\n\n        if(root == NULL){\n            return 0;\n        }\n\n        int l_sum = max(0 , solver(root -&gt;left , maxi));\n        int r_sum = max(0 , solver(root -&gt;right , maxi));\n\n        maxi = max(maxi , (l_sum+r_sum+root -&gt;val));\n\n        return root -&gt;val + max(l_sum , r_sum);\n    }\n\n    int maxPathSum(TreeNode* root) {\n\n        int maxi = INT_MIN;\n        solver(root , maxi);\n        return maxi;\n    }\n};\n</code></pre> Vertical Order Traversal of a Binary Tree <ul> <li>Vertical Order Traversal of a Binary Tree (leetcode)</li> </ul> <p>Before doing this problem go through the problem like (Top View of Binary Tree , Bottom View of Binary Tree) which is available in First Important Questions List. \ud83d\udd25</p> <pre><code>class Solution {\n    public:\n    vector&lt;vector&lt;int&gt;&gt; verticalTraversal(TreeNode* root) {\n\n        vector&lt;vector&lt;int&gt;&gt; ans;\n        if(root == NULL){\n            return ans;\n        }\n\n        // vertex , level , datas\n        map&lt;int,map&lt;int,multiset&lt;int&gt;&gt;&gt; mp;\n\n        // node , vertex , level\n        queue&lt;pair&lt;TreeNode*,pair&lt;int,int&gt;&gt;&gt; q;\n        q.push({root,{0,1}});\n\n        while(!q.empty()){\n            auto it = q.front();\n            q.pop();\n            TreeNode* node = it.first;\n            int line = it.second.first;\n            int level = it.second.second;\n            mp[line][level].insert(node -&gt;val);\n\n            if(node -&gt;left){\n                q.push({node -&gt;left,{line-1,level+1}});\n            }\n            if(node -&gt;right){\n                q.push({node -&gt;right,{line+1,level+1}});\n            }\n        }\n\n        for(auto p : mp){\n            vector&lt;int&gt; temp;\n            for(auto q : p.second){\n                multiset&lt;int&gt; st = q.second;\n                for(auto it : st){\n                    temp.push_back(it);\n                }\n            }\n            ans.push_back(temp);\n        }\n        return ans;\n    }\n};\n</code></pre> Maximum Width of Binary Tree <ul> <li>Maximum Width of Binary Tree (leetcode)</li> </ul> <p>Algorithm / Intuition</p> <ul> <li>Start by assigning an index to the root node as 0. For each level, the left child gets an index equal to (2 * parent index +1), and the right child gets an index equal to (2 * parent index + 2). Using a level order traversal, we use the leftmost and rightmost nodes at each level and using their indices, get the width at that level. Keep track of the maximum width encountered during the traversal. Whenever a wider level is found, update the maximum width.</li> </ul> <p></p> <pre><code>class Solution {\n    public:\n    int widthOfBinaryTree(TreeNode* root) {\n\n        if(root == NULL){\n            return 0;\n        }\n\n        long long ans = 0;\n        queue&lt;pair&lt;TreeNode*,int&gt;&gt; q;\n        q.push({root,0});\n        while(!q.empty()){\n\n            long long start = q.front().second;\n            long long end = q.back().second;\n            ans = max(ans,(end-start+1));\n            int N = q.size();\n            for(int i = 0 ; i &lt; N ; i++){\n                TreeNode* node = q.front().first;\n                long long idx = q.front().second;\n                q.pop();\n                if(node -&gt;left){\n                    q.push({node -&gt;left,2*idx+1});\n                }\n                if(node -&gt;right){\n                    q.push({node -&gt;right,2*idx+2});\n                }\n            }\n        }\n        return ans;\n    }\n};\n</code></pre> All Nodes Distance K in Binary Tree <ul> <li>All Nodes Distance K in Binary Tree (leetcode)</li> </ul> <p>\ud83d\udcaf \ud83e\udd47 Think about storing parent of child node, because we need to go from child to parent in some cases.</p> <pre><code>class Solution {\n    public:\n    void helper(TreeNode* root , map&lt;TreeNode*,TreeNode*&gt; &amp;parent){\n\n        queue&lt;TreeNode*&gt; q;\n        q.push(root);\n        while(!q.empty()){\n\n            int N = q.size();\n            for(int i = 0 ; i &lt; N ; i++){\n                TreeNode* node = q.front();\n                q.pop();\n                if(node -&gt;left){\n                    q.push(node -&gt;left);\n                    parent[node -&gt;left] = node;\n                }\n                if(node -&gt;right){\n                    q.push(node -&gt;right);\n                    parent[node -&gt;right] = node;\n                }\n            }\n        }\n    }\n\n    vector&lt;int&gt; distanceK(TreeNode* root, TreeNode* target, int k) {\n\n        map&lt;TreeNode*,TreeNode*&gt; parent;\n        helper(root , parent);\n\n        map&lt;TreeNode*,bool&gt; vis;\n        int count = 0;\n        queue&lt;TreeNode*&gt; q;\n        q.push(target);\n        while(!q.empty()){\n\n            int N = q.size();\n            if(count == k){\n                break;\n            }\n\n            for(int i = 0 ; i &lt; N ; i++){\n                TreeNode* node = q.front();\n                q.pop();\n\n                vis[node] = true;\n\n                if(node -&gt;left &amp;&amp; vis[node -&gt;left] == false){\n                    q.push(node -&gt;left);\n                    vis[node -&gt;left] = true;\n                }\n                if(node -&gt;right &amp;&amp; vis[node -&gt;right] == false){\n                    q.push(node -&gt;right);\n                    vis[node -&gt;right] = true;\n                }\n                if(parent[node] &amp;&amp; vis[parent[node]] == false){\n                    q.push(parent[node]);\n                    vis[parent[node]] = true;\n                }\n            }\n            count++;\n        }\n\n        vector&lt;int&gt; ans;\n        while(!q.empty()){\n            ans.push_back(q.front() -&gt;val);\n            q.pop();\n        }\n\n        return ans;\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/binary_tree/questions/#other-important-questions-list","title":"Other Important Questions List","text":"1. Important Questions List <ul> <li> <p>Maximum Depth of Binary Tree (leetcode)</p> </li> <li> <p>Balanced Binary Tree (leetcode)</p> </li> <li> <p>Diameter of Binary Tree (leetcode)</p> </li> <li> <p>Same Tree (leetcode)</p> </li> <li> <p>Binary Tree Zigzag Level Order Traversal (leetcode)</p> </li> <li> <p>Boundary Traversal of binary tree (gfg)</p> </li> <li> <p>Vertical Order Traversal of a Binary Tree (leetcode)</p> </li> <li> <p>Top View of Binary Tree (gfg)</p> </li> <li> <p>Bottom View of Binary Tree (gfg)</p> </li> <li> <p>Left View of Binary Tree (gfg)</p> </li> <li> <p>Binary Tree Right Side View (leetcode)</p> </li> <li> <p>Symmetric Tree (leetcode)</p> </li> </ul> 2. Important Questions List <ul> <li> <p>Root to Leaf Paths (gfg)</p> </li> <li> <p>Lowest Common Ancestor of a Binary Tree (leetcode)</p> </li> <li> <p>Check for Children Sum Property in a Binary Tree (gfg)</p> </li> </ul> <p>This problem's logic is same as All Nodes Distance K in Binary Tree</p> <ul> <li>Check for Children Sum Property in a Binary Tree (gfg)</li> </ul> <ul> <li> <p>Construct Binary Tree from Preorder and Inorder Traversal (leetcode)</p> </li> <li> <p>Construct Binary Tree from Inorder and Postorder Traversal (leetcode)</p> </li> <li> <p>Serialize and Deserialize Binary Tree (leetcode)</p> </li> <li> <p>Flatten Binary Tree to Linked List (leetcode)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/binary_tree/traversal_technique/bfs/","title":"Breadth-First Search (BFS)","text":""},{"location":"dsa/binary_tree/traversal_technique/bfs/#level-order-traversal","title":"Level Order Traversal:","text":"<p>Visit nodes level-by-level and left-to-right fashion at the same level. Here, the traversal is level-wise. It means that the most left child has traversed first and then the other children of the same level from left to right have traversed.</p> <p></p> <pre><code>void solver(Node* root){\n\n    queue&lt;Node*&gt; q;\n    q.push(root);\n\n    while(!q.empty()){\n\n        Node* node = q.front();\n        q.pop();\n        cout&lt;&lt;node -&gt;data&lt;&lt;\" \";\n\n        if(node -&gt;left != NULL)\n            q.push(node -&gt;left);\n\n        if(node -&gt;right != NULL)\n            q.push(node -&gt;right);\n\n    }\n}\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/binary_tree/traversal_technique/bfs/#other-important-questions-list","title":"Other Important Questions List","text":"Practice Questions List <ul> <li> <p>Level order traversal (gfg)</p> </li> <li> <p>Binary Tree Level Order Traversal (leetcode)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/binary_tree/traversal_technique/dfs/","title":"Depth-First Search (DFS)","text":""},{"location":"dsa/binary_tree/traversal_technique/dfs/#preorder-traversal-root-left-right","title":"Preorder Traversal (root-left-right):","text":"<p>Visit the root node before visiting any nodes inside the left or right subtrees. Here, the traversal is root \u2013 left child \u2013 right child. It means that the root node is traversed first then its left child and finally the right child.</p> <p></p> <pre><code>void printPreorder(Node* node){\n\n    if (node == NULL){\n        return;\n    }\n\n    cout &lt;&lt; node-&gt;data &lt;&lt; \" \";\n\n    printPreorder(node-&gt;left);\n    printPreorder(node-&gt;right);\n}\n</code></pre>"},{"location":"dsa/binary_tree/traversal_technique/dfs/#inorder-traversal-left-root-right","title":"Inorder Traversal (left-root-right):","text":"<p>Visit the root node after visiting all nodes inside the left subtree but before visiting any node within the right subtree. Here, the traversal is left child \u2013 root \u2013 right child.  It means that the left child is traversed first then its root node and finally the right child.</p> <p></p> <pre><code>void printInorder(Node* node){\n\n    if (node == NULL){\n        return;\n    }\n\n\n    printInorder(node-&gt;left);\n\n    cout &lt;&lt; node-&gt;data &lt;&lt; \" \";\n\n    printInorder(node-&gt;right);\n}\n</code></pre>"},{"location":"dsa/binary_tree/traversal_technique/dfs/#postorder-traversal-left-right-root","title":"Postorder Traversal (left-right-root):","text":"<p>Visit the root node after visiting all the nodes of the left and right subtrees.  Here, the traversal is left child \u2013 right child \u2013 root.  It means that the left child has traversed first then the right child and finally its root node.</p> <p></p> <pre><code>void printPostorder(Node* node){\n\n    if (node == NULL){\n        return;\n    }\n\n\n    printPostorder(node-&gt;left);\n    printPostorder(node-&gt;right);\n\n    cout &lt;&lt; node-&gt;data &lt;&lt; \" \";\n\n}\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/binary_tree/traversal_technique/dfs/#other-important-questions-list","title":"Other Important Questions List","text":"Practice Questions List <ul> <li> <p>Binary Tree Representation (gfg)</p> </li> <li> <p>Binary Tree Preorder Traversal (leetcode)</p> </li> <li> <p>Binary Tree Inorder Traversal (leetcode)</p> </li> <li> <p>Binary Tree Postorder Traversal (leetcode)</p> </li> <li> <p>Binary Tree Postorder Traversal [Iterative] (gfg)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/dp/","title":"Dynamic Programming","text":""},{"location":"dsa/dp/#contents","title":"Contents","text":""},{"location":"dsa/dp/introduction/","title":"Introduction to Dynamic Programming","text":""},{"location":"dsa/dp/introduction/#dynamic-programming-or-dp","title":"Dynamic Programming or DP","text":"<p>Dynamic Programming is a method used in mathematics and computer science to solve complex problems by breaking them down into simpler subproblems.</p> <p>Dynamic Programming can be described as storing answers to various sub-problems to be used later whenever required to solve the main problem.</p> <p></p> How Does Dynamic Programming (DP) Work? <ul> <li>Identify Subproblems :- Divide the main problem into smaller, independent subproblems.</li> <li>Store Solutions :- Solve each subproblem and store the solution in a table or array.</li> <li>Build Up Solutions :- Use the stored solutions to build up the solution to the main problem.</li> <li>Avoid Redundancy :- By storing solutions, DP ensures that each subproblem is solved only once, reducing computation time.</li> </ul>"},{"location":"dsa/dp/introduction/#approaches-of-dynamic-programming-dp","title":"Approaches of Dynamic Programming (DP)","text":"<p>The two common dynamic programming approaches are :-</p> <ul> <li>Memoization: Known as the \u201ctop-down\u201d dynamic programming, usually the problem is solved in the direction of the main problem to the base cases.</li> <li>Tabulation: Known as the \u201cbottom-up\" dynamic programming, usually the problem is solved in the direction of solving the base cases to the main problem</li> </ul> <p></p>"},{"location":"dsa/dp/introduction/#we-will-be-using-the-example-of-fibonacci-numbers","title":"We will be using the example of Fibonacci numbers.","text":"<p>The following series is called the Fibonacci series :- 0,1,1,2,3,5,8,13,21,...</p> <p>We need to find the nth Fibonacci number, where n is based on a 0-based index.</p> <p>Every ith number of the series is equal to the sum of (i-1)th and (i-2)th number where the first and second number is given as 0 and 1 respectively.</p>"},{"location":"dsa/dp/introduction/#part-1-memoizaton","title":"Part - 1: Memoizaton","text":"<p>As every number is equal to the sum of the previous two terms, the recurrence relation can be written as :-</p> <p></p> <p>The basic pseudo-code for the problem will be given as :-</p> <p></p> <p>Steps to memoize a recursive solution :-</p> <ul> <li> <p>\ud83d\udcaf\ud83d\udc4d Any recursive solution to a problem can be memoized using these three steps :-</p> <ul> <li> Create a dp[n+1] array initialized to -1.</li> <li> Whenever we want to find the answer of a particular value (say n), we first check whether the answer is already calculated using the dp array(i.e dp[n]!= -1 ). If yes, simply return the value from the dp array.</li> <li> If not, then we are finding the answer for the given value for the first time, we will use the recursive relation as usual but before returning from the function, we will set dp[n] to the solution we get.</li> </ul> </li> </ul>"},{"location":"dsa/dp/introduction/#code","title":"Code","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nint fibonacci(int n, vector&lt;int&gt;&amp; dp){\n    if(n&lt;=1) return n;\n\n    if(dp[n]!= -1) return dp[n];\n    return dp[n]= fibonacci(n-1,dp) + fibonacci(n-2,dp);\n}\n\nint main() {\n\n  int n=5;\n  vector&lt;int&gt; dp(n+1,-1);\n  cout&lt;&lt;fibonacci(n,dp);\n\n  return 0;\n}\n</code></pre>"},{"location":"dsa/dp/introduction/#time-complexity-on","title":"Time Complexity: O(N)","text":"<p>Reason: The overlapping subproblems will return the answer in constant time O(1). Therefore the total number of new subproblems we solve is \u2018n\u2019. Hence total time complexity is O(N).</p>"},{"location":"dsa/dp/introduction/#space-complexity-on","title":"Space Complexity: O(N)","text":"<p>Reason: We are using a recursion stack space(O(N)) and an array (again O(N)). Therefore total space complexity will be O(N) + O(N) \u2248 O(N)</p>"},{"location":"dsa/dp/introduction/#part-2-tabulation","title":"Part -2: Tabulation","text":"<p>Tabulation is a \u2018bottom-up\u2019 approach where we start from the base case and reach the final answer that we want.</p> <ul> <li> <p>\ud83d\udcaf\ud83d\udc4d Steps to convert Recursive Solution to Tabulation one.</p> <ul> <li> Declare a dp[] array of size n+1.</li> <li> First initialize the base condition values, i.e i=0 and i=1 of the dp array as 0 and 1 respectively.</li> <li> Set an iterative loop that traverses the array( from index 2 to n) and for every index set its value as dp[i-1] + dp[i-2]. </li> </ul> </li> </ul>"},{"location":"dsa/dp/introduction/#code_1","title":"Code","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nint fibonacci(int n){\n    vector&lt;int&gt; dp(n+1,-1);\n\n    dp[0]= 0;\n    dp[1]= 1;\n\n    for(int i=2; i&lt;=n; i++){\n        dp[i] = dp[i-1]+ dp[i-2];\n    }\n\n    return dp[n];\n}\n\nint main() {\n\n  int n=5;\n  cout&lt;&lt;fibonacci(n);\n\n  return 0;\n}\n</code></pre>"},{"location":"dsa/dp/introduction/#time-complexity-on_1","title":"Time Complexity: O(N)","text":"<p>Reason: We are running a simple iterative loop</p>"},{"location":"dsa/dp/introduction/#space-complexity-on_1","title":"Space Complexity: O(N)","text":"<p>Reason: We are using an external array of size \u2018n+1\u2019.</p>"},{"location":"dsa/dp/introduction/#part-3-space-optimization","title":"Part 3: Space Optimization","text":"<p>\ud83e\udd14 If we closely look at the below relation</p> <p>dp[i] =  dp[i-1] + dp[i-2]</p> <p>we see that for any i, we do need only the last two values in the array. So is there a need to maintain a whole array for it?   The answer is \u2018No\u2019. Let us call dp[i-1] as prev and dp[i-2] as prev2.</p> <p>Now understand the following illustration.</p> <p></p> <ul> <li>Each iteration\u2019s cur_i and prev becomes the next iteration\u2019s prev and prev2 respectively.</li> <li>Therefore after calculating cur_i, if we update prev and prev2 according to the next step, we will always get the answer. </li> <li>After the iterative loop has ended we can simply return prev as our answer.</li> </ul>"},{"location":"dsa/dp/introduction/#code_2","title":"Code","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nint main() {\n\n  int n=5;\n  int prev2 = 0;\n  int prev = 1;\n\n  for(int i=2; i&lt;=n; i++){\n      int cur_i = prev2+ prev;\n      prev2 = prev;\n      prev= cur_i;\n  }\n\n  cout&lt;&lt;prev;\n\n  return 0;\n}\n</code></pre>"},{"location":"dsa/dp/introduction/#time-complexity-on_2","title":"Time Complexity: O(N)","text":"<p>Reason: We are running a simple iterative loop</p>"},{"location":"dsa/dp/introduction/#space-complexity-o1","title":"Space Complexity: O(1)","text":"<p>Reason: We are not using any extra space</p>"},{"location":"dsa/dp/categorize_dp/1d/","title":"1-D Dynamic Programming","text":"<p>We defined sub-problems and their dependency, other important entities in dp are the dependent elements or variables. The count of these variables defines the dimension of the problem. If a problem is dependent on 1 variable, its a 1D dp problem.</p> <p>Approach to solving 1-D DP problems :-</p> <ul> <li>Using memoization (top-down)</li> <li>Using tabulation method (bottom-up)</li> </ul> <p>\ud83e\udde0 \ud83d\udc4d Out of bound base cases should be written at the top of all of the base cases.</p>"},{"location":"dsa/dp/categorize_dp/1d/#questions","title":"Questions","text":"<p>\ud83d\udca1 In the below questions try to draw the recursion's diagram of each problem on the \ud83d\udcdd paper.</p> Climbing Stairs <ul> <li>Climbing Stairs (leetcode)</li> </ul> <p>memoization</p> <pre><code>int solver(int n , vector&lt;int&gt; &amp;dp){\n\n    if(n == 0){\n        return 1;\n    }\n    if(n &lt; 0){\n        return 0;\n    }\n\n    if(dp[n] != -1){\n        return dp[n];\n    }\n\n    int l = solver(n-1 , dp);\n    int r = solver(n-2 , dp);\n\n    return dp[n] = l+r;\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(int n){\n\n    vector&lt;int&gt; dp(n+1 , -1);\n    dp[0] = 1;\n    for(int i = 1 ; i &lt;= n ; i++){\n        if(i == 1){\n            dp[i] = dp[i-1];\n        }\n        else{\n            dp[i] = dp[i-1]+dp[i-2];\n        }\n    }\n\n    return dp[n];\n}\n</code></pre> Frog Jump <ul> <li>Frog Jump (gfg)</li> </ul> <p>memoization</p> <pre><code>int solver(vector&lt;int&gt; &amp;height , int n , vector&lt;int&gt; &amp;dp){\n\n    if(n == 0){\n        return 0;\n    }\n\n    if(dp[n] != -1){\n        return dp[n];\n    }\n\n    int l = solver(height , n-1 , dp) + abs(height[n]-height[n-1]);\n    int r = INT_MAX;\n    if(n &gt; 1)\n        r = solver(height , n-2 , dp) + abs(height[n]-height[n-2]);\n\n\n    return dp[n] = min(l,r);\n\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(vector&lt;int&gt; &amp;height , int n){\n\n    vector&lt;int&gt; dp(n+1 , -1);\n    dp[0] = 0;\n    dp[1] = abs(height[1]-height[0]);\n\n    for(int i = 2 ; i &lt; n ; i++){\n        int jump1 = dp[i-1] + abs(height[i]-height[i-1]);\n        int jump2 = dp[i-2] + abs(height[i]-height[i-2]);\n        dp[i] = min(jump1,jump2);\n    }\n\n    return dp[n-1];\n}\n</code></pre> Frog Jump with k distances <ul> <li>Frog Jump with k distances (gfg)</li> </ul> <p>memoization</p> <pre><code>int solver(vector&lt;int&gt; &amp;height , int n , int k , vector&lt;int&gt; &amp;dp){\n\n  if(n == 0){\n      return 0;\n  }\n\n  if(dp[n] != -1){\n      return dp[n];\n  }\n\n  int ans = INT_MAX;\n  for(int i = 1 ; i &lt;= k ; i++){\n      if(n-i &gt;= 0){\n          int cost = solver(height , n-i , k , dp) + abs(height[n]-height[n-i]);\n          ans = min(ans , cost);\n      }\n\n\n  }\n\n  return dp[n] = ans;\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(vector&lt;int&gt; &amp;height , int n , int k){\n\n  vector&lt;int&gt; dp(n+1,-1);\n  dp[0] = 0;\n\n  for(int i = 1 ; i&lt;n ; i++){\n\n      int ans = INT_MAX;\n      for(int j = 1 ; j &lt;= k ; j++){\n          if(i-j &gt;= 0){\n             int cost = dp[i-j] + abs(height[i]-height[i-j]);\n            ans = min(ans , cost);\n          }\n      }\n      dp[i] = ans;\n  }\n\n  return dp[n-1];\n}\n</code></pre> Maximum sum of non-adjacent elements <ul> <li>Maximum sum of non-adjacent elements (leetcode)</li> </ul> <p>memoization</p> <pre><code>int solver(vector&lt;int&gt; &amp;nums , int n , vector&lt;int&gt; &amp;dp){\n\n    if(n == 0){\n        return nums[n];\n    }\n    if(n &lt; 0){\n        return 0;\n    }\n\n    if(dp[n] != -1){\n        return dp[n];\n    }\n\n    int picked = nums[n] + solver(nums , n-2 , dp);\n    int not_picked = 0 + solver(nums , n-1 , dp);\n\n    return dp[n] = max(picked , not_picked);\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(vector&lt;int&gt; &amp;nums , int n){\n\n    vector&lt;int&gt; dp(n+1 , -1);\n    dp[0] = nums[0];\n\n    for(int i = 1 ; i &lt; n ; i++){\n        int picked = nums[i];\n        if(i &gt; 1) picked += dp[i-2];\n        int not_picked = 0 + dp[i-1];\n\n        dp[i] = max(picked , not_picked);\n    }\n\n    return dp[n-1];\n}\n</code></pre> House Robber II <ul> <li>House Robber II (leetcode)</li> </ul> <p> After reading the question see the below image, you will get the idea to solve</p> <p></p> <p></p> <p>memoization</p> <pre><code>class Solution {\npublic:\n\n    int solver(int n , vector&lt;int&gt; &amp;nums , vector&lt;int&gt; &amp;dp){\n\n        if(n == 0){\n            return nums[n];\n        }\n        if(n &lt; 0){\n            return 0;\n        }\n\n        if(dp[n] != -1){\n            return dp[n];\n        }\n\n        int picked = nums[n] + solver(n-2 , nums , dp);\n        int not_picked = 0 + solver(n-1 , nums , dp);\n\n        return dp[n] = max(picked , not_picked);\n    }\n\n    int rob(vector&lt;int&gt;&amp; nums) {\n\n        int n = nums.size();\n        if(n == 1){\n            return nums[0];\n        }\n        vector&lt;int&gt; v1 , v2;\n        for(int i = 1 ; i &lt; n ; i++){\n            v1.push_back(nums[i]);\n        }\n        for(int i = 0 ; i &lt; n-1 ; i++){\n            v2.push_back(nums[i]);\n        }\n        vector&lt;int&gt; dp1(v1.size()+1 , -1);\n        vector&lt;int&gt; dp2(v2.size()+1 , -1);\n        int ans1 = solver(v1.size()-1 , v1 , dp1);\n        int ans2 = solver(v2.size()-1 , v2 , dp2);\n\n        return max(ans1 , ans2);\n    }\n};\n</code></pre> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/dp/categorize_dp/2d/","title":"2-D Dynamic Programming","text":"<p>We defined sub-problems and their dependency, other important entities in dp are the dependent elements or variables. The count of these variables defines the dimension of the problem. If a problem is dependent on 2 variable, its a 2D dp problem.</p> <p>\ud83e\udde0 \ud83d\udc4d Out of bound base cases should be written at the top of all of the base cases.</p>"},{"location":"dsa/dp/categorize_dp/2d/#questions","title":"Questions","text":"<p>\ud83d\udca1 In the below questions try to draw the recursion's diagram of each problem on the \ud83d\udcdd paper.</p> Geek's Training <ul> <li>Geek's Training (gfg)</li> </ul> <p>\ud83e\udd1e For this question : - Only think about which activity is done before and you should pass that activity to recursion that's why the same activity will not happen next day.</p> <p>memoization</p> <pre><code>int solver(vector&lt;vector&lt;int&gt;&gt; &amp;points , int n , int last_task , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n    if(n == 0){\n        int maxi = INT_MIN;\n        for(int i = 0 ; i &lt; 3 ; i++){\n            if(i != last_task){\n                maxi = max(maxi , points[n][i]);\n            }\n        }\n        return maxi;\n    }\n\n    if(dp[n][last_task] != -1){\n        return dp[n][last_task];\n    }\n\n    int max_points = INT_MIN;\n    for(int i = 0 ; i &lt; 3 ; i++){\n        if(i != last_task){\n           int point = points[n][i] + solver(points , n-1 , i , dp);\n           max_points = max(max_points , point);\n        }\n    }\n    return dp[n][last_task] = max_points;\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(vector&lt;vector&lt;int&gt;&gt; &amp;points , int n){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (4,-1));\n\n    dp[0][0] = max(points[0][1], points[0][2]);\n    dp[0][1] = max(points[0][0], points[0][2]);\n    dp[0][2] = max(points[0][0], points[0][1]);\n    dp[0][3] = max(points[0][0], max(points[0][1], points[0][2]));\n\n    for(int i = 1 ; i &lt; n ; i++){\n        for(int j = 0 ; j &lt; 4 ; j++){\n\n            for (int task = 0; task &lt;= 2; task++) {\n                if (task != j) {\n                  int activity = points[i][task] + dp[i - 1][task];\n                  dp[i][j] = max(dp[i][j], activity);\n                }\n            }\n        }\n    }\n\n    return dp[n-1][3];\n}\n</code></pre> Grid Unique Paths <ul> <li>Grid Unique Paths (leetcode)</li> </ul> <p>memoization</p> <pre><code>int solver(int m , int n , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n    if(m &lt; 0 || n &lt; 0){\n        return 0;\n    }\n    if(m == 0 &amp;&amp; n == 0){\n        return 1;\n    }\n\n    if(dp[m][n] != -1){\n        return dp[m][n];\n    }\n\n    int up = solver(m-1 , n , dp);\n    int left = solver(m , n-1 , dp);\n\n    return dp[m][n] = up+left;\n\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(int m , int n){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(m+1 , vector&lt;int&gt; (n , -1));\n\n    for(int i = 0 ; i &lt; m ; i++){\n        for(int j = 0 ; j &lt; n ; j++){\n            if(i == 0 &amp;&amp; j == 0){\n                dp[i][j] = 1;\n                continue;\n            }\n            int down = 0;\n            int right = 0;\n            if(i &gt; 0)\n                down = dp[i-1][j];\n            if(j &gt; 0)\n                right = dp[i][j-1];\n            dp[i][j] = down+right;\n        }\n    }\n    return dp[m-1][n-1];\n}\n</code></pre> Grid Unique Paths II <ul> <li>Grid Unique Paths II (leetcode)</li> </ul> <p>memoization</p> <pre><code>int solver(vector&lt;vector&lt;int&gt;&gt; &amp;obstacleGrid , int m , int n , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n    if(m &gt;= 0 &amp;&amp; n &gt;= 0 &amp;&amp; obstacleGrid[m][n] == 1){\n        return 0;\n    }\n    if(m &lt; 0 || n &lt; 0){\n        return 0;\n    }\n    if(m == 0 &amp;&amp; n == 0){\n        return 1;\n    }\n\n    if(dp[m][n] != -1){\n        return dp[m][n];\n    }\n\n    int up = solver(obstacleGrid , m-1 , n , dp);\n    int left = solver(obstacleGrid , m , n-1 , dp);\n\n    return dp[m][n] = up+left;\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(vector&lt;vector&lt;int&gt;&gt; &amp;obstacleGrid , int m , int n){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(m , vector&lt;int&gt; (n , -1));\n    for(int i = 0 ; i &lt; m ; i++){\n        for(int j = 0 ; j &lt; n ; j++){\n            if(i &gt;= 0 &amp;&amp; j &gt;= 0 &amp;&amp; obstacleGrid[i][j] == 1){\n                dp[i][j] = 0;\n                continue;\n            }\n\n            if(i == 0 &amp;&amp; j == 0){\n                dp[i][j] = 1;\n                continue;\n            }\n\n            int down = 0;\n            int right = 0;\n            if(i &gt; 0)\n                down = dp[i-1][j];\n            if(j &gt; 0)\n                right = dp[i][j-1];\n            dp[i][j] = down+right;\n        }\n    }\n    return dp[m-1][n-1];\n}\n</code></pre> Minimum path sum <ul> <li>Minimum path sum (leetcode)</li> </ul> <p>memoization</p> <pre><code>int solver(vector&lt;vector&lt;int&gt;&gt; &amp;grid , int n , int m , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n    if(n &lt; 0 || m &lt; 0){\n        return 1e8;\n    }\n    if(n == 0 &amp;&amp; m == 0){\n        return grid[n][m];\n    }\n\n    if(dp[n][m] != -1){\n        return dp[n][m];\n    }\n\n    int up = grid[n][m] + solver(grid , n-1 , m , dp);\n    int left = grid[n][m] + solver(grid , n , m-1 , dp);\n\n    return dp[n][m] = min(up , left);\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(vector&lt;vector&lt;int&gt;&gt; &amp;grid , int n , int m){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (m , -1));\n\n    for(int i = 0 ; i &lt; n ; i++){\n        for(int j = 0 ; j &lt; m ; j++){\n            if(i == 0 &amp;&amp; j == 0){\n                dp[i][j] = grid[0][0];\n                continue;\n            }\n\n            int down = grid[i][j];\n            if(i &gt; 0)\n                down += dp[i-1][j];\n            else\n                down += 1e8;\n\n            int right = grid[i][j];\n            if(j &gt; 0)\n                right += dp[i][j-1];\n            else\n                right += 1e8;\n\n            dp[i][j] = min(down , right);\n        }\n    }\n    return dp[n-1][m-1];\n}\n</code></pre> Minimum path sum in triangle <ul> <li>Minimum path sum in triangle (leetcode)</li> </ul> <p>memoization</p> <pre><code>int solver(vector&lt;vector&lt;int&gt;&gt; &amp;triangle , int i , int j , int n , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n    if(i == n){\n        return triangle[i][j];\n    }\n\n    if(dp[i][j] != -1){\n        return dp[i][j];\n    }\n\n    int down = triangle[i][j] + solver(triangle , i+1 , j , n , dp);\n    int diag = triangle[i][j] + solver(triangle , i+1 , j+1 , n , dp);\n\n    return dp[i][j] = min(down , diag);\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(vector&lt;vector&lt;int&gt;&gt; &amp;triangle , int n){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (n , -1));\n    for(int i = 0 ; i &lt; n ; i++){\n        dp[n-1][i] = triangle[n-1][i];\n    }\n    for(int i = n-2 ; i &gt;= 0 ; i--){\n        for(int j = i ; j &gt;= 0 ; j--){\n            int up = triangle[i][j] + dp[i+1][j];\n            int diag = triangle[i][j] + dp[i+1][j+1];\n\n            dp[i][j] = min(up , diag);\n        }\n    }\n    return dp[0][0];\n}\n</code></pre> Minimum Falling Path Sum <ul> <li>Minimum Falling Path Sum (leetcode)</li> </ul> <p>memoization</p> <pre><code>int solver(int i , int j , int m , vector&lt;vector&lt;int&gt;&gt; &amp;matrix , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n    if(i &lt; 0 || j &lt; 0 || j &gt;= m){\n        return 1e8;\n    }\n    if(i == 0){\n        return matrix[0][j];\n    }\n\n    if(dp[i][j] != -1){\n        return dp[i][j];\n    }\n\n    int up = matrix[i][j] + solver(i-1 , j , m , matrix , dp);\n    int diag_left = matrix[i][j] + solver(i-1 , j-1 , m , matrix , dp);\n    int diag_right = matrix[i][j] + solver(i-1 , j+1 , m , matrix , dp);\n\n    return dp[i][j] = min(up , min(diag_left , diag_right));\n}\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(int n , int m , vector&lt;vector&lt;int&gt;&gt; &amp;matrix){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (m , -1));\n    for (int j = 0; j &lt; m; j++) {\n        dp[0][j] = matrix[0][j];\n    }\n\n    for(int i = 1 ; i &lt; n ; i++){\n        for(int j = 0 ; j &lt; m ; j++){\n            int up = matrix[i][j] + dp[i-1][j];\n\n            int diag_left = matrix[i][j];\n            if (j-1 &gt;= 0) {\n                diag_left += dp[i-1][j-1];\n            } else {\n                diag_left += 1e9;\n            }\n\n            int diag_right = matrix[i][j];\n            if (j+1 &lt; m) {\n                diag_right += dp[i-1][j+1];\n            } else {\n                diag_right += 1e9;\n            }\n\n            dp[i][j] = min(up , min(diag_left , diag_right));\n        }\n    }\n    int mini = INT_MAX;\n    for (int j = 0; j &lt; m; j++) {\n        mini = min(mini, dp[n - 1][j]);\n    }\n    return mini;\n}\n</code></pre> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/dp/categorize_dp/3d/","title":"3-D Dynamic Programming","text":"<p>We defined sub-problems and their dependency, other important entities in dp are the dependent elements or variables. The count of these variables defines the dimension of the problem. If a problem is dependent on 3 variable, its a 3D dp problem.</p> <p>\ud83e\udde0 \ud83d\udc4d Out of bound base cases should be written at the top of all of the base cases.</p>"},{"location":"dsa/dp/categorize_dp/3d/#questions","title":"Questions","text":"<p>\ud83d\udca1 In the below questions try to draw the recursion's diagram of each problem on the \ud83d\udcdd paper.</p> Chocolates Pickup <ul> <li>Chocolates Pickup (gfg)</li> </ul> <p>Steps to form the recursive solution :-</p> <p>Base Case:</p> <ul> <li> <p>If j1&lt;0 or j1&gt;=M or j2&lt;0 or j2&gt;=M  , then we return -1e9 </p> </li> <li> <p>When i == N-1, it means we are at the last row, so we need to return from here. Now it can happen that at the last row, both Alice and Bob are at the same cell, in this condition we will return only chocolates collected by Alice, mat[i][j1] ( as question states that the chocolates cannot be doubly calculated), otherwise we return sum of chocolates collected by both, mat[i][j1] + mat[i][j1][j2].</p> </li> </ul> <pre><code>if(j1 &lt; 0 || j1 &gt;= m || j2 &gt;= m || j2 &lt; 0){\n    return -1e9;\n}\nif(i == n-1){\n    if(j1 == j2){\n        return grid[i][j1];\n    }\n    else{\n        return grid[i][j1] + grid[i][j2];\n    }\n}\n</code></pre> <p>Step 2: Try out all possible choices at a given index.</p> <ul> <li> <p>we need to understand that we want to move Alice and Bob together. Both of them can individually move three moves but say Alice moves to bottom-left, then Bob can have three different moves for Alice\u2019s move, and so on.</p> </li> <li> <p>Hence we have a total of 9 different options at every f(i,j1,j2) to move Alice and Bob. Now we can manually write these 9 options or we can observe a pattern in them, first Alice moves to one side and Bob tries all three choices, then again Alice moves, then Bob, and so on. This pattern can be easily captured by using two nested loops that change the column numbers(j1 and j2).</p> </li> <li> <p>Note: if (j1===j2), as discussed in the base case, we will only consider chocolates collected by one of them otherwise we will consider chocolates collected by both of them.</p> </li> </ul> <p>Step 3:  Take the maximum of all choices</p> <pre><code>int maxi = INT_MIN;\nfor(int p = -1 ; p &lt;= 1 ; p++){\n    for(int q = -1 ; q &lt;= 1 ; q++){\n        int ans;\n\n        if(j1 == j2){\n            ans = grid[i][j1];\n        }\n        else{\n            ans = grid[i][j1]+ grid[i][j2];\n        }\n        ans += solver(i+1 , j1+p , j2+q , n , m , grid , dp);\n\n        maxi = max(maxi , ans);\n    }\n}\n</code></pre> <p>memoization</p> <pre><code>class Solution{\n  public:\n\n    int solver(int i , int j1 , int j2 , int n , int m , vector&lt;vector&lt;int&gt;&gt; &amp;grid , vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; &amp;dp){\n\n        if(j1 &lt; 0 || j1 &gt;= m || j2 &gt;= m || j2 &lt; 0){\n            return -1e9;\n        }\n        if(i == n-1){\n            if(j1 == j2){\n                return grid[i][j1];\n            }\n            else{\n                return grid[i][j1] + grid[i][j2];\n            }\n        }\n\n        if(dp[i][j1][j2] != -1){\n            return dp[i][j1][j2];\n        }\n\n        int maxi = INT_MIN;\n        for(int p = -1 ; p &lt;= 1 ; p++){\n            for(int q = -1 ; q &lt;= 1 ; q++){\n                int ans;\n\n                if(j1 == j2){\n                    ans = grid[i][j1];\n                }\n                else{\n                    ans = grid[i][j1]+ grid[i][j2];\n                }\n                ans += solver(i+1 , j1+p , j2+q , n , m , grid , dp);\n\n                maxi = max(maxi , ans);\n            }\n        }\n        return dp[i][j1][j2] = maxi;\n    }\n\n    int solve(int n, int m, vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\n        vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(n , vector&lt;vector&lt;int&gt;&gt;(m , vector&lt;int&gt;(m , -1)));\n        return solver(0 , 0 , m-1 , n , m , grid , dp);\n    }\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/dp/categorize_dp/dp_on_string/","title":"DP on String","text":""},{"location":"dsa/dp/categorize_dp/dp_on_string/#what-is-a-string","title":"What is a String?","text":"<p>String is considered a data type in general and is typically represented as arrays of bytes (or words) that store a sequence of characters. String is defined as an array of characters. The difference between a character array and a string is the string is terminated with a special character \u2018\\0\u2019. Some examples of strings are : - \u201cgeeks\u201d , \u201cfor\u201d, \u201cgeeks\u201d, \u201cGeeksforGeeks\u201d, \u201cGeeks for Geeks\u201d, \u201c123Geeks\u201d.</p> <p>Something about subsequence :-  \ud83d\udcaf \ud83d\udd25</p> <p>A subsequence of a string is a list of characters of the string where some characters are deleted (or not deleted at all) and they should be in the same order in the subsequence as in the original string.</p> <p>For eg:-</p> <p></p> <ul> <li>Strings like \u201ccab\u201d,\u201d bc\u201d will not be called as a subsequence of \u201cabc\u201d as the characters are not coming in the same order.</li> </ul> <p>Note:- For a string of length n, the number of subsequences will be 2n.</p>"},{"location":"dsa/dp/categorize_dp/dp_on_string/#questions","title":"Questions","text":"<p>\ud83d\udca1 In the below questions try to draw the recursion's diagram of each problem on the \ud83d\udcdd paper.</p> Longest Common Subsequence <ul> <li>Longest Common Subsequence (leetcode)</li> </ul> <p>memoization</p> <pre><code>class Solution {\n  public:\n\n    int solver(string &amp;str1 , int n1 , string &amp;str2 , int n2 , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n1 &lt; 0 || n2 &lt; 0){\n            return 0;\n        }\n\n        if(dp[n1][n2] != -1){\n            return dp[n1][n2];\n        }\n\n        // if matched\n        if(str1[n1] == str2[n2])\n            return dp[n1][n2] = 1 + solver(str1 , n1-1 , str2 , n2-1 , dp);\n\n        // if not matched\n        return dp[n1][n2] = max(solver(str1 , n1-1 , str2 , n2 , dp) , solver(str1 , n1 , str2 , n2-1 , dp));\n    }\n\n    int longestCommonSubsequence(string text1, string text2) {\n\n        int n1 = text1.length();\n        int n2 = text2.length();\n        vector&lt;vector&lt;int&gt;&gt; dp(n1 , vector&lt;int&gt;(n2 , -1));\n\n        return solver(text1 , n1-1 , text2 , n2-1 , dp);\n    }\n};\n</code></pre> <p>tabulation</p> <p>Intuition for tabulation \ud83d\udd25</p> <p>\u2192 In the recursive logic, we set the base case to if (ind1&lt;0 || ind2&lt;0) but we can\u2019t set the dp array\u2019s index to -1. Therefore a hack for this issue is to shift every index by 1 towards the right.</p> <ul> <li>Therefore, now the base case will be if(ind1==0 || ind2==0).</li> <li>Similarly, we will implement the recursive code by keeping in mind the shifting of indexes, therefore S1[ind1] will be converted to S1[ind1-1]. Same for others.</li> <li>At last we will print dp[N][M] as our answer.</li> </ul> <pre><code>int tabulation(string &amp;str1 , int n1 , string &amp;str2 , int n2){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n1+1 , vector&lt;int&gt;(n2+1 , -1));\n    for(int j = 0 ; j &lt;= n2 ; j++){\n        dp[0][j] = 0;\n    }\n    for(int i = 0 ; i &lt;= n1 ; i++){\n        dp[i][0] = 0;\n    }\n\n    for(int i = 1 ; i &lt;= n1 ; i++){\n        for(int j = 1 ; j &lt;= n2 ; j++){\n            if(str1[i-1] == str2[j-1])\n                dp[i][j] = 1 + dp[i-1][j-1];\n            else\n                dp[i][j] = max(dp[i-1][j] , dp[i][j-1]);\n        }\n    }\n\n    return dp[n1][n2];\n}\n</code></pre> Print Longest Common Subsequence <ul> <li>Print Longest Common Subsequence (gfg)</li> </ul> <p>tabulation</p> <pre><code>void lcs(string s1, string s2) {\n\n    int n = s1.size();\n    int m = s2.size();\n\n    vector &lt; vector &lt; int &gt;&gt; dp(n + 1, vector &lt; int &gt; (m + 1, 0));\n    for (int i = 0; i &lt;= n; i++) {\n        dp[i][0] = 0;\n    }\n    for (int i = 0; i &lt;= m; i++) {\n        dp[0][i] = 0;\n    }\n\n    for (int ind1 = 1; ind1 &lt;= n; ind1++) {\n        for (int ind2 = 1; ind2 &lt;= m; ind2++) {\n        if (s1[ind1 - 1] == s2[ind2 - 1])\n            dp[ind1][ind2] = 1 + dp[ind1 - 1][ind2 - 1];\n        else\n            dp[ind1][ind2] = 0 + max(dp[ind1 - 1][ind2], dp[ind1][ind2 - 1]);\n        }\n    }\n\n    int i = n;\n    int j = m;\n\n    string str = \"\";\n\n    while (i &gt; 0 &amp;&amp; j &gt; 0) {\n        if (s1[i - 1] == s2[j - 1]) {\n            str += s1[i-1];\n            i--;\n            j--;\n        } else if (s1[i - 1] &gt; s2[j - 1]) {\n            i--;\n        } else j--;\n    }\n\n    reverse(str.begin(),str.end());\n    cout &lt;&lt; str;\n}\n\nint main() {\n\n    string s1 = \"abcde\";\n    string s2 = \"bdgek\";\n\n    cout &lt;&lt; \"The Longest Common Subsequence is \";\n    lcs(s1, s2);\n\n    cout&lt;&lt;endl;\n}\n</code></pre> Longest Common Substring <ul> <li>Longest Common Substring (gfg)</li> </ul> <p>Thinking in terms of consecutiveness of characters \ud83d\udd25</p> <p>We have two conditions :-</p> <ul> <li> <p>if (S1[i-1] != S2[j-1]), the characters don\u2019t match, therefore the consecutiveness of characters is broken. So we set the cell value (dp[i][j]) as 0.</p> </li> <li> <p>if (S1[i-1] == S2[j-1]), then the characters match and we simply set its value to 1+dp[i-1][j-1]. We have done so because dp[i-1][j-1] gives us the longest common substring till the last cell character. As the current cell\u2019s character is matching we are adding 1 to the consecutive chain.</p> </li> </ul> <p>Note: dp[n][m] will not give us the answer; rather the maximum value in the entire dp array will give us the length of the longest common substring.</p> <p>tabulation</p> <pre><code>int longestCommonSubstr (string S1, string S2, int n, int m){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n+1 , vector&lt;int&gt;(m+1 , -1));\n    for(int j = 0 ; j &lt;= m ; j++){\n        dp[0][j] = 0;\n    }\n    for(int i = 0 ; i &lt;= n ; i++){\n        dp[i][0] = 0;\n    }\n\n    int ans = 0;\n    for(int i = 1 ; i &lt;= n ; i++){\n        for(int j = 1 ; j &lt;= m ; j++){\n            if(S1[i-1] == S2[j-1]){\n                dp[i][j] = 1 + dp[i-1][j-1];\n                ans = max(ans , dp[i][j]);\n            }\n            else{\n                dp[i][j] = 0;\n            }\n        }\n    }\n\n    return ans;\n}\n</code></pre> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/dp/categorize_dp/subsequences_subset/","title":"DP on Subsequences/Subset","text":""},{"location":"dsa/dp/categorize_dp/subsequences_subset/#what-is-a-subsequence","title":"What is a Subsequence?","text":"<p>As the name suggests, a subsequence is a sequence of the elements of the array obtained by deleting some elements of the array. One important thing related to the subsequence is that even after deleting some elements, the sequence of the array elements is not changed. Both the string and arrays can have subsequences.</p> <ul> <li>We can have 2^n subsequences of an array since we keep the original ordering, this is the same as subsets of an array.</li> </ul> <p></p> Code to Find All Subsequences <pre><code>void generateSubsequences(int arr[], int index, vector&lt;int&gt; subarray, int n) {\n\n    if (index == n) {\n        for (auto i : subarray)\n            cout &lt;&lt; i &lt;&lt; \" \";\n\n        if (subarray.size() == 0)\n            cout &lt;&lt; \"[]\";\n        cout &lt;&lt; endl;\n        return;\n    }\n    else {\n\n        subarray.push_back(arr[index]);\n        generateSubsequences(arr, index + 1, subarray, n);\n\n        subarray.pop_back();\n        generateSubsequences(arr, index + 1, subarray, n);\n    }\n}\n\nint main() {\n    int arr[] = {1, 2, 3};\n    int n = sizeof(arr) / sizeof(arr[0]);\n    vector&lt;int&gt; subarray;\n\n    cout &lt;&lt; \"All the subsequences are: \" &lt;&lt; endl;\n    generateSubsequences(arr, 0, subarray, n);\n    return 0;\n}\n</code></pre>"},{"location":"dsa/dp/categorize_dp/subsequences_subset/#what-is-a-subset","title":"What is a Subset?","text":"<p>A subset is often confused with subarray and subsequence but a subset is nothing but any possible combination of the original array (or a set).</p> <ul> <li>We can have 2^(size of the array) i.e. 2^n subsets of an array.</li> </ul> <p>For example, the subsets of array arr = [1, 2, 3, 4, 5] can be:</p> <p>[3, 1] [2, 5] [1, 2], etc.</p> Code to Find All Subsets <pre><code>void generateSubsets(int arr[], int n) {\n\n    int powerSet = pow(2, n);\n    for (int counter = 0; counter &lt; powerSet; counter++) {\n        for (int i = 0; i &lt; n; i++) {\n            // if the i-th bit is set then print the i-th element\n            if (counter &amp; (1 &lt;&lt; i))\n                cout &lt;&lt; arr[i] &lt;&lt; \" \";\n        }\n        cout &lt;&lt; endl;\n    }\n}\n</code></pre>"},{"location":"dsa/dp/categorize_dp/subsequences_subset/#what-is-a-subarray","title":"What is a Subarray?","text":"<p>Well, a subarray is nothing but a slice of these contiguous memory locations of the actual array. In simpler terms, a subarray is nothing but any contiguous part of a given array. The subarray has the same sequence of elements (order of the elements) as it is in the array.</p> <ul> <li>So, we can have n * (n+1)/2 non-empty subarrays of an array.</li> </ul> <p></p> Code to find All Subarrays <pre><code>void generateSubArrays(int arr[], int n) {\n\n    for (int i = 0; i &lt; n; i++) {\n        for (int j = i; j &lt; n; j++) {\n\n            // Printing the subarray between the current \n            // starting point i.e. i and the current ending point i.e. j\n            for (int k = i; k &lt;= j; k++)\n                cout &lt;&lt; arr[k] &lt;&lt; \" \";\n            cout &lt;&lt; endl;\n        }\n    }\n}\n</code></pre>"},{"location":"dsa/dp/categorize_dp/subsequences_subset/#questions","title":"Questions","text":"<p>\ud83d\udca1 In the below questions try to draw the recursion's diagram of each problem on the \ud83d\udcdd paper.</p> Subset sum equal to target <ul> <li>Subset sum equal to target (gfg)</li> </ul> <p>memoization</p> <pre><code>bool solver(vector&lt;int&gt; &amp;arr , int sum , int n , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n    if(sum == 0){\n        return true;\n    }\n    if(n == 0){\n        return arr[0] == sum;\n    }\n\n    if(dp[n][sum] != -1){\n        return dp[n][sum];\n    }\n\n    bool not_take = solver(arr , sum , n-1 , dp);\n\n    bool take = false;\n    if(arr[n] &lt;= sum){\n        take = solver(arr , sum-arr[n] , n-1 , dp);\n    }\n\n    return dp[n][sum] = take || not_take;\n}\n\nbool isSubsetSum(vector&lt;int&gt;arr, int sum){\n\n    int n = arr.size();\n    vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (sum+1 , -1));\n\n    return solver(arr , sum , n-1 , dp);\n}\n</code></pre> <p>tabulation</p> <pre><code>bool tabulation(vector&lt;int&gt; &amp;arr , int sum , int n){\n\n    vector&lt;vector&lt;bool&gt;&gt; dp(n , vector&lt;bool&gt; (sum+1 , false));\n    for (int i = 0; i &lt; n; i++) {\n        dp[i][0] = true;\n    }\n\n    if (arr[0] &lt;= sum) {\n        dp[0][arr[0]] = true;\n    }\n\n    for(int i = 1 ; i &lt; n ; i++){\n        for(int j = 1 ; j &lt;= sum ; j++){\n\n            bool not_take = dp[i-1][j];\n            bool take = false;\n            if(arr[i] &lt;= j)\n                take = dp[i-1][j-arr[i]];\n\n            dp[i][j] = take || not_take;\n        }\n    }\n\n    return dp[n-1][sum];\n}\n</code></pre> Partition Equal Subset Sum <ul> <li>Partition Equal Subset Sum (leetcode)</li> </ul> <p>memoization</p> <pre><code>class Solution {\npublic:\n\n    bool solver(vector&lt;int&gt; &amp;nums , int n , int target , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(target == 0){\n            return true;\n        }\n        if(n == 0){\n            return nums[n] == target;\n        }\n\n        if(dp[n][target] != -1){\n            return dp[n][target];\n        }\n\n        int not_picked = solver(nums , n-1 , target , dp);\n        int picked = false;\n        if(nums[n] &lt;= target)\n            picked = solver(nums , n-1 , target-nums[n] , dp);\n\n        return dp[n][target] = not_picked || picked;\n    }\n\n    bool canPartition(vector&lt;int&gt;&amp; nums) {\n\n        int sum = 0;\n        int n = nums.size();\n        for(int i = 0 ; i &lt; n ; i++){\n            sum += nums[i];\n        }\n\n        int target = 0;\n        if(sum%2 == 0){\n            target = sum/2;\n        }\n        else{\n            return false;\n        }\n\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (target+1 , -1));\n        return solver(nums , n-1 , target , dp);\n    }\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> Count Subsets with Sum K <ul> <li>Count Subsets with Sum K (gfg)</li> </ul> <p>memoization</p> <pre><code>class Solution{\n   public:\n    int mod = 1e9+7;\n    int solver(int arr[] , int n , int sum , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n &lt; 0){\n            if(sum == 0)\n                return 1;\n            else\n                return 0;\n        }\n\n        if(dp[n][sum] != -1){\n            return dp[n][sum];\n        }\n\n        int not_take = solver(arr , n-1 , sum , dp);\n        int take = 0;\n        if(arr[n] &lt;= sum)\n            take = solver(arr , n-1 , sum-arr[n] , dp);\n\n        return dp[n][sum] = (take+not_take)%mod;\n    }\n\n    int perfectSum(int arr[], int n, int sum){\n\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt;(sum+1 , -1));\n        return solver(arr , n-1 , sum , dp);\n    }\n\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> Count Partitions with Given Difference <ul> <li>Count Partitions with Given Difference (gfg)</li> </ul> <p>memoization</p> <pre><code>class Solution{\n   public:\n    int mod = (int)(1e9 + 7);\n    int solver(int n , vector&lt;int&gt; &amp;arr , int target_sum , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n &lt; 0){\n            if(target_sum == 0){\n                return 1;\n            }\n            else{\n                return 0;\n            }\n        }\n\n        if(dp[n][target_sum] != -1){\n            return dp[n][target_sum];\n        }\n\n        int not_take = solver(n-1 , arr , target_sum , dp);\n        int take = 0;\n        if(arr[n] &lt;= target_sum)\n            take = solver(n-1 , arr , target_sum - arr[n] , dp);\n\n        return dp[n][target_sum] = (take+not_take)%mod;\n    }\n\n    int countPartitions(int n, int d, vector&lt;int&gt;&amp; arr) {\n\n        int sum = 0;\n        for(int i = 0 ; i &lt; n ; i++){\n            sum += arr[i];\n        }\n\n        if((sum-d)%2 != 0 || sum &lt; d){\n            return 0;\n        }\n\n        int target_sum = (sum-d)/2;\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (target_sum+1 , -1));\n\n        return solver(n-1 , arr , target_sum , dp);\n    }\n\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> 0/1 Knapsack <ul> <li>0/1 Knapsack (gfg)</li> </ul> <p>memoization</p> <pre><code>class Solution{\n   public:\n    int solver(int w , int wt[] , int val[] , int n , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n == 0){\n            if(wt[n] &lt;= w)\n                return val[n];\n            else\n                return 0;\n        }\n\n        if(dp[n][w] != -1){\n            return dp[n][w];\n        }\n\n        int pick = INT_MIN;\n        if(wt[n] &lt;= w)\n            pick = val[n] + solver(w-wt[n] , wt , val , n-1 , dp);\n        int not_pick = 0 + solver(w , wt , val , n-1 , dp);\n\n        return dp[n][w] = max(pick , not_pick);\n    }\n\n    int knapSack(int W, int wt[], int val[], int n){ \n\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (W+1 , -1));\n        return solver(W , wt , val , n-1 , dp);\n    }\n\n};\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(int w , int wt[] , int val[] , int n){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (w+1 , 0));\n    for(int i = wt[0] ; i &lt;= w ; i++){\n        dp[0][i] = val[0];\n    }\n\n    for(int i = 1 ; i &lt; n ; i++){\n        for(int j = 0 ; j &lt;= w ; j++){\n\n            int not_pick = 0 + dp[i-1][j];\n\n            int pick = INT_MIN;\n            if(wt[i] &lt;= j)\n                pick = val[i] + dp[i-1][j-wt[i]];\n\n            dp[i][j] = max(pick , not_pick);\n        }\n    }\n\n    return dp[n-1][w];\n}\n</code></pre> Minimum Coins/Coin Change <ul> <li>Minimum Coins/Coin Change (leetcode)</li> </ul> <p>Steps to form the recursive solution :-</p> <p>Base Cases:</p> <ul> <li> <p>If ind==0, it means we are at the first item, so in that case, the following cases can arise:</p> <ol> <li> <p>arr[0] = 4 and T = 12 \ud83e\udd1e \u2192 In such a case where the target is divisible by the coin element, we will return T%arr[0].</p> </li> <li> <p>arr[0] =4 and T=1 , arr[0]=3 T=10 \ud83e\udd1e \u2192 In all other cases, we will not be able to form a solution, so we will return a big number like 1e9</p> </li> </ol> </li> </ul> <p>Step 2: Try out all possible choices at a given index.</p> <ul> <li> <p>Exclude the current element in the subsequence: We first try to find a subsequence without considering the current index coin. If we exclude the current coin, the target sum will not be affected and the number of coins added to the solution will be 0. So we will call the recursive function f(ind-1,T)</p> </li> <li> <p>Include the current element in the subsequence: We will try to find a subsequence by considering the current icoin. As we have included the coin, the target sum will be updated to T-arr[ind] and we have considered 1 coin to our solution.</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 Now here is the catch, as there is an unlimited supply of coins, we want to again form a solution with the same coin value. So we will not recursively call for f(ind-1, T-arr[ind]) rather we will stay at that index only and call for f(ind, T-arr[ind]) to find the answer.</p> <p>memoization</p> <pre><code>class Solution {\n   public:\n\n    int solver(vector&lt;int&gt; &amp;coins , int amount , int n , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n == 0){\n            if(amount%coins[n] == 0){\n                return amount/coins[n];\n            }\n            else{\n                return 1e9;\n            }\n        }\n\n        if(dp[n][amount] != -1){\n            return dp[n][amount];\n        }\n\n        int not_picked = 0 + solver(coins , amount , n-1 , dp);\n        int picked = INT_MAX;\n        if(coins[n] &lt;= amount)\n            picked = 1 + solver(coins , amount-coins[n] , n , dp);\n\n        return dp[n][amount] = min(picked , not_picked);\n    }\n\n    int coinChange(vector&lt;int&gt;&amp; coins, int amount) {\n\n        int n = coins.size();\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (amount+1 , -1));\n        int ans = solver(coins , amount , n-1 , dp);\n\n        if(ans == 1e9) return -1;\n        return ans;\n    }\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> Target Sum <ul> <li>Target Sum (leetcode)</li> </ul> <p></p> <ul> <li>Look at the above image and try to find out the relation between s1 - s2 = d , here d = target of this given question.</li> <li>And also look at the question Count Partitions with Given Difference in the above questions list.</li> </ul> <p>memoization</p> <pre><code>class Solution {\n   public:\n\n    int solver(int n , vector&lt;int&gt; &amp;nums , int target_sum , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n &lt; 0){\n            if(target_sum == 0){\n                return 1;\n            }\n            else{\n                return 0;\n            }\n        }\n\n        if(dp[n][target_sum] != -1){\n            return dp[n][target_sum];\n        }\n\n        int not_take = solver(n-1 , nums , target_sum , dp);\n        int take = 0;\n        if(nums[n] &lt;= target_sum)\n            take = solver(n-1 , nums , target_sum - nums[n] , dp);\n\n        return dp[n][target_sum] = take+not_take;\n    }\n\n    int findTargetSumWays(vector&lt;int&gt;&amp; nums, int target) {\n\n        int sum = 0;\n        int n = nums.size();\n        for(int i = 0 ; i &lt; n ; i++){\n            sum += nums[i];\n        }\n\n        if((sum-target)%2 != 0 || sum &lt; target){\n            return 0;\n        }\n\n        int target_sum = (sum-target)/2;\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (target_sum+1 , -1));\n\n        return solver(n-1 , nums , target_sum , dp);\n    }\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> Coin Change II <ul> <li>Coin Change II (leetcode)</li> </ul> <p>memoization</p> <pre><code>class Solution {\n  public:\n\n    int solver(int amount , vector&lt;int&gt; &amp;coins , int n , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n == 0){\n            if(amount%coins[n] == 0){\n                return 1;\n            }\n            else{\n                return 0;\n            }\n        }\n\n        if(dp[n][amount] != -1){\n            return dp[n][amount];\n        }\n\n        int not_take = solver(amount , coins , n-1 , dp);\n        int take = 0;\n        if(coins[n] &lt;= amount)\n            take = solver(amount-coins[n] , coins , n , dp);\n\n        return dp[n][amount] = take + not_take;\n    }\n\n    int change(int amount, vector&lt;int&gt;&amp; coins) {\n\n        int n = coins.size();\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (amount +1 , -1));\n        int ans = solver(amount , coins , n-1 , dp);\n\n        return ans;\n    }\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> Unbounded Knapsack <ul> <li>Unbounded Knapsack (gfg)</li> </ul> <p>memoization</p> <pre><code>class Solution{\n   public:\n    int solver(int n , int w , int val[] , int wt[] , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n == 0){\n            if(wt[n] &lt;= w){\n                return (w/wt[n])*val[n];\n            }\n            else{\n                return 0;\n            }\n        }\n\n        if(dp[n][w] != -1){\n            return dp[n][w];\n        }\n\n        int not_pick = 0 + solver(n-1 , w , val , wt , dp);\n        int pick = INT_MIN;\n        if(wt[n] &lt;= w){\n            pick = val[n] + solver(n , w-wt[n] , val , wt , dp);\n        }\n\n        return dp[n][w] = max(pick , not_pick);\n    }\n\n    int knapSack(int N, int W, int val[], int wt[]){\n\n        vector&lt;vector&lt;int&gt;&gt; dp(N , vector&lt;int&gt; (W+1 , -1));\n        return solver(N-1 , W , val , wt , dp);\n    }\n\n};\n</code></pre> <p>tabulation</p> <pre><code>int tabulation(int n , int w , int val[] , int wt[]){\n\n    vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (w+1 , -1));\n    for(int i = 0 ; i &lt;= w ; i++){\n        dp[0][i] = (i/wt[0])*val[0];\n    }\n\n    for(int i = 1 ; i &lt; n ; i++){\n        for(int j = 0 ; j &lt;= w ; j++){\n\n            int not_pick = dp[i-1][j];\n\n            int pick = INT_MIN;\n            if(wt[i] &lt;= j)\n                pick = val[i] + dp[i][j-wt[i]];\n\n            dp[i][j] = max(pick , not_pick);\n        }\n    }\n\n    return dp[n-1][w];\n}\n</code></pre> Rod Cutting Problem <ul> <li>Rod Cutting Problem (gfg)</li> </ul> <p>memoization</p> <pre><code>class Solution{\n   public:\n    int solver(int price[] , int n , int rod_length , vector&lt;vector&lt;int&gt;&gt; &amp;dp){\n\n        if(n == 0){\n            return rod_length*price[n];\n        }\n\n        if(dp[n][rod_length] != -1){\n            return dp[n][rod_length];\n        }\n\n        int not_pick = 0 + solver(price , n-1 , rod_length , dp);\n        int pick = INT_MIN;\n        if(rod_length &gt;= n+1)\n            pick = price[n] + solver(price , n , rod_length-(n+1) , dp);\n\n        return dp[n][rod_length] = max(pick , not_pick);\n    }\n\n    int cutRod(int price[], int n) {\n\n        vector&lt;vector&lt;int&gt;&gt; dp(n , vector&lt;int&gt; (n+1 , -1));\n        return solver(price , n-1 , n , dp);\n    }\n\n};\n</code></pre> <p>tabulation</p> <pre><code>\n</code></pre> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/graph/","title":"Graph","text":""},{"location":"dsa/graph/#contents","title":"Contents","text":""},{"location":"dsa/graph/introduction/","title":"Introduction to Graph","text":""},{"location":"dsa/graph/introduction/#what-is-graph","title":"What is Graph?","text":"<p>Graph is a non-linear data structure consisting of vertices and edges. The vertices are sometimes also referred to as nodes and the edges are lines that connect any two nodes in the graph. More formally a Graph is composed of a set of vertices( V ) and a set of edges( E ). The graph is denoted by G(V, E).</p> <p></p>"},{"location":"dsa/graph/introduction/#types-of-graph","title":"Types of Graph","text":""},{"location":"dsa/graph/introduction/#implementation-of-graph","title":"Implementation of Graph","text":"See the code <pre><code>    #include&lt;bits/stdc++.h&gt;\n    using namespace std;\n\n    class graph\n    {\n        public: \n            unordered_map&lt;int, list&lt;int&gt;&gt; adj;\n\n        void addEdge(int u, int v, bool direction)\n        {   \n            // direction 0 means undirected graph\n            // direction 1 means directed graph\n            adj[u].push_back(v);\n            if(direction == 0)\n            {\n                adj[v].push_back(u);\n            }\n        } \n\n        void printAdjList()\n        {\n            for(auto i : adj)\n            {\n                cout&lt;&lt;\"Printing adjacent list : \";\n                cout&lt;&lt;i.first&lt;&lt;\"-&gt;\";\n                for(auto j : i.second)\n                {\n                    cout&lt;&lt;j&lt;&lt;\", \";\n                }\n                cout&lt;&lt;endl;\n            }\n        } \n    };\n\n    int main()\n    {\n        int n, m;\n        cout&lt;&lt;\"Enter the number of nodes : \"&lt;&lt;endl;\n        cin&gt;&gt;n;\n\n        cout&lt;&lt;\"Enter the number of edges : \"&lt;&lt;endl;\n        cin&gt;&gt;m;\n\n        graph g;\n\n        cout&lt;&lt;\"Enter the edges : \"&lt;&lt;endl;\n        for(int i = 0; i&lt;m; i++)\n        {\n            int u, v;\n            cin&gt;&gt; u &gt;&gt; v;\n\n            g.addEdge(u, v, 0);\n        }\n\n        g.printAdjList();\n    }\n</code></pre>"},{"location":"dsa/graph/introduction/#representations-of-graph","title":"Representations of Graph","text":"<p>There are two most common ways to represent a graph :</p> <ol> <li>Adjacency Matrix</li> <li>Adjacency List</li> </ol>"},{"location":"dsa/graph/introduction/#adjacency-matrix-representation","title":"Adjacency Matrix Representation","text":"See the code <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main()\n{\n    int n, m;\n    cin &gt;&gt; n &gt;&gt; m;\n    // adjacency matrix for undirected graph\n    // time complexity: O(n)\n    int adj[n+1][n+1];\n    for(int i = 0; i &lt; m; i++)\n    {\n        int u, v;\n        cin &gt;&gt; u &gt;&gt; v;\n        adj[u][v] = 1;\n        adj[v][u] = 1; // this statement will be removed in case of directed graph\n    }\n    return 0;\n}\n</code></pre>"},{"location":"dsa/graph/introduction/#adjacency-list-representation","title":"Adjacency List Representation","text":"See the code <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main()\n{\n    int n, m;\n    cin &gt;&gt; n &gt;&gt; m;\n    // adjacency list for undirected graph\n    // time complexity: O(2E)\n    vector&lt;int&gt; adj[n+1];\n    for(int i = 0; i &lt; m; i++)\n    {\n        int u, v;\n        cin &gt;&gt; u &gt;&gt; v;\n        adj[u].push_back(v);\n        adj[v].push_back(u); // this statement will be removed in case of directed graph\n    }\n    return 0;\n}\n</code></pre>"},{"location":"dsa/graph/question/","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> DFS &amp; BFS <ul> <li> <p>Number of provinces (leetcode)</p> </li> <li> <p>Rotten Oranges (leetcode)</p> </li> <li> <p>Flood fill (leetcode)</p> </li> <li> <p>0/1 Matrix (leetcode)</p> </li> <li> <p>Surrounded Regions (leetcode)</p> </li> <li> <p>Number of Enclaves (leetcode)</p> </li> <li> <p>Word ladder-1 (leetcode)</p> </li> <li> <p>Word ladder-2 (leetcode)</p> </li> <li> <p>Is Graph Bipartite? (leetcode)</p> </li> </ul> Topo Sort <ul> <li> <p>Topological sort (gfg)</p> </li> <li> <p>Course Schedule - I (leetcode)</p> </li> <li> <p>Course Schedule - II (leetcode)</p> </li> <li> <p>Find eventual safe states (leetcode)</p> </li> <li> <p>Alien dictionary (leetcode)</p> </li> </ul> Shortest Path Algorithms and Problems <ul> <li> <p>Shortest Path in UG with unit weights (gfg)</p> </li> <li> <p>Shortest Path in DAG (gfg)</p> </li> <li> <p>Djisktra's Algorithm (gfg)</p> </li> <li> <p>Shortest Path in Weighted undirected graph (gfg)</p> </li> <li> <p>Shortest path in a binary matrix (leetcode)</p> </li> <li> <p>Path with minimum effort (leetcode)</p> </li> <li> <p>Cheapest flights within k stops (leetcode)</p> </li> <li> <p>Network Delay time (leetcode)</p> </li> <li> <p>Number of ways to arrive at destination (leetcode)</p> </li> <li> <p>Minimum Multiplications to reach End (gfg)</p> </li> <li> <p>Bellman Ford Algorithm (gfg)</p> </li> <li> <p>Floyd Warshal Algorithm (gfg)</p> </li> <li> <p>Find the city with the smallest number of neighbors in a threshold distance (leetcode)</p> </li> </ul> MinimumSpanningTree/Disjoint Set and Problems <ul> <li> <p>Minimum Spanning Tree [ Prim's/Kruskal's Algorithm ] (gfg)</p> </li> <li> <p>Disjoint Set [Union by Rank &amp; size] (gfg)</p> </li> <li> <p>Number of operations to make network connected (leetcode)</p> </li> <li> <p>Most Stones Removed with Same Row or Column (leetcode)</p> </li> <li> <p>Accounts merge (leetcode)</p> </li> <li> <p>Number of island II (leetcode)</p> </li> <li> <p>Making a Large Island (leetcode)</p> </li> <li> <p>Swim in rising water (leetcode)</p> </li> </ul> Other Algorithms Problems <ul> <li> <p>Bridges in Graph (leetcode)</p> </li> <li> <p>Articulation Point (gfg)</p> </li> <li> <p>Kosaraju's Algorithm (gfg)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/","title":"Disjoint Set (<code>Union By Rank | Union by Size</code>)","text":"<ul> <li>Disjoint Set data structure which is a <code>very important topic</code> in the entire graph series.</li> </ul> <p>Question: Given two components of an undirected graph</p> <p></p> <p>The question is whether node 1 and node 5 are in the same component or not.</p> <p>Approach:</p> <ul> <li> <p>Now, in order to solve this question we can use either the DFS or BFS traversal technique like if we traverse the components of the graph we can find that node 1 and node 5 are not in the same component. This is actually the brute force approach whose time complexity is O(N+E)(N = no. of nodes, E = no. of edges). </p> </li> <li> <p>But using a Disjoint Set data structure we can solve this same problem in <code>constant time</code>.</p> </li> </ul> <ul> <li>The disjoint Set data structure is generally used for dynamic graphs.</li> </ul>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#dynamic-graphs","title":"Dynamic graphs","text":"<p>A dynamic graph generally refers to a graph that keeps on changing its configuration. Let\u2019s deep dive into it using an example:</p> <ul> <li> <p>Let\u2019s consider the edge information for the given graph as: {{1,2}, {2,3}, {4,5}, {6,7}, {5,6}, {3,7}}. Now if we start adding the edges one by one, in each step the structure of the graph will change. So, after each step, if we perform the same operation on the graph while updating the edges, the result might be different. In this case, the graph will be considered a dynamic graph.</p> </li> <li> <p>For example, after adding the first 4 edges if we look at the graph, we will find that node 4 and node 1 belong to different components but after adding all 6 edges if we search for the same we will figure out that node 4 and node 1 belong to the same component.</p> </li> </ul> <p></p> <ul> <li>So, after any step, if we try to figure out whether two arbitrary nodes u and v belong to the same component or not, Disjoint Set will be able to answer this query in constant time.</li> </ul>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#functionalities-of-disjoint-set-data-structure","title":"Functionalities of Disjoint Set data structure","text":"<p>The disjoint set data structure generally provides two types of functionalities:</p> <ul> <li> <p>Finding the ultimate parent for a particular node (findPar())</p> </li> <li> <p>Union (in broad terms this method basically adds an edge between two nodes)</p> <ul> <li>Union by rank</li> <li>Union by size</li> </ul> </li> </ul>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#rank","title":"Rank","text":"<p>The rank of a node generally refers to the distance (the number of nodes including the leaf node) between the furthest leaf node and the current node. Basically rank includes all the nodes beneath the current node.</p> <p></p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#ultimate-parent","title":"Ultimate parent","text":"<p>The parent of a node generally refers to the node right above that particular node. But the ultimate parent refers to the topmost node or the root node.</p> <p></p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#path-compression","title":"Path compression","text":"<p>Basically, connecting each node in a particular path to its ultimate parent refers to path compression. Let\u2019s understand it using the following illustration:</p> <p></p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#algorithm","title":"Algorithm","text":"<p>Initial configuration</p> <p>rank array: This array is initialized with zero.</p> <p>parent array: The array is initialized with the value of nodes i.e. parent[i] = i.</p> <p>The algorithm steps</p> <ul> <li> <p>Firstly, the Union function requires two nodes(let\u2019s say u and v) as arguments. Then we will find the ultimate parent (using the findPar() function that is discussed later) of u and v. Let\u2019s consider the ultimate parent of u is pu and the ultimate parent of v is pv.</p> </li> <li> <p>After that, we will find the rank of pu and pv.</p> </li> <li> <p>Finally, we will connect the ultimate parent with a smaller rank to the other ultimate parent with a larger rank. But if the ranks are equal, we can connect any parent to the other parent and we will increase the rank by one for the parent node to whom we have connected the other one.</p> </li> </ul>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#code","title":"Code","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\nclass DisjointSet {\n    vector&lt;int&gt; rank, parent;\npublic:\n    DisjointSet(int n) {\n        rank.resize(n + 1, 0);\n        parent.resize(n + 1);\n\n        // initially, everyone is self-parent.\n        for (int i = 0; i &lt;= n; i++) {\n            parent[i] = i;\n        }\n    }\n\n    int findUPar(int node) {\n        if (node == parent[node])\n            return node;\n        return parent[node] = findUPar(parent[node]); // path compression\n    }\n\n    void unionByRank(int u, int v) {\n        int ulp_u = findUPar(u);  // ulp means ultimate parent\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (rank[ulp_u] &lt; rank[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n        }\n        else if (rank[ulp_v] &lt; rank[ulp_u]) {\n            parent[ulp_v] = ulp_u;\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            rank[ulp_u]++;\n        }\n    }\n};\nint main() {\n    DisjointSet ds(7);\n    ds.unionByRank(1, 2);\n    ds.unionByRank(2, 3);\n    ds.unionByRank(4, 5);\n    ds.unionByRank(6, 7);\n    ds.unionByRank(5, 6);\n    // if 3 and 7 same or not\n    if (ds.findUPar(3) == ds.findUPar(7)) {\n        cout &lt;&lt; \"Same\\n\";\n    }\n    else cout &lt;&lt; \"Not same\\n\";\n\n    ds.unionByRank(3, 7);\n\n    if (ds.findUPar(3) == ds.findUPar(7)) {\n        cout &lt;&lt; \"Same\\n\";\n    }\n    else cout &lt;&lt; \"Not same\\n\";\n    return 0;\n}\n</code></pre>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#time-complexity","title":"Time complexity \u23f2\ufe0f","text":"<p>The actual time complexity is O(4* alpha) which is very small and close to 1.</p> <ul> <li>So, we assume it to be of <code>constant time-complexity</code>.</li> <li>Exact derivation of the time-complexity is a very long &amp; tedious mathematical proof. So, don't worry!</li> </ul>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#follow-up-in-the-union-by-rank-method-why-do-we-need-to-connect-the-smaller-rank-to-the-larger-rank","title":"Follow up: In the union by rank method, why do we need to connect the smaller rank to the larger rank? \ud83e\udd14","text":"<ul> <li>In this case, the traversal time to find the ultimate parent for nodes 3, 4, 5, 6, 7, and 8 increases and so the path compression time also increases. But if we do the following</li> </ul> <ul> <li>the traversal time to find the ultimate parent for only nodes 1 and 2 increases. So the path compression time becomes relatively lesser than in the previous case. So, we can conclude that we should always connect a smaller rank to a larger one with the goal of<ul> <li>shrinking the height of the graph.</li> <li>reducing the time complexity as much as we can.</li> </ul> </li> </ul>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Disjoint_set_union/#disjoint-set-union-by-size","title":"Disjoint Set <code>Union by size</code>","text":"<p>Sorry, What was the meaning of Rank, again?</p> <p>After applying path compression the rank of the graphs becomes distorted. So, rather than storing the rank, we can just store the size of the components for comparing which component is greater or smaller.</p> <ul> <li>So, rather than storing the rank, we can just store the size of the components for comparing which component is greater or smaller.</li> </ul> <ul> <li>Algorithm is very same as <code>Union by Rank</code>, only the <code>Size</code> word is used, which indicates the size of each node.</li> <li>We will initialize size vector with 1, and unlike in rank when doing union, we will increment size by the size of node we are appending.</li> </ul> <pre><code>class DisjointSet {\n    vector&lt;int&gt; parent, size;\npublic:\n    DisjointSet(int n) {\n        parent.resize(n + 1); // (n+1) will handle both 0-bases &amp; 1-based indexing graph\n        size.resize(n + 1);\n        for (int i = 0; i &lt;= n; i++) {\n            parent[i] = i;\n            size[i] = 1;\n        }\n    }\n\n    int findUPar(int node) {\n        if (node == parent[node])\n            return node;\n        return parent[node] = findUPar(parent[node]); // path compression\n    }\n\n    void unionByRank(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (rank[ulp_u] &lt; rank[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n        }\n        else if (rank[ulp_v] &lt; rank[ulp_u]) {\n            parent[ulp_v] = ulp_u;\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            rank[ulp_u]++;\n        }\n    }\n\n    void unionBySize(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (size[ulp_u] &lt; size[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n            size[ulp_v] += size[ulp_u];\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            size[ulp_u] += size[ulp_v];\n        }\n    }\n};\n</code></pre>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Kruskals_Algorithm/","title":"Kruskal's Algorithm","text":""},{"location":"dsa/graph/Minimum_Spanning_Tree/Kruskals_Algorithm/#kruskals-algorithm-minimum-spanning-tree","title":"Kruskal's Algorithm - Minimum Spanning Tree","text":"<p>We will be implementing Kruskal\u2019s algorithm using the Disjoint Set data structure. Kruskal\u2019s algorithm to find the minimum cost spanning tree uses the greedy approach.</p> The algorithm steps are as follows :- <ul> <li> <p>First, we need to extract the edge information(if not given already) from the given adjacency list in the format of (wt, u, v) where u is the current node, v is the adjacent node and wt is the weight of the edge between node u and v and we will store the tuples in an array.</p> </li> <li> <p>Then the array must be sorted in the ascending order of the weights so that while iterating we can get the edges with the minimum weights first.</p> </li> <li> <p>After that, we will iterate over the edge information, and for each tuple, we will apply the  following operation:</p> <ul> <li> <p>First, we will take the two nodes u and v from the tuple and check if the ultimate parents of both nodes are the same or not using the findUPar() function provided by the Disjoint Set data structure.</p> </li> <li> <p>If the ultimate parents are the same, we need not do anything to that edge as there already exists a path between the nodes and we will continue to the next tuple.</p> </li> <li> <p>If the ultimate parents are different, we will add the weight of the edge to our final answer (i.e. mstWt variable used in the following code) and apply the union operation(i.e. either unionBySize(u, v) or unionByRank(u, v)) with the nodes u and v. The union operation is also provided by the Disjoint Set.</p> </li> </ul> </li> </ul> <p></p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Kruskals_Algorithm/#code","title":"Code","text":"<pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass DisjointSet {\n    vector&lt;int&gt; rank, parent, size;\npublic:\n    DisjointSet(int n) {\n        rank.resize(n + 1, 0);\n        parent.resize(n + 1);\n        size.resize(n + 1);\n        for (int i = 0; i &lt;= n; i++) {\n            parent[i] = i;\n            size[i] = 1;\n        }\n    }\n\n    int findUPar(int node) {\n        if (node == parent[node])\n            return node;\n        return parent[node] = findUPar(parent[node]);\n    }\n\n    void unionByRank(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (rank[ulp_u] &lt; rank[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n        }\n        else if (rank[ulp_v] &lt; rank[ulp_u]) {\n            parent[ulp_v] = ulp_u;\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            rank[ulp_u]++;\n        }\n    }\n\n    void unionBySize(int u, int v) {\n        int ulp_u = findUPar(u);\n        int ulp_v = findUPar(v);\n        if (ulp_u == ulp_v) return;\n        if (size[ulp_u] &lt; size[ulp_v]) {\n            parent[ulp_u] = ulp_v;\n            size[ulp_v] += size[ulp_u];\n        }\n        else {\n            parent[ulp_v] = ulp_u;\n            size[ulp_u] += size[ulp_v];\n        }\n    }\n};\nclass Solution\n{\npublic:\n    //Function to find sum of weights of edges of the Minimum Spanning Tree.\n    int spanningTree(int V, vector&lt;vector&lt;int&gt;&gt; adj[])\n    {\n        // 1 - 2 wt = 5\n        /// 1 - &gt; (2, 5)\n        // 2 -&gt; (1, 5)\n\n        // 5, 1, 2\n        // 5, 2, 1\n        vector&lt;pair&lt;int, pair&lt;int, int&gt;&gt;&gt; edges;\n        for (int i = 0; i &lt; V; i++) {\n            for (auto it : adj[i]) {\n                int adjNode = it[0];\n                int wt = it[1];\n                int node = i;\n\n                edges.push_back({wt, {node, adjNode}});\n            }\n        }\n\n        DisjointSet ds(V); // ds is DisjointSet class object\n\n        sort(edges.begin(), edges.end());\n        int mstWt = 0;\n        for (auto it : edges) {\n            int wt = it.first;\n            int u = it.second.first;\n            int v = it.second.second;\n\n            if (ds.findUPar(u) != ds.findUPar(v)) {\n                mstWt += wt;\n                ds.unionBySize(u, v);\n            }\n        }\n\n        return mstWt;\n    }\n};\n</code></pre>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Kruskals_Algorithm/#time-complexity","title":"Time Complexity","text":"<p>O(N+E) + O(E logE) + O(E*4\u03b1*2)   where N = no. of nodes and E = no. of edges. O(N+E) for extracting edge information from the adjacency list. O(E logE) for sorting the array consists of the edge tuples. Finally, we are using the disjoint set operations inside a loop. The loop will continue to E times. Inside that loop, there are two disjoint set operations like findUPar() and UnionBySize() each taking 4 and so it will result in 4*2. That is why the last term O(E*4*2) is added.</p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Kruskals_Algorithm/#space-complexity","title":"Space Complexity","text":"<p>O(N) + O(N) + O(E) where E = no. of edges and N = no. of nodes. O(E) space is taken by the array that we are using to store the edge information. And in the disjoint set data structure, we are using two N-sized arrays i.e. a parent and a size array (as we are using unionBySize() function otherwise, a rank array of the same size if unionByRank() is used) which result in the first two terms O(N).</p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Prims_Algorithm/","title":"Prim's Algorithm","text":""},{"location":"dsa/graph/Minimum_Spanning_Tree/Prims_Algorithm/#prims-algorithm-minimum-spanning-tree","title":"Prim's Algorithm - Minimum Spanning Tree","text":"<p>Prim's algorithm is a minimum spanning tree algorithm that takes a graph as input and finds the subset of the edges of that graph which</p> <ul> <li>form a tree that includes every vertex.</li> <li>has the minimum sum of weights among all the trees that can be formed from the graph</li> </ul> The steps for implementing Prim's algorithm <ol> <li>Initialize the minimum spanning tree with a vertex chosen at random.</li> <li>Find all the edges that connect the tree to new vertices, find the minimum and add it to the tree.</li> <li>Keep repeating step 2 until we get a minimum spanning tree.</li> </ol> <pre><code>class Solution{\npublic:\n    //Function to find sum of weights of edges of the Minimum Spanning Tree.\n    int spanningTree(int V, vector&lt;vector&lt;int&gt;&gt; adj[]){\n\n        priority_queue&lt;pair&lt;int, int&gt;,vector&lt;pair&lt;int, int&gt; &gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; pq;\n        vector&lt;int&gt; vis(V, 0);\n        // {wt, node}\n        pq.push({0, 0});\n        int sum = 0;\n        while (!pq.empty()) {\n            auto it = pq.top();\n            pq.pop();\n            int node = it.second;\n            int wt = it.first;\n\n            if (vis[node] == 1) continue;\n            // add it to the mst\n            vis[node] = 1;\n            sum += wt;\n            for (auto it : adj[node]) {\n                int adjNode = it[0];\n                int edW = it[1];\n                if (!vis[adjNode]) {\n                    pq.push({edW, adjNode});\n                }\n            }\n        }\n        return sum;\n    }\n};\n</code></pre>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Prims_Algorithm/#time-complexity","title":"Time Complexity","text":"<p>O(E*logE) + O(E*logE)~ O(E*logE), where E = no. of given edges. -&gt; The maximum size of the priority queue can be E so after at most E iterations the priority queue will be empty and the loop will end. Inside the loop, there is a pop operation that will take logE time. This will result in the first O(E*logE) time complexity. Now, inside that loop, for every node, we need to traverse all its adjacent nodes where the number of nodes can be at most E. If we find any node unvisited, we will perform a push operation and for that, we need a logE time complexity. So this will result in the second O(E*logE).</p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/Prims_Algorithm/#space-complexity","title":"Space Complexity","text":"<p>O(E) + O(V), where E = no. of edges and V = no. of vertices.</p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/intro/","title":"Minimum spanning trees","text":""},{"location":"dsa/graph/Minimum_Spanning_Tree/intro/#what-are-spanning-trees","title":"What are spanning trees?","text":"<p>A spanning tree is a subset of Graph G, such that all the vertices are connected using minimum possible number of edges.</p> <ul> <li>Hence, a spanning tree does not have cycles</li> <li>a graph may have more than one spanning tree</li> <li>Every node is reachable by another node.</li> </ul> <p>Info</p> <p>Spanning tree</p> <ul> <li>n nodes (vertices)</li> <li>(n-1) edges</li> </ul> <p></p>"},{"location":"dsa/graph/Minimum_Spanning_Tree/intro/#properties-of-spanning-tree","title":"Properties of Spanning tree","text":"<ul> <li>A Spanning tree does not exist for a disconnected graph.</li> <li>For a connected graph having N vertices then the number of edges in the spanning tree for that graph will be N-1.</li> <li>A Spanning tree does not have any cycle.</li> <li>We can construct a spanning tree for a complete graph by removing E-N+1 edges, where E is the number of Edges and N is the number of vertices.</li> <li>Algorithms like <code>Dijkstra</code> &amp; <code>A* search</code> algorithm internally build a spanning tree as an intermediate step.</li> </ul>"},{"location":"dsa/graph/Minimum_Spanning_Tree/intro/#minimum-spanning-tree","title":"Minimum Spanning tree","text":"<ul> <li>A spanning tree with minimum sum of weights.</li> </ul>"},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/","title":"Detect Cycle In Directed Graph","text":""},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#detect-cycle-in-directed-graph-using-bfs","title":"Detect Cycle in directed Graph using BFS","text":""},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#intuition","title":"Intuition:","text":"<ol> <li> <p>Since we know topological sorting is only possible for directed acyclic graphs(DAGs) if we apply Kahn\u2019s algorithm in a directed cyclic graph(A directed graph that contains a cycle), it will fail to find the topological sorting(i.e. The final sorting will not contain all the nodes or vertices).</p> </li> <li> <p>So, finally, we will check the sorting to see if it contains all V vertices or not. If the result does not include all V vertices, we can conclude that there is a cycle.</p> </li> </ol> <p></p> <pre><code>// Function to detect cycle in a directed graph.\nbool isCyclic(int V, vector&lt;int&gt; adj[]) {\n    int indegree[V] = {0};\n    for (int i = 0; i &lt; V; i++) {\n        for (auto it : adj[i]) {\n            indegree[it]++;\n        }\n    }\n\n    queue&lt;int&gt; q;\n    for (int i = 0; i &lt; V; i++) {\n        if (indegree[i] == 0) {\n            q.push(i);\n        }\n    }\n\n    int cnt = 0;\n    // o(v + e)\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n        cnt++;\n        // node is in your topo sort\n        // so please remove it from the indegree\n\n        for (auto it : adj[node]) {\n            indegree[it]--;\n            if (indegree[it] == 0) q.push(it);\n        }\n    }\n\n    if (cnt == V) return false;\n    return true;\n}\n</code></pre>"},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#time-complexity","title":"Time Complexity","text":"<p>O(V+E), where V = no. of nodes and E = no. of edges. This is a simple BFS algorithm.</p>"},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#space-complexity","title":"Space Complexity","text":"<p>O(N) + O(N) ~ O(2N), O(N) for the in-degree array, and O(N) for the queue data structure used in BFS(where N = no.of nodes).</p>"},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#detect-cycle-in-an-directed-graph-using-dfs","title":"Detect Cycle in an directed Graph using DFS","text":"<p>Only we have do</p> <p>We need to create an extra <code>dfs_visited[n]</code> array to keep track of visited nodes in the current path.</p> <pre><code>class Solution{\npublic:\n\n    bool detectCycle(int start , vector&lt;int&gt; &amp;vis , vector&lt;int&gt; &amp;dfs_vis , vector&lt;int&gt; adj[]){\n\n        vis[start] = 1;\n        dfs_vis[start] = 1;\n        for(auto it : adj[start]){\n            if(vis[it] == 0){\n                bool return_val = detectCycle(it , vis , dfs_vis , adj);\n                if(return_val == true){\n                    return true;\n                }\n            }\n            else if(dfs_vis[it] == 1){\n                return true;\n            }\n        }\n        dfs_vis[start] = 0;\n\n        return false;\n    }\n\n    bool isCyclic(int V, vector&lt;int&gt; adj[]) {\n\n        vector&lt;int&gt; vis(V,0);\n        vector&lt;int&gt; dfs_vis(V,0);\n\n        for(int i = 0 ; i &lt; V ; i++){\n            if(vis[i] == 0){\n                bool cycle = detectCycle(i , vis , dfs_vis , adj);\n                if(cycle == true){\n                    return true;\n                }\n            }\n        }\n\n        return false;\n    }\n};\n</code></pre>"},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#time-complexity_1","title":"Time Complexity","text":"<p>O(V+E), where V = no. of nodes and E = no. of edges. This is a simple DFS algorithm.</p>"},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#space-complexity_1","title":"Space Complexity","text":"<p>O(N) + O(N) + 0(N) ~ O(3N), 0(N) visited array, 0(N) for dfs_visited array and O(N) Space for recursive stack space.</p>"},{"location":"dsa/graph/cycle_detection/in_directed_using_bfs_dfs/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Directed Graph Cycle <ul> <li>Directed Graph Cycle (gfg)</li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/","title":"Detect Cycle In Undirected Graph","text":""},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/#detect-cycle-in-an-undirected-graph-using-bfs","title":"Detect Cycle in an Undirected Graph using BFS","text":"<p>The intuition is that we start from a node, and start doing BFS level-wise, if somewhere down the line, we visit a single node twice, it means we came via two paths to end up at the same node. It implies there is a cycle in the graph because we know that we start from different directions but can arrive at the same node only if the graph is connected or contains a cycle, otherwise we would never come to the same node again.</p> <p></p> <p>Danger</p> <p>A graph can have connected components as well. In such cases, if any component forms a cycle then the graph is said to have a cycle.</p> <pre><code>for(int i = 1 ; i &lt;= n ; i++) {\n    if(!vis[i]) {\n        if(detect(i))\n            return true;\n    }\n}\nreturn false;\n</code></pre> <p></p> <p></p> <p>Only we have to check</p> <p>visited == true   &amp;&amp;   parent != adjacentNode</p> <pre><code>bool detect(int src, vector&lt;int&gt; adj[], int vis[]) {\n    vis[src] = 1;\n    // store &lt;source node, parent node&gt;\n    queue&lt;pair&lt;int,int&gt;&gt; q;\n    q.push({src, -1});\n    // traverse until queue is not empty\n    while(!q.empty()) {\n        int node = q.front().first;\n        int parent = q.front().second;\n        q.pop();\n\n        // go to all adjacent nodes\n        for(auto adjacentNode: adj[node]) {\n            // if adjacent node is unvisited\n            if(!vis[adjacentNode]) {\n                vis[adjacentNode] = 1;\n                q.push({adjacentNode, node});\n            }\n            // if adjacent node is visited and is not it's own parent node\n            else if(parent != adjacentNode) {\n                // yes it is a cycle\n                return true;\n            }\n        }\n    }\n    // there's no cycle\n    return false;\n}\n\n// Function to detect cycle in an undirected graph.\nbool isCycle(int V, vector&lt;int&gt; adj[]) {\n    int vis[V] = {0}; \n    // for graph with connected components \n    for(int i = 0 ; i&lt;V ; i++) {\n        if(!vis[i]) {\n            if(dfs(i, -1, vis, adj) == true) return true; \n        }\n    }\n    return false; \n}\n</code></pre>"},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/#time-complexity","title":"Time Complexity","text":"<p>O(N + 2E) + O(N), Where N = Nodes, 2E is for total degrees as we traverse all adjacent nodes. In the case of connected components of a graph, it will take another O(N) time.</p>"},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/#space-complexity","title":"Space Complexity","text":"<p>O(N) + O(N) ~ O(N), Space for queue data structure and visited array.</p>"},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/#detect-cycle-in-an-undirected-graph-using-dfs","title":"Detect Cycle in an Undirected Graph using DFS","text":"<p>The cycle in a graph starts from a node and ends at the same node. DFS is a traversal technique that involves the idea of recursion and backtracking. DFS goes in-depth, i.e., traverses all nodes by going ahead, and when there are no further nodes to traverse in the current path, then it backtracks on the same path and traverses other unvisited nodes. The intuition is that we start from a source and go in-depth, and reach any node that has been previously visited in the past, it means there's a cycle.</p> <p></p> <p></p> <p>Only we have to check</p> <p>visited == true   &amp;&amp;   parent != adjacentNode</p> <pre><code>bool dfs(int node, int parent, int vis[], vector&lt;int&gt; adj[]) {\n    vis[node] = 1; \n    // visit adjacent nodes\n    for(auto adjacentNode: adj[node]) {\n        // unvisited adjacent node\n        if(!vis[adjacentNode]) {\n            if(dfs(adjacentNode, node, vis, adj) == true) \n                return true; \n        }\n        // visited node but not a parent node\n        else if(adjacentNode != parent) return true; \n    }\n    return false; \n}\n\n// Function to detect cycle in an undirected graph.\nbool isCycle(int V, vector&lt;int&gt; adj[]) {\n    int vis[V] = {0}; \n    // for graph with connected components \n    for(int i = 0 ; i&lt;V ; i++) {\n        if(!vis[i]) {\n            if(dfs(i, -1, vis, adj) == true) return true; \n        }\n    }\n    return false; \n}\n</code></pre>"},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/#time-complexity_1","title":"Time Complexity","text":"<p>O(N + 2E) + O(N), Where N = Nodes, 2E is for total degrees as we traverse all adjacent nodes. In the case of connected components of a graph, it will take another O(N) time.</p>"},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/#space-complexity_1","title":"Space Complexity","text":"<p>O(N) + O(N) ~ O(N), Space for recursive stack space and visited array.</p>"},{"location":"dsa/graph/cycle_detection/in_undirected_using_bfs_dfs/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Undirected Graph Cycle <ul> <li>Undirected Graph Cycle (gfg)</li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/graph/important_algos/Bellman_Ford/","title":"Bellman Ford Algorithm","text":""},{"location":"dsa/graph/important_algos/Bellman_Ford/#bellman-ford-algorithm","title":"Bellman Ford Algorithm","text":"<p>Bellman-Ford is a single source shortest path algorithm that determines the shortest path between a given source vertex and every other vertex in a graph. This algorithm can be used on both weighted and unweighted graphs.</p> <ul> <li>This algorithm is only applicable for directed graphs.</li> </ul> <p></p> <p>Tip</p> <p>A Bellman-Ford algorithm is also guaranteed to find the shortest path in a graph, similar to Dijkstra\u2019s algorithm. Although Bellman-Ford is slower than Dijkstra\u2019s algorithm, it is capable of handling graphs with negative edge weights, which makes it more versatile.</p>"},{"location":"dsa/graph/important_algos/Bellman_Ford/#idea","title":"Idea \ud83e\udd14","text":"<ul> <li> <p>The Bellman-Ford algorithm\u2019s primary principle is that it starts with a single source and calculates the distance to each node.</p> </li> <li> <p>The distance is initially unknown and assumed to be infinite, but as time goes on, the algorithm relaxes those paths by identifying a few shorter paths.</p> </li> <li> <p>Hence it is said that Bellman-Ford is based on <code>Principle of Relaxation</code>.</p> </li> <li> <p>Iterate through all the edges for (n-1) times, do relaxation.</p> </li> <li>To detect cycle, iterate for the one last time (n time), and if a single relaxation is possible, means the graph contains negative cycles, and hence shortest distance can't be found.</li> </ul>"},{"location":"dsa/graph/important_algos/Bellman_Ford/#what-is-relaxation-in-bellman-ford-algorithm","title":"What is relaxation in Bellman-ford algorithm?","text":"<pre><code>// dist[] &lt;= distance of nodes from a source node\n// if there's an edge from x to y, and the dist can be reduced, do it.\n// this is called relaxation.\nif (dist[x]+wt &lt; dist[y]){\n    dist[y]=dist[x]+wt;\n}\n</code></pre>"},{"location":"dsa/graph/important_algos/Bellman_Ford/#why-iterate-for-n-1-times","title":"Why iterate for (n-1) times?","text":"<ul> <li>In the worst case, for a graph with n nodes, the farthest node from source node can be at the (n-1 edge) (if they are in one component).</li> <li>So, if we have iterated for (n-1) times and did the relaxation, we can be sure that we have covered the worst case. Now, either some nodes will be in another component (which can't be visited from source node), or a negative cycle will be present in the graph.</li> </ul> <ul> <li>If the other nodes are in another component, then again no updation in the distance array will happen.</li> <li>But, if the graph have negative cycle, our distance array will again be updated (in other words, relaxation condition will be true).</li> </ul> <ul> <li>So, when we are iterating through all the edges for the nth time, a single relaxation condition is sufficient to indicate the graph contains negative cycle.</li> </ul>"},{"location":"dsa/graph/important_algos/Bellman_Ford/#code","title":"Code","text":"<pre><code>//  Function to implement Bellman Ford\n//  edges: vector of vectors which represents the graph\n//  S: source vertex to start traversing graph with\n//  V: number of vertices\n\nvector&lt;int&gt; bellman_ford(int V, vector&lt;vector&lt;int&gt;&gt;&amp; edges, int S) {\n    vector&lt;int&gt; dist(V, 1e8);\n    dist[S] = 0;\n    for (int i = 0; i &lt; V - 1; i++) {\n        for (auto it : edges) {\n            int u = it[0];\n            int v = it[1];\n            int wt = it[2];\n            if (dist[u] != 1e8 &amp;&amp; dist[u] + wt &lt; dist[v]) {\n                dist[v] = dist[u] + wt;\n            }\n        }\n    }\n    // Nth relaxation to check negative cycle\n    for (auto it : edges) {\n        int u = it[0];\n        int v = it[1];\n        int wt = it[2];\n        if (dist[u] != 1e8 &amp;&amp; dist[u] + wt &lt; dist[v]) {\n            return { -1};\n        }\n    }\n\n    return dist;\n}\n</code></pre>"},{"location":"dsa/graph/important_algos/Bellman_Ford/#time-complexity","title":"Time Complexity","text":"<p>O(V*E), where V = no. of vertices and E = no. of Edges.</p>"},{"location":"dsa/graph/important_algos/Bellman_Ford/#space-complexity","title":"Space Complexity","text":"<p>O(V) for the distance array which stores the minimized distances.</p>"},{"location":"dsa/graph/important_algos/Dijkstra/","title":"Dijkstra's Algorithm","text":""},{"location":"dsa/graph/important_algos/Dijkstra/#print-shortest-path-dijkstras-algorithm","title":"Print Shortest Path - Dijkstra\u2019s Algorithm","text":"<p>Given a weighted graph and a source vertex in the graph, find the shortest paths from the source to all the other vertices in the given graph.</p> <p>No negative weights</p> <ul> <li>Dijkstra's algorithm doesn't works for graphs containing negative weights.</li> <li>It can't detect negative cycles and will stuck in the loop forever.</li> <li>Bellman-ford algorithm will tackle these shortcomings, but will have more time complexity.</li> </ul> <p></p> <p>Why priority queue is preferred over queue?</p> <ul> <li>The only difference between a queue and a priority queue is that we have to traverse all connected nodes of a current node and find the minimum among them when we use a normal queue which takes time of O(V). But using the priority queue we can optimize it to O(log V).</li> <li>The Time Complexity of Dijkstra\u2019s Algorithm using a normal queue is O(V^2).</li> </ul>"},{"location":"dsa/graph/important_algos/Dijkstra/#code","title":"Code","text":"<pre><code>vector&lt;int&gt; dijkstra(int V, vector&lt;vector&lt;int&gt;&gt; adj[], int S){\n\n    // Create a priority queue for storing the nodes as a pair {dist,node}\n    // where dist is the distance from source to the node. \n    priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; pq;\n\n    // Initialising distTo list with a large number to\n    // indicate the nodes are unvisited initially.\n    // This list contains distance from source to the nodes.\n    vector&lt;int&gt; distTo(V, INT_MAX);\n\n    // Source initialised with dist=0.\n    distTo[S] = 0;\n    pq.push({0, S});\n\n    // Now, pop the minimum distance node first from the min-heap\n    // and traverse for all its adjacent nodes.\n    while (!pq.empty()){\n        int node = pq.top().second;\n        int dis = pq.top().first;\n        pq.pop();\n\n        // Check for all adjacent nodes of the popped out\n        // element whether the prev dist is larger than current or not.\n        for (auto it : adj[node]){\n            int v = it[0];\n            int w = it[1];\n            if (dis + w &lt; distTo[v])\n            {\n                distTo[v] = dis + w;\n\n                // If current distance is smaller,\n                // push it into the queue.\n                pq.push({dis + w, v});\n            }\n        }\n    }\n    // Return the list containing shortest distances\n    // from source to all the nodes.\n    return distTo;\n}\n</code></pre>"},{"location":"dsa/graph/important_algos/Dijkstra/#time-complexity","title":"Time Complexity","text":"<p>O(E *log(V)), Where N = number of vertices and E = number of edges.</p>"},{"location":"dsa/graph/important_algos/Floyd_Warshall/","title":"Floyd Warshall Algorithm","text":""},{"location":"dsa/graph/important_algos/Floyd_Warshall/#floyd-warshall-algorithm","title":"Floyd Warshall Algorithm","text":"<p>The Floyd Warshall Algorithm is an all pair shortest path algorithm unlike Dijkstra and Bellman Ford which are single source shortest path algorithms. This algorithm works for both the directed and undirected weighted graphs. But, it does not work for the graphs with negative cycles (where the sum of the edges in a cycle is negative).</p> <ul> <li>Multi-source shortest path algorithm</li> <li>Can detect negative cycles</li> </ul> <p>It is used to calculate the shortest path from each node to another node.</p>"},{"location":"dsa/graph/important_algos/Floyd_Warshall/#algorithm","title":"Algorithm","text":"<ol> <li>We'll create a adjacency matrix representation of the graph.</li> <li>Each cell with index {i,j} will represent distance from <code>node i</code> to <code>node j</code>.</li> <li>We'll initialize the matrix with a very large number (<code>1e9 or INT_MAX</code>).</li> <li>Update all the diagonal elements to be 0. <code>mat[i][i]=0</code>. Since to go from node-0 to node-0, distance will be 0.</li> <li>Now, traverse all the edges and update the matrix accordingly.</li> <li>Once done, now the matrix contains distance by direct route (from i to j). Now, we will follow the intermediate approach.</li> <li>Instead of directly going from node-i to node-j, we will go via node-k. So, <code>new_dist=node[i][k]+node[k][j]</code>. And, if this new distance is smaller than the existing distance, we will update it.</li> <li><code>For k, we will start from 0 and go till last node (n-1)</code>.</li> <li>In the end, our matrix with cell {i,j} will contain shortest distance from node-i to node-j.</li> <li>To detect if the graph contains negative cycle, simply check if diagonal element are non-zero. If they are, the graph contains a <code>negative cycle</code>.</li> </ol> <p>This is so because, we initialized the diagonals with 0, and our graph started traversing from some node and reached back to itself with negative weight, means, negative cycle.</p>"},{"location":"dsa/graph/important_algos/Floyd_Warshall/#code","title":"Code","text":"<p>GFG Floyd-Warshall algorithm question link</p> <p>GFG Floyd-Warshall algorithm question link</p> <pre><code>class Solution {\n  public:\n    void shortest_distance(vector&lt;vector&lt;int&gt;&gt;&amp;matrix){\n\n        int n = matrix.size();\n\n        for(int k=0;k&lt;n;k++){\n            for(int i=0;i&lt;n;i++){\n                for(int j=0;j&lt;n;j++){\n                    int dist_ij = matrix[i][j];\n                    int dist_ik = matrix[i][k];\n                    int dist_kj = matrix[k][j];\n\n                    // if there exists a route from {i =&gt; k =&gt; j}\n                    if(dist_ik!=-1 &amp;&amp; dist_kj!=-1){\n\n                        // if no route b/w {i=&gt;j} or smaller distance through k\n                        if(dist_ij==-1 || (dist_ij &gt; dist_ik + dist_kj)){\n                            matrix[i][j] = dist_ik+dist_kj;\n                        }\n                    }\n                }\n            }\n        }\n    }\n};01-dsa/01-graph/\n</code></pre> Check if graph contains negative cycle <ul> <li>If we were required to check if the graph contains negative cycle,</li> <li>simply check if diagonals are non-zero (negative mainly).</li> </ul> <pre><code>for(int i=0;i&lt;n;i++)\n    if(matrix[i][i]&lt;0)\n        cout&lt;&lt;\"Graph contains negative cycle\"&lt;&lt;endl;\n</code></pre>"},{"location":"dsa/graph/important_algos/Floyd_Warshall/#time-complexity","title":"Time Complexity","text":"<p>O(V3), as we have three nested loops each running for V times, where V = no. of vertices.</p>"},{"location":"dsa/graph/important_algos/Floyd_Warshall/#space-complexity","title":"Space Complexity","text":"<p>O(V2), where V = no. of vertices. This space complexity is due to storing the adjacency matrix of the given graph.</p>"},{"location":"dsa/graph/important_algos/kosaraju/","title":"Kosaraju's Algorithm","text":""},{"location":"dsa/graph/important_algos/kosaraju/#strongly-connected-components-kosarajus-algorithm","title":"Strongly Connected Components - Kosaraju's Algorithm","text":"<p>A component is called a Strongly Connected Component(SCC) only if for every possible pair of vertices (u, v) inside that component, u is reachable from v and v is reachable from u.</p> <ul> <li>Strongly Connected Components are only valid for directed graph.</li> </ul> <p>In the below directed graph, the Strongly Connected Component(SCC) have been marked</p> <p></p> <ul> <li> <p>To find the strongly connected components of a given directed graph, we uses Kosaraju\u2019s Algorithm.</p> </li> <li> <p>we can expect two types of questions from this topic :-</p> <ul> <li>Find the number of strongly connected components of a given graph.</li> <li>Print the strongly connected components of a given graph.</li> </ul> </li> </ul> Steps to perform Kosaraju\u2019s Algorithm <ul> <li>Sort all the nodes according to their finishing time, to do this we did topological sort using DFS.</li> <li>Reverse all the edges of the entire graph.</li> <li>Perform the DFS and count the no. of different DFS calls to get the no. of SCC.</li> </ul>"},{"location":"dsa/graph/important_algos/kosaraju/#code","title":"Code","text":"<pre><code>    #include &lt;bits/stdc++.h&gt;\n    using namespace std;\n\n    class Solution\n    {\n      private:\n        void dfs(int node, vector&lt;int&gt; &amp;vis, vector&lt;int&gt; adj[], stack&lt;int&gt; &amp;st) {\n            vis[node] = 1;\n            for (auto it : adj[node]) {\n                if (!vis[it]) {\n                    dfs(it, vis, adj, st);\n                }\n            }\n\n            st.push(node);\n        }\n     private:\n        void dfs3(int node, vector&lt;int&gt; &amp;vis, vector&lt;int&gt; adjT[]) {\n            vis[node] = 1;\n            for (auto it : adjT[node]) {\n                if (!vis[it]) {\n                    dfs3(it, vis, adjT);\n                }\n            }\n        }\n     public:\n        //Function to find number of strongly connected components in the graph.\n        int kosaraju(int V, vector&lt;int&gt; adj[])\n        {\n            vector&lt;int&gt; vis(V, 0);\n            stack&lt;int&gt; st;\n            for (int i = 0; i &lt; V; i++) {\n                if (!vis[i]) {\n                    dfs(i, vis, adj, st);\n                }\n            }\n\n            vector&lt;int&gt; adjT[V];\n            for (int i = 0; i &lt; V; i++) {\n                vis[i] = 0;\n                for (auto it : adj[i]) {\n                    // i -&gt; it\n                    // it -&gt; i\n                    adjT[it].push_back(i);\n                }\n            }\n\n            int scc = 0;\n            while (!st.empty()) {\n                int node = st.top();\n                st.pop();\n                if (!vis[node]) {\n                    scc++;\n                    dfs3(node, vis, adjT);\n                }\n            }\n            return scc;\n        }\n    };\n</code></pre>"},{"location":"dsa/graph/important_algos/kosaraju/#time-complexity","title":"Time Complexity","text":"<p>O(V+E) + O(V+E) + O(V+E) ~ O(V+E) , where V = no. of vertices, E = no. of edges. The first step is a simple DFS, so the first term is O(V+E). The second step of reversing the graph and the third step, containing DFS again, will take O(V+E) each.</p>"},{"location":"dsa/graph/important_algos/kosaraju/#space-complexity","title":"Space Complexity","text":"<p>O(V)+O(V)+O(V+E), where V = no. of vertices, E = no. of edges. Two O(V) for the visited array and the stack we have used. O(V+E) space for the reversed adjacent list.</p>"},{"location":"dsa/graph/topological_bipartite/bipartite/","title":"Bipartite using (BFS & DFS)","text":""},{"location":"dsa/graph/topological_bipartite/bipartite/#bipartite-graph","title":"Bipartite Graph","text":"<p>If we are able to colour a graph with two colours such that no adjacent nodes have the same colour, it is called a bipartite graph.</p> <ul> <li>Any linear graph with no cycle is always a bipartite graph.</li> <li>With a cycle, any graph with an even cycle length can also be a bipartite graph.</li> </ul> <p></p> <ul> <li>Any graph with an odd cycle length can never be a bipartite graph.</li> </ul> <p></p>"},{"location":"dsa/graph/topological_bipartite/bipartite/#checking-bipartite-using-bfs","title":"Checking Bipartite using (BFS)","text":"Points to remember <p>We need to create an extra <code>vector&lt;int&gt; color(V,-1)</code> vector to keep track of colored nodes.</p> <ul> <li>And see this portion of code <pre><code>for(auto it : adj[node]){\n    if(color[it] == -1){\n        q.push(it);\n        color[it] = 1-color[node];\n    }\n    else if(color[it] == color[node]){\n        return false;\n    }\n}\n</code></pre></li> </ul> <pre><code>class Solution{\npublic:\n\n    bool check(int start , vector&lt;int&gt; adj[] , vector&lt;int&gt; &amp;color){\n\n        queue&lt;int&gt; q;\n        q.push(start);\n        color[start] = 0;\n\n        while(!q.empty()){\n            int node = q.front();\n            q.pop();\n\n            for(auto it : adj[node]){\n                if(color[it] == -1){\n                    q.push(it);\n                    color[it] = 1-color[node];\n                }\n                else if(color[it] == color[node]){\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }\n\n    bool isBipartite(int V, vector&lt;int&gt;adj[]){\n\n        vector&lt;int&gt; color(V,-1);\n\n        for(int i = 0 ; i &lt; V ; i++){\n            if(color[i] == -1){\n                bool ans = check(i , adj , color);\n                if(ans == false){\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }\n\n};\n</code></pre>"},{"location":"dsa/graph/topological_bipartite/bipartite/#time-complexity","title":"Time Complexity","text":"<p>O(N+E), Where N = Nodes, E is no. of edges.</p>"},{"location":"dsa/graph/topological_bipartite/bipartite/#space-complexity","title":"Space Complexity","text":"<p>O(2N) ~ O(N), Space for queue data structure and color array.</p>"},{"location":"dsa/graph/topological_bipartite/bipartite/#checking-bipartite-using-dfs","title":"Checking Bipartite using (DFS)","text":"Points to remember <p>We need to create an extra <code>vector&lt;int&gt; color(V,-1)</code> vector to keep track of colored nodes.</p> <pre><code>class Solution{\npublic:\n\n    bool check(int start , int col , vector&lt;int&gt; adj[] , vector&lt;int&gt; &amp;color){\n\n        color[start] = col;\n\n        for(auto it : adj[start]){\n            if(color[it] == -1){\n                if(check(it , 1-col , adj , color) == false){\n                    return false;\n                } \n            }\n            else if(color[it] == col){\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    bool isBipartite(int V, vector&lt;int&gt;adj[]){\n\n        vector&lt;int&gt; color(V,-1);\n\n        for(int i = 0 ; i &lt; V ; i++){\n            if(color[i] == -1){\n                bool ans = check(i , 0 , adj , color);\n                if(ans == false){\n                    return false;\n                }\n            }\n        }\n\n        return true;\n    }\n\n};\n</code></pre>"},{"location":"dsa/graph/topological_bipartite/bipartite/#time-complexity_1","title":"Time Complexity","text":"<p>O(N + 2E), Where N = Vertices, 2E is for total degrees as we traverse all adjacent nodes.</p>"},{"location":"dsa/graph/topological_bipartite/bipartite/#space-complexity_1","title":"Space Complexity","text":"<p>O(2N) ~ O(N), Space for DFS stack space and colour array.</p>"},{"location":"dsa/graph/topological_bipartite/topological/","title":"Topological Sort (BFS & DFS)","text":""},{"location":"dsa/graph/topological_bipartite/topological/#topological-sort","title":"Topological Sort","text":"<p>Topological sort: The linear ordering of nodes/vertices such that if there exists an edge between 2 nodes u,v then \u2018u\u2019 appears before \u2018v\u2019.</p> Tip <p>Topological Sorting is applicable only for DAG(Directed Acyclic Graph).</p> <p></p>"},{"location":"dsa/graph/topological_bipartite/topological/#topological-sort-using-bfs","title":"Topological Sort Using (BFS)","text":"Steps to remember <ol> <li>Find in-degree of all nodes and fill them in an array.</li> <li>Now take Queue data structure and add nodes that have in-degree is 0.</li> <li>Take the top/peek node from Queue, add this x to our answer.</li> <li>We'll apply some conditions to the BFS:<ul> <li>Now take neighbour nodes of popped nodes and reduce their in-degree by 1.</li> <li>if any of the popped element nodes's in-degree becomes 0, push it in to the queue.</li> </ul> </li> </ol> <pre><code>vector&lt;int&gt; topo(int N, vector&lt;int&gt; adj[]) {\n    queue&lt;int&gt; q; \n    vector&lt;int&gt; indegree(N, 0); \n    for(int i = 0;i&lt;N;i++) {\n        for(auto it: adj[i]) {\n            indegree[it]++; \n        }\n    }\n\n    for(int i = 0;i&lt;N;i++) {\n        if(indegree[i] == 0) {\n            q.push(i); \n        }\n    }\n    vector&lt;int&gt; topo;\n    while(!q.empty()) {\n        int node = q.front(); \n        q.pop(); \n        topo.push_back(node);\n        for(auto it : adj[node]) {\n            indegree[it]--;\n            if(indegree[it] == 0) {\n                q.push(it); \n            }\n        }\n    }\n    return topo;\n}\n</code></pre>"},{"location":"dsa/graph/topological_bipartite/topological/#time-complexity","title":"Time Complexity","text":"<p>O(N+E), where N = no. of nodes and E = no. of edges.</p>"},{"location":"dsa/graph/topological_bipartite/topological/#space-complexity","title":"Space Complexity","text":"<p>O(N) + O(N)</p>"},{"location":"dsa/graph/topological_bipartite/topological/#topological-sort-using-dfs","title":"Topological Sort Using (DFS)","text":"Steps to remember <ul> <li>Visited Vector - To store visit of each vertex</li> <li>Stack - To maintain the topo sort order.</li> </ul> <pre><code>void findTopoSort(int node, vector&lt;int&gt; &amp;vis, stack&lt;int&gt; &amp;st, vector&lt;int&gt; adj[]) {\n    vis[node] = 1;\n\n    for (auto it: adj[node]) {\n      if (!vis[it]) {\n        findTopoSort(it, vis, st, adj);\n      }\n    }\n    st.push(node);\n}\n\nvector&lt;int&gt; topoSort(int N, vector&lt;int&gt; adj[]) {\n    stack&lt;int&gt; st;\n    vector&lt;int&gt; vis(N, 0);\n    for (int i = 0; i &lt; N; i++) {\n        if (vis[i] == 0) {\n            findTopoSort(i, vis, st, adj);\n        }\n    }\n    vector&lt;int&gt; topo;\n    while (!st.empty()) {\n        topo.push_back(st.top());\n        st.pop();\n    }\n\n    return topo;\n}\n</code></pre>"},{"location":"dsa/graph/topological_bipartite/topological/#time-complexity_1","title":"Time Complexity","text":"<p>O(N+E), where N = no. of nodes and E = no. of edges.</p>"},{"location":"dsa/graph/topological_bipartite/topological/#space-complexity_1","title":"Space Complexity","text":"<p>O(N) + O(N) , Visited Array and Stack data structure. Both will be using O(N).</p>"},{"location":"dsa/graph/traversal_technique/bfs/","title":"Breadth-First Search (BFS)","text":""},{"location":"dsa/graph/traversal_technique/bfs/#breadth-first-search-or-bfs","title":"Breadth First Search or BFS","text":"<p>Breadth First Search (BFS) is a fundamental graph traversal algorithm. It involves visiting all the connected nodes of a graph in a level-by-level manner.</p> <p></p> <p></p> Practice question <ul> <li>BFS of Graph (gfg)</li> </ul> <pre><code>    #include &lt;bits/stdc++.h&gt;\n    using namespace std;\n\n    vector&lt;int&gt; bfs(vector&lt;int&gt; adj[] , int size){\n\n        vector&lt;int&gt; visited(size , 0);\n        vector&lt;int&gt; ans;\n        queue&lt;int&gt; q;\n        q.push(1);\n        visited[1] = 1;\n\n        while(!q.empty()){\n\n            int temp = q.front();\n            q.pop();\n            ans.push_back(temp);\n\n            for(auto val : adj[temp]){\n\n                if(visited[val] == 0){\n                    visited[val] = 1;\n                    q.push(val);\n                }\n\n            }\n        }\n\n        return ans;\n    }\n\n    int main(){\n\n        int V = 6;\n        vector&lt;int&gt; adj[V];\n\n        adj[1] = {2, 5};\n        adj[2] = {1, 5, 3};\n        adj[3] = {2, 4, 5};\n        adj[4] = {3, 5};\n        adj[5] = {1, 2, 3, 4};\n\n        vector&lt;int&gt; ans = bfs(adj , V);\n\n        for(auto val : ans){\n            cout&lt;&lt;val&lt;&lt;\" \";\n        }\n\n        return 0;\n    }\n</code></pre>"},{"location":"dsa/graph/traversal_technique/bfs/#time-complexity","title":"Time Complexity","text":"<p>O(N) + O(2E), Where N = Nodes, 2E is for total degrees as we traverse all adjacent nodes.</p>"},{"location":"dsa/graph/traversal_technique/bfs/#space-complexity","title":"Space Complexity","text":"<p>O(3N) ~ O(N), Space for queue data structure visited array and an adjacency list</p>"},{"location":"dsa/graph/traversal_technique/dfs/","title":"Depth-First Search (DFS)","text":""},{"location":"dsa/graph/traversal_technique/dfs/#depth-first-search-or-dfs","title":"Depth First Search or DFS","text":"<p>DFS is a traversal technique which involves the idea of recursion and backtracking. DFS goes in-depth, i.e. traverses all nodes by going ahead, and when there are no further nodes to traverse in the current path, then it backtracks on the same path and traverses other unvisited nodes. </p> <p></p> Practice question <ul> <li>DFS of Graph (gfg)</li> </ul> <pre><code>    #include &lt;bits/stdc++.h&gt;\n    using namespace std;\n\n    void Helper(vector&lt;int&gt; adj[] , vector&lt;int&gt; &amp;visited , vector&lt;int&gt; &amp;ans , int start){\n\n        visited[start] = 1;\n        ans.push_back(start);\n\n        for(auto val : adj[start]){\n\n            if(visited[val] == 0){\n                Helper(adj , visited , ans , val);\n            }\n        }\n    }\n\n    vector&lt;int&gt; dfs(vector&lt;int&gt; adj[] , int size){\n\n        vector&lt;int&gt; visited(size , 0);\n        int start = 1;\n        vector&lt;int&gt; ans;\n\n        Helper(adj , visited , ans , start);\n\n        return ans;\n    }\n\n    int main(){\n\n        int V = 6;\n        vector&lt;int&gt; adj[V];\n\n        adj[1] = {2, 3};\n        adj[2] = {1, 4, 5};\n        adj[3] = {1};\n        adj[4] = {2};\n        adj[5] = {2};\n\n        vector&lt;int&gt; ans = dfs(adj , V);\n\n        for(auto val : ans){\n            cout&lt;&lt;val&lt;&lt;\" \";\n        }\n\n        return 0;\n    }\n</code></pre>"},{"location":"dsa/graph/traversal_technique/dfs/#time-complexity","title":"Time Complexity","text":"<p>For an undirected graph, O(N) + O(2E), For a directed graph, O(N) + O(E), Because for every node we are calling the recursive function once, the time taken is O(N) and 2E is for total degrees as we traverse for all adjacent nodes.</p>"},{"location":"dsa/graph/traversal_technique/dfs/#space-complexity","title":"Space Complexity","text":"<p>O(3N) ~ O(N), Space for dfs stack space, visited array and an adjacency list.</p>"},{"location":"dsa/linked_list/","title":"Linked List","text":""},{"location":"dsa/linked_list/#contents","title":"Contents","text":""},{"location":"dsa/linked_list/introduction/","title":"Introduction to Linked List","text":""},{"location":"dsa/linked_list/introduction/#what-is-a-linked-list","title":"What is a Linked List?","text":"<p>A linked list is a linear data structure that consists of a series of nodes connected by pointers. Each node contains data and a reference to the next node in the list.</p> <p>Unlike arrays, linked lists allow for efficient insertion or removal of elements from any position in the list, as the nodes are not stored contiguously in memory.</p> <p></p>"},{"location":"dsa/linked_list/categorize_linked_list/circular_ll/","title":"Circular Linked List","text":""},{"location":"dsa/linked_list/categorize_linked_list/circular_ll/#circular-linked-list","title":"Circular Linked List","text":"<p>A circular linked list is that in which the last node contains the pointer to the first node of the list.</p> <p></p>"},{"location":"dsa/linked_list/categorize_linked_list/doubly_ll/","title":"Doubly Linked List","text":""},{"location":"dsa/linked_list/categorize_linked_list/doubly_ll/#doubly-linked-list","title":"Doubly Linked List","text":"<p>A doubly linked list or a two-way linked list is a more complex type of linked list that contains a pointer to the next as well as the previous node in sequence.</p> <p></p>"},{"location":"dsa/linked_list/categorize_linked_list/doubly_ll/#implementation","title":"Implementation","text":"See the code <pre><code>#include &lt;bits/stdc++.h&gt; \nusing namespace std; \n\n// Structure of Node\nclass Node{ \n  public: \n    int data;\n    Node* next;\n    Node* pre;\n\n    Node(int data){\n        this -&gt;data = data;\n        this -&gt;next = NULL;\n        this -&gt;pre = NULL;\n    }\n}; \n\nNode* constructLL(vector&lt;int&gt;&amp; arr) {\n\n    if(arr.size() == 0){\n        return NULL;\n    }\n\n    Node *Head = new Node(arr[0]);\n    Node *temp = Head;\n\n    for(int i = 1 ; i &lt; arr.size() ; i++){\n        Node* new_node = new Node(arr[i]);\n        temp -&gt;next = new_node;\n        new_node -&gt;pre = temp;\n        temp = temp -&gt;next;\n    }\n\n    return Head;\n}\n\nvoid printList(Node* head){ \n\n    Node* temp = head;\n    while (temp != NULL) { \n\n        cout &lt;&lt; temp-&gt;data &lt;&lt; \" \"; \n        temp = temp-&gt;next;\n    } \n}\n\nint main(){ \n\n    vector&lt;int&gt; arr = {1,2,3,4,5};\n\n    Node *head = constructLL(arr);\n    printList(head);\n    cout&lt;&lt;endl;\n\n    return 0; \n}\n</code></pre>"},{"location":"dsa/linked_list/categorize_linked_list/doubly_ll/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Introduction to Doubly Linked List <ul> <li>Introduction to Doubly Linked List (gfg)</li> </ul> <pre><code>class Solution {\n  public:\n    Node* constructDLL(vector&lt;int&gt;&amp; arr) {\n        if(arr.size() == 1){\n            return new Node(arr[0]);\n        }\n\n        Node* head = new Node(arr[0]);\n        Node* temp = head;\n        for(int i = 1 ; i &lt; arr.size() ; i++){\n            Node* new_node = new Node(arr[i]);\n            temp -&gt;next = new_node;\n            new_node -&gt;prev = temp;\n            temp = temp -&gt;next;\n        }\n        return head;\n    }\n};\n</code></pre> Delete node in Doubly Linked List <ul> <li>Delete node in Doubly Linked List (gfg)</li> </ul> <pre><code>class Solution{\n  public:\n    Node* deleteNode(Node *head, int x){\n\n        if(head == NULL){\n            return NULL;\n        }\n\n        Node* temp = head;\n        int cnt = 0;\n        while(temp != NULL){\n            cnt++;\n            if(cnt == x){\n                break;\n            }\n            temp = temp -&gt;next;\n        }\n\n        Node* previous = temp -&gt;prev;\n        Node* ahead = temp -&gt;next;\n\n        if(previous == NULL &amp;&amp; ahead == NULL){\n            return NULL;\n            free(temp);\n        }\n        else if(previous == NULL &amp;&amp; ahead != NULL){\n            head = head -&gt;next;\n            ahead -&gt;prev = NULL;\n            free(temp);\n        }\n        else if(previous != NULL &amp;&amp; ahead == NULL){\n            previous -&gt;next = NULL;\n            temp -&gt;prev = NULL;\n            free(temp);\n        }\n        else{\n            previous -&gt;next = temp -&gt;next;\n            ahead -&gt;prev = previous;\n            temp -&gt;next = NULL;\n            temp -&gt;prev = NULL;\n            free(temp);\n        }\n\n        return head;\n    }\n};\n</code></pre> Doubly linked list Insertion at given position <pre><code>// below code follow 1 based indexing.\nNode* Insert_node(Node* head , int idx , int num){\n\n    if(head == NULL){\n        Node* new_node = new Node(num);\n        return new_node;\n    }\n\n    Node* temp = head;\n    int count = 0;\n    while(temp != NULL){\n        count++;\n        if(count == idx){\n            break;\n        }\n        temp = temp -&gt;next;\n    }\n\n    Node* previous = temp -&gt;pre;\n\n    if(previous == NULL){\n        Node* new_node = new Node(num);\n        new_node -&gt;next = temp;\n        temp -&gt;pre = new_node;\n        head = new_node;\n    }\n    else{\n        Node* new_node = new Node(num);\n        previous -&gt;next = new_node;\n        new_node -&gt;pre = previous;\n        new_node -&gt;next = temp;\n        temp -&gt;pre = new_node;\n    }\n\n    return head;\n}\n</code></pre> Reverse a Doubly Linked List <ul> <li>Reverse a Doubly Linked List (gfg)</li> </ul> <pre><code>class Solution{\n   public:\n    Node* reverseDLL(Node * head){\n\n        if(head == NULL || head -&gt;next == NULL){\n            return head;\n        }\n\n        Node* curr = head;\n        Node* pre = NULL;\n\n        while(curr != NULL){\n            Node* temp = curr -&gt;next;\n            curr -&gt;next = pre;\n            curr -&gt;prev = temp;\n            pre = curr;\n            curr = temp;\n\n        }\n        return pre;\n    }\n};\n</code></pre> Least Recently Used (LRU) cache  V.V.I <ul> <li>LRU Cache (leetcode)</li> </ul> <p>Striver LRU explanation video </p> <p>If you are unable to do this question then first go through above video and then try to understand the below code.</p> <pre><code>class LRUCache {\n    public:\n    class Node{\n        public:\n            int key;\n            int val;\n            Node* next;\n            Node* prev;\n\n            Node(int key , int val){\n                this -&gt;key = key;\n                this -&gt;val = val;\n                next = NULL;\n                prev = NULL;\n            }\n    };\n\n    Node* head = new Node(-1 , -1);\n    Node* tail = new Node(-1 , -1);\n\n    int cap;\n    unordered_map&lt;int,Node*&gt; mp;\n\n    LRUCache(int capacity) {\n        cap = capacity;\n        head -&gt;next = tail;\n        tail -&gt;prev = head;\n    }\n\n    void addNode(Node* newNode){\n        Node* temp = head -&gt;next;\n        newNode -&gt;next = temp;\n        temp -&gt;prev = newNode;\n\n        newNode -&gt;prev = head;\n        head -&gt;next = newNode;\n    }\n\n    void deleteNode(Node* newNode){\n        Node* nextt = newNode -&gt;next;\n        Node* prevv = newNode -&gt;prev;\n\n        nextt -&gt;prev = prevv;\n        prevv -&gt;next = nextt;\n    }\n\n    int get(int key) {\n\n        if(mp.find(key) != mp.end()){\n            Node* resNode = mp[key];\n            int ans = resNode-&gt;val;\n            mp.erase(key);\n            deleteNode(resNode);\n            addNode(resNode);\n\n            mp[key] = head-&gt;next;\n            return ans;\n        }\n        return -1;\n    }\n\n    void put(int key, int value) {\n        if(mp.find(key) != mp.end()){\n            Node* curr = mp[key];\n            mp.erase(key);\n            deleteNode(curr);\n        }\n        if(mp.size() == cap){\n            mp.erase(tail -&gt;prev -&gt;key);\n            deleteNode(tail -&gt;prev);\n        }\n\n        addNode(new Node(key , value));\n        mp[key] = head -&gt;next;\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/linked_list/categorize_linked_list/doubly_ll/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Find pairs with given sum in doubly linked list (gfg)</p> </li> <li> <p>Remove duplicates from a sorted doubly linked list (gfg)</p> </li> <li> <p>Delete all occurrences of a given key in a doubly linked list (gfg)</p> </li> <li> <p>Flatten a Multilevel Doubly Linked List (leetcode)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/linked_list/categorize_linked_list/singly_ll/","title":"Singly Linked List","text":""},{"location":"dsa/linked_list/categorize_linked_list/singly_ll/#singly-linked-list","title":"Singly Linked List","text":"<p>It is the simplest type of linked list in which every node contains some data and a pointer to the next node of the same data type.</p> <p></p>"},{"location":"dsa/linked_list/categorize_linked_list/singly_ll/#implementation","title":"Implementation","text":"See the code <pre><code>#include &lt;bits/stdc++.h&gt; \nusing namespace std; \n\n// Structure of Node\nclass Node{ \n  public: \n    int data;\n    Node* next;\n\n    Node(int data){\n        this -&gt;data = data;\n        this -&gt;next = NULL;\n    }\n}; \n\nNode* constructLL(vector&lt;int&gt;&amp; arr) {\n\n    if(arr.size() == 0){\n        return NULL;\n    }\n\n    Node *Head = new Node(arr[0]);\n    Node *temp = Head;\n\n    for(int i = 1 ; i &lt; arr.size() ; i++){\n        Node* new_node = new Node(arr[i]);\n        temp -&gt;next = new_node;\n        temp = temp -&gt;next;\n    }\n\n    return Head;\n}\n\nvoid printList(Node* head){ \n\n    Node* temp = head;\n    while (temp != NULL) { \n\n        cout &lt;&lt; temp-&gt;data &lt;&lt; \" \"; \n        temp = temp-&gt;next;\n    } \n}\n\nint main(){ \n\n    vector&lt;int&gt; arr = {1,2,3,4,5};\n\n    Node *head = constructLL(arr);\n    printList(head);\n    cout&lt;&lt;endl;\n\n    return 0; \n}\n</code></pre>"},{"location":"dsa/linked_list/categorize_linked_list/singly_ll/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Linked List Insertion <ul> <li>Linked List Insertion (gfg)</li> </ul> <pre><code>class Solution{\npublic:\n    //Function to insert a node at the beginning of the linked list.\n    Node *insertAtBegining(Node *head, int x) {\n\n        Node* new_node = new Node(x);\n        new_node -&gt;next = head;\n        return new_node;\n    }\n\n\n    //Function to insert a node at the end of the linked list.\n    Node *insertAtEnd(Node *head, int x)  {\n\n        Node* new_node = new Node(x);\n        if(head == NULL){\n            return new_node;\n        }\n        Node* temp = head;\n        Node* last = NULL;\n        while(temp != NULL){\n            last = temp;\n            temp = temp -&gt;next;\n        }\n        last -&gt;next = new_node;\n\n        return head;\n    }\n};\n</code></pre> Deleting a node in LinkedList <ul> <li>Deleting a node in LinkedList (leetcode)</li> </ul> <pre><code>class Solution {\n  public:\n    void deleteNode(ListNode* node) {\n\n        ListNode* ahead_node = node -&gt;next;\n        node -&gt;val = ahead_node -&gt;val;\n        node -&gt;next = ahead_node -&gt;next;\n\n    }\n};\n</code></pre> Find the length of the linkedlist <ul> <li>Find the length of the linkedlist (gfg)</li> </ul> <pre><code>class Solution{\n  public:\n    int getCount(struct Node* head){\n\n        int count = 0;\n        Node* temp = head;\n        while(temp != NULL){\n            count++;\n            temp = temp -&gt;next;\n        }\n\n        return count;\n    }\n};\n</code></pre> Search an element in the linkedlist <ul> <li>Search an element in the linkedlist (gfg)</li> </ul> <pre><code>class Solution {\n  public:\n    bool searchKey(int n, struct Node* head, int key) {\n\n        Node* temp = head;\n        while(temp != NULL){\n            if(temp -&gt;data == key){\n                return true;\n            }\n            temp = temp -&gt;next;\n        }\n        return false;\n    }\n};\n</code></pre> Deletion a node of given index <pre><code>Node* delete_node(Node* head , int index){\n\n    if(head == NULL){\n        return NULL;\n    }\n    if(head != NULL){\n        if(index == 1){\n            head = head -&gt;next;\n            return head;\n        }\n    }\n\n    Node* pre = NULL;\n    Node* temp = head;\n    int count = 0;\n    while(temp != NULL){\n        count++;\n        if(count == index){\n            pre -&gt;next = temp -&gt;next;\n            free(pre -&gt;next);\n        }\n        pre = temp;\n        temp = temp -&gt;next;\n    }\n    return head;\n}\n</code></pre> Insertion a node of given index <pre><code>Node* insert_node(Node* head , int num , int idx){\n\n    if(head == NULL){\n        return NULL;\n    }\n    if(head != NULL){\n        if(idx == 1){\n            Node* temp = new Node(num);\n            temp -&gt;next = head;\n            return temp;\n        }\n    }\n\n    Node* pre = NULL;\n    Node* temp = head;\n    int count = 0;\n    while(temp != NULL){\n        count++;\n        if(count == idx){\n            Node* new_ele = new Node(num);\n            pre -&gt;next = new_ele;\n            new_ele -&gt;next = temp;\n        }\n        pre = temp;\n        temp = temp -&gt;next;\n    } \n    return head;\n}\n</code></pre> Reverse a Linked List <ul> <li>Reverse a Linked List (leetcode)</li> </ul> <pre><code>class Solution {\n  public:\n    ListNode* reverseList(ListNode* head) {\n\n        ListNode* curr = head;\n        ListNode* pre = NULL;\n\n        while(curr != NULL){\n            ListNode* next = curr -&gt;next;\n            curr -&gt;next = pre;\n            pre = curr;\n            curr = next;\n        }\n\n        return pre;\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/linked_list/categorize_linked_list/singly_ll/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Middle of the Linked List (leetcode)</p> </li> <li> <p>Linked List cycle (leetcode)</p> </li> <li> <p>Linked List cycle II (leetcode)</p> </li> <li> <p>Find length of Loop (gfg)</p> </li> <li> <p>Check if LL is palindrome or not (leetcode)</p> </li> <li> <p>Segrregate odd and even nodes in LL (leetcode)</p> </li> <li> <p>Remove Nth node from the back of the LL (leetcode)</p> </li> <li> <p>Delete the middle node of LL (leetcode)</p> </li> <li> <p>Sort LL (leetcode)</p> </li> <li> <p>Given a linked list of 0s, 1s and 2s, sort it (gfg)</p> </li> <li> <p>Find the intersection point of LL (leetcode)</p> </li> <li> <p>Add 1 to a number represented as linked list (gfg)</p> </li> <li> <p>Add two numbers in LL (leetcode)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/sliding_window/","title":"Sliding Window","text":""},{"location":"dsa/sliding_window/#contents","title":"Contents","text":""},{"location":"dsa/sliding_window/introduction/","title":"Introduction to Sliding Window Technique","text":""},{"location":"dsa/sliding_window/introduction/#what-is-sliding-window-technique","title":"What is Sliding Window Technique?","text":"<p>Sliding Window problems are problems in which a fixed or variable-size window is moved through a data structure, typically an array or string, to solve problems efficiently based on continuous subsets of elements.</p> <p>This technique is commonly used in algorithms like finding subarrays with a specific sum, finding the longest substring with unique characters, or solving problems that require a fixed-size window to process elements efficiently.</p> <p></p>"},{"location":"dsa/sliding_window/introduction/#how-to-use-sliding-window-technique","title":"How to use Sliding Window Technique?","text":"<p>There are basically two types of sliding window:</p>"},{"location":"dsa/sliding_window/introduction/#1-fixed-size-sliding-window","title":"1. Fixed Size Sliding Window:","text":"<p>The general steps to solve these questions by following below steps:</p> <ul> <li>Find the size of the window required, say K.</li> <li>Compute the result for 1<sup>st</sup> window.</li> <li>Then use a loop to slide the window by 1 and keep computing the result window by window.</li> </ul> Max Sum Subarray of size K <ul> <li>Max Sum Subarray of size K (gfg)</li> </ul> <pre><code>class Solution{\n   public:\n    long maximumSumSubarray(int K, vector&lt;int&gt; &amp;arr , int N){\n\n        long sum = 0;\n        long ans = INT_MIN;\n        int i = 0;\n        int j = 0;\n\n        while(j &lt; N){\n\n            sum += arr[j];\n\n            // Compute the result for 1st window.\n            if(j-i+1 &lt; K){\n                j++;\n            }\n            else if(j-i+1 == K){\n\n                // Slide the window by 1 and keep computing the result window by window.\n                ans = max(ans , sum);\n                sum -= arr[i];\n                i++;\n                j++;\n            }\n        }\n        return ans;\n    }\n};\n</code></pre>"},{"location":"dsa/sliding_window/introduction/#2-variable-size-sliding-window","title":"2. Variable Size Sliding Window:","text":"<p>The general steps to solve these questions by following below steps:</p> <ul> <li>In this type of sliding window problem, we increase our right pointer one by one till our condition is true.</li> <li>At any step if our condition does not match, we shrink the size of our window by increasing left pointer.</li> <li>Again, when our condition satisfies, we start increasing the right pointer and follow step 1.</li> <li>We follow these steps until we reach to the end of the array.</li> </ul> Smallest subarray with sum greater than x <ul> <li>Smallest subarray with sum greater than x (gfg)</li> </ul> <pre><code>class Solution{\n  public:\n    int smallestSubWithSum(int arr[], int n, int x){\n\n        int sum = 0;\n        int ans = INT_MAX;\n        int i = 0;\n        int j = 0;\n        while(j &lt; n){\n\n            sum += arr[j];\n            while(sum &gt; x){\n                ans = min(ans , j-i+1);\n                sum -= arr[i];\n                i++;\n            }\n\n            j++;\n        }\n\n        if(ans == INT_MAX){\n            return 0;\n        }\n\n        return ans;\n    }\n};\n</code></pre>"},{"location":"dsa/sliding_window/introduction/#how-to-identify-sliding-window-problems","title":"How to Identify Sliding Window Problems:","text":"<ul> <li>These problems generally require Finding Maximum/Minimum Subarray, Substrings which satisfy some specific condition.</li> <li>The size of the subarray or substring \u2018K\u2019 will be given in some of the problems.</li> <li>These problems can easily be solved in O(N^2) time complexity using nested loops, using sliding window we can solve these in O(N) Time Complexity.</li> <li>Required Time Complexity: O(N) or O(Nlog(N))</li> <li>Constraints: N &lt;= 10^6 , If N is the size of the Array/String.</li> </ul>"},{"location":"dsa/sliding_window/question/","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> First negative integer in every window of size k <ul> <li>First negative integer in every window of size k (gfg)</li> </ul> <pre><code>vector&lt;long long&gt; printFirstNegativeInteger(long long int arr[], long long int N, long long int K) {\n\n    vector&lt;long long&gt; ans;\n    queue&lt;int&gt; q;\n    int i = 0;  \n    int j = 0;\n\n    while(j &lt; N){\n\n        if(arr[j] &lt; 0){\n            q.push(arr[j]);\n        }\n\n        if(j-i+1 &lt; K){\n            j++;\n        }\n        else if(j-i+1 == K){\n\n            if(q.empty()){\n                ans.push_back(0);\n            }\n            else{\n                ans.push_back(q.front());\n            }\n\n            if(arr[i] &lt; 0){\n                q.pop();\n            }\n            i++;\n            j++;\n        }\n    }\n\n    return ans;\n}\n</code></pre> Count Occurences of Anagrams <ul> <li>Count Occurences of Anagrams (gfg)</li> </ul> <pre><code>class Solution{\n    public:\n    int search(string pat, string txt) {\n\n        map&lt;char , int&gt; mp;\n        for(int i = 0 ; i &lt; pat.length() ; i++){\n            mp[pat[i]]++;\n        }\n\n        int count = mp.size();\n        int k = pat.length();\n        int ans = 0;\n        int i = 0;\n        int j = 0;\n\n        while(j &lt; txt.length()){\n\n            if(mp.find(txt[j]) != mp.end()){\n                mp[txt[j]]--;\n                if(mp[txt[j]] == 0){\n                    count--;\n                }\n            }\n            if(j-i+1 &lt; k){\n                j++;\n            }\n            else if(j-i+1 == k){\n                if(count == 0){\n                    ans++;\n                }\n                if(mp.find(txt[i]) != mp.end()){\n                    mp[txt[i]]++;\n                    if(mp[txt[i]] == 1){\n                        count++;\n                    }\n                }\n                i++;\n                j++;\n            }\n        }\n        return ans;\n    }\n\n};\n</code></pre> Maximum of all subarrays of size k <ul> <li>Maximum of all subarrays of size k (gfg)</li> </ul> <pre><code>class Solution{\n    public:\n    vector&lt;int&gt; max_of_subarrays(vector&lt;int&gt; arr, int n, int k) {\n\n        vector&lt;int&gt; ans;\n        int maxi = INT_MIN;\n        int i = 0;\n        int j = 0;\n        while(j &lt; n){\n\n            if(arr[j] &gt; maxi){\n                maxi = arr[j];\n            }\n\n            if(j-i+1 &lt; k){\n                j++;\n            }\n            else if(j-i+1 == k){\n                ans.push_back(maxi);\n                if(arr[i] != maxi){\n                    i++;\n                    j++;\n                }\n                else if(arr[i] == maxi){\n                    i++;\n                    j = i;\n                    maxi = 0;\n                }\n\n            }\n        }\n        return ans;\n    }\n};\n</code></pre> Number of subarray whose sum equals to K <ul> <li>Subarray Sum Equals K (leetcode)</li> </ul> <pre><code>class Solution {\n    public:\n    int subarraySum(vector&lt;int&gt;&amp; nums, int k) {\n\n        int count = 0;\n        int sum = 0;\n        map&lt;int,int&gt; mp;\n\n        for(int i = 0 ; i &lt; nums.size() ; i++){\n            sum += nums[i];\n\n            if(sum == k){\n                count++;\n            }\n\n            if(mp.find(sum-k) != mp.end()){\n                count += mp[sum-k];\n            }\n\n            mp[sum]++;\n\n        }\n\n        return count;\n\n    }\n};\n</code></pre> Number of Substrings Containing All Three Characters <ul> <li>Number of Substrings Containing All Three Characters (leetcode)</li> </ul> <p>BruteForce</p> <pre><code>class Solution {\n    public:\n    int numberOfSubstrings(string s) {\n\n        int n = s.length();\n        int count = 0;\n        for(int i = 0; i &lt; n ; i++){\n            vector&lt;int&gt; hash(3,0);\n            for(int j = i ; j &lt; n ; j++){\n                hash[s[j]-'a'] = 1;\n                if(hash[0]+hash[1]+hash[2] == 3){\n                    count += n-j;\n                    break;\n                }\n            }\n        }\n        return count;\n    }\n};\n</code></pre> <p>Optimal</p> <pre><code>class Solution {\n    public:\n    int numberOfSubstrings(string s) {\n\n        vector&lt;int&gt; last_seen(3,-1);\n        int ans = 0;\n        int j = 0;\n\n        while(j &lt; s.length()){\n\n            last_seen[s[j]-'a'] = j;\n            if(last_seen[0] != -1 &amp;&amp; last_seen[1] != -1 &amp;&amp; last_seen[2] != -1){\n                int mini = min(last_seen[0],min(last_seen[1],last_seen[2]));\n                ans += mini+1;\n            }\n            j++;\n        }\n        return ans;\n    }\n};\n</code></pre> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/sliding_window/question/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Longest Substring Without Repeating Characters (leetcode)</p> </li> <li> <p>Max Consecutive Ones III  (leetcode)</p> </li> <li> <p>Longest Repeating Character Replacement (leetcode)</p> </li> <li> <p>Fruit Into Baskets (gfg)</p> </li> <li> <p>Binary Subarrays With Sum  (leetcode)</p> </li> <li> <p>Count Number of Nice Subarrays  (leetcode)</p> </li> <li> <p>Maximum Points You Can Obtain from Cards (leetcode)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/sorting/","title":"Sorting","text":""},{"location":"dsa/sorting/#contents","title":"Contents","text":""},{"location":"dsa/sorting/introduction/","title":"Introduction to Sorting","text":""},{"location":"dsa/sorting/introduction/#what-is-sorting","title":"What is Sorting?","text":"<p>Sorting refers to rearrangement of a given array or list of elements according to a comparison operator on the elements. The comparison operator is used to decide the new order of elements in the respective data structure.</p> <ul> <li>Sorting means reordering of all the elements either in ascending or in descending order.</li> </ul> <p></p>"},{"location":"dsa/sorting/introduction/#applications-of-sorting","title":"Applications of Sorting","text":"<ul> <li> <p>Searching Algorithms: Sorting is often a crucial step in search algorithms like binary search, Ternary Search, where the data needs to be sorted before searching for a specific element.</p> </li> <li> <p>Data management: Sorting data makes it easier to search, retrieve, and analyze.</p> </li> <li> <p>Database optimization: Sorting data in databases improves query performance.</p> </li> <li> <p>Machine learning: Sorting is used to prepare data for training machine learning models.</p> </li> <li> <p>Operating Systems: Sorting algorithms are used in operating systems for tasks like task scheduling, memory management, and file system organization.</p> </li> </ul>"},{"location":"dsa/sorting/introduction/#sorting-algorithms","title":"Sorting Algorithms","text":"<ul> <li>Selection Sort</li> <li>Bubble Sort</li> <li>Insertion Sort</li> <li>Merge Sort</li> <li>Quick Sort</li> </ul>"},{"location":"dsa/sorting/sorting_techniques/bubble_sort/","title":"Bubble Sort Algorithm","text":"<p>Bubble Sort is the simplest sorting algorithm that works by repeatedly swapping the adjacent elements if they are in the wrong order. This algorithm is not suitable for large data sets as its average and worst-case time complexity is quite high.</p> <p></p> <p>In Bubble Sort algorithm</p> <ul> <li> <p>Traverse from left and compare adjacent elements and the higher one is placed at right side.</p> </li> <li> <p>In this way, the largest element is moved to the rightmost end at first.</p> </li> <li> <p>This process is then continued to find the second largest and place it and so on until the data is sorted.</p> </li> </ul> Practice question <ul> <li>Bubble Sort (gfg)</li> </ul> <pre><code>void bubbleSort(int arr[], int n) {\n\n    for(int i = 0 ; i &lt; n ; i++){\n        for(int j = 0 ; j &lt; n-i-1 ; j++){\n            if(arr[j] &gt; arr[j+1]){\n                swap(arr[j],arr[j+1]);\n            }\n        }\n    }\n}\n</code></pre> <p>Time complexity: O(N^2)  (where N = size of the array), for the worst, and average cases.</p> <p>Space Complexity: O(1)</p> <p>Optimized approach (Reducing time complexity for the best case):</p> <p>The best case occurs if the given array is already sorted. We can reduce the time complexity to O(N) by just adding a small check inside the loops. </p> <ul> <li> <p>We will check in the first iteration if any swap is taking place. If the array is already sorted no swap will occur and we will break out from the loops. </p> </li> <li> <p>Thus the iteration of the outer loop will be just 1. And our overall time complexity will be O(N).</p> </li> </ul> <pre><code>void bubbleSort(int arr[], int n) {\n\n    for(int i = 0 ; i &lt; n ; i++){\n        int didSwap = 0;\n        for(int j = 0 ; j &lt; n-i-1 ; j++){\n            if(arr[j] &gt; arr[j+1]){\n                swap(arr[j],arr[j+1]);\n                didSwap = 1;\n            }\n        }\n        if(didSwap == 0){\n            break;\n        }\n    }\n}\n</code></pre>"},{"location":"dsa/sorting/sorting_techniques/insertion_sort/","title":"Insertion Sort Algorithm","text":"<p>Insertion sort is a simple sorting algorithm that works by building a sorted array one element at a time. It is considered an in-place sorting algorithm, meaning it doesn\u2019t require any additional memory space beyond the original array.</p> <p></p> <p>Algorithm:</p> <ul> <li> <p>We have to start with second element of the array as first element in the array is assumed to be sorted.</p> </li> <li> <p>Compare second element with the first element and check if the second element is smaller then swap them.</p> </li> <li> <p>Move to the third element and compare it with the second element, then the first element and swap as necessary to put it in the correct position among the first three elements.</p> </li> <li> <p>Continue this process, comparing each element with the ones before it and swapping as needed to place it in the correct position among the sorted elements.</p> </li> <li> <p>Repeat until the entire array is sorted.</p> </li> </ul> Practice question <ul> <li>Insertion Sort (gfg)</li> </ul> <pre><code>void insertion_sort(int arr[], int n) {\n    for (int i = 0; i &lt;= n - 1; i++) {\n        int j = i;\n        while (j &gt; 0 &amp;&amp; arr[j - 1] &gt; arr[j]) {\n            swap(arr[j-1],arr[j]);\n            j--;\n        }\n    }\n}\n</code></pre> <p>Time complexity: O(N^2)  (where N = size of the array), for the worst, and average cases.</p> <p>Space Complexity: O(1)</p> <p>Best Case Time Complexity: </p> <p>The best case occurs if the given array is already sorted. And if the given array is already sorted, the outer loop will only run and the inner loop will run for 0 times. So, our overall time complexity in the best case will boil down to O(N), where N = size of the array.</p>"},{"location":"dsa/sorting/sorting_techniques/merge_sort/","title":"Merge Sort Algorithm","text":"<p>Merge sort is a sorting algorithm that follows the divide-and-conquer approach. It works by recursively dividing the input array into smaller subarrays and sorting those subarrays then merging them back together to obtain the sorted array.</p> <p>How does Merge Sort work?</p> <p>Here\u2019s a step-by-step explanation of how merge sort works:</p> <ol> <li> <p>Divide: Divide the list or array recursively into two halves until it can no more be divided.</p> </li> <li> <p>Conquer: Each subarray is sorted individually using the merge sort algorithm.</p> </li> <li> <p>Merge: The sorted subarrays are merged back together in sorted order. The process continues until all elements from both subarrays have been merged.</p> </li> </ol> <p></p> <p>Approach:</p> <p>We will be creating 2 functions <code>mergeSort()</code> and <code>merge()</code></p> <ol> <li> <p>mergeSort(arr[], low, high):</p> <ul> <li> <p>In order to implement merge sort we need to first divide the given array into two halves. Now, if we carefully observe, we need not divide the array and create a separate array, but we will divide the array's range into halves every time. For example, the given range of the array is 0 to 4(0-based indexing). Now on the first go, we will divide the range into half like (0+4)/2 = 2. So, the range of the left half will be 0 to 2 and for the right half, the range will be 3 to 4. Similarly, if the given range is low to high, the range for the two halves will be low to mid and mid+1 to high, where mid = (low+high)/2. This process will continue until the range size becomes.</p> </li> <li> <p>So, in mergeSort(), we will divide the array around the middle index(rather than creating a separate array) by making the recursive call :</p> <ul> <li>mergeSort(arr,low,mid)   [Left half of the array]</li> <li>mergeSort(arr,mid+1,high)  [Right half of the array] where low = leftmost index of the array, high = rightmost index of the array, and mid = middle index of the array.</li> </ul> </li> <li> <p>Now, in order to complete the recursive function, we need to write the base case as well. We know from step 2.1, that our recursion ends when the array has only 1 element left. So, the leftmost index, low, and the rightmost index high become the same as they are pointing to a single element. Base Case: if(low &gt;= high) return;</p> </li> </ul> Pseudocode of <code>mergeSort()</code> function <pre><code>void mergeSort(vector&lt;int&gt; &amp;arr, int low, int high){\n\n    if (low &gt;= high) return;\n    int mid = (low + high) / 2 ;\n\n    mergeSort(arr, low, mid);  // left half\n    mergeSort(arr, mid + 1, high); // right half\n    merge(arr, low, mid, high);  // merging sorted halves\n}\n</code></pre> </li> <li> <p>merge(arr[], low, mid, high):</p> <ul> <li> <p>In the merge function, we will use a temp array to store the elements of the two sorted arrays after merging. Here, the range of the left array is low to mid and the range for the right half is mid+1 to high.</p> </li> <li> <p>Now we will take two pointers left and right, where left starts from low and right starts from mid+1.</p> </li> <li> <p>Using a while loop( while(left &lt;= mid &amp;&amp; right &lt;= high)), we will select two elements, one from each half, and will consider the smallest one among the two. Then, we will insert the smallest element in the temp array.</p> </li> <li> <p>After that, the left-out elements in both halves will be copied as it is into the temp array.</p> </li> </ul> Pseudocode of <code>merge()</code> function <pre><code>void merge(vector&lt;int&gt; &amp;arr, int low, int mid, int high){\n\n    vector&lt;int&gt; temp; // temporary array\n    int left = low;      // starting index of left half of arr\n    int right = mid + 1;   // starting index of right half of arr\n\n    //storing elements in the temporary array in a sorted manner\n    while (left &lt;= mid &amp;&amp; right &lt;= high) {\n        if (arr[left] &lt;= arr[right]) {\n            temp.push_back(arr[left]);\n            left++;\n        }\n        else {\n            temp.push_back(arr[right]);\n            right++;\n        }\n    }\n\n    // if elements on the left half are still left\n    while (left &lt;= mid) {\n        temp.push_back(arr[left]);\n        left++;\n    }\n\n    //  if elements on the right half are still left\n    while (right &lt;= high) {\n        temp.push_back(arr[right]);\n        right++;\n    }\n\n    // transfering all elements from temporary to arr\n    int z = 0;\n    for (int i = low; i &lt;= high; i++) {\n        arr[i] = temp[z];\n        z++;\n    }\n}\n</code></pre> </li> </ol> <p>Code</p> Practice question <ul> <li>Merge Sort (gfg)</li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nvoid merge(vector&lt;int&gt; &amp;arr, int low, int mid, int high){\n\n    vector&lt;int&gt; temp; // temporary array\n    int left = low;      // starting index of left half of arr\n    int right = mid + 1;   // starting index of right half of arr\n\n    //storing elements in the temporary array in a sorted manner\n    while (left &lt;= mid &amp;&amp; right &lt;= high) {\n        if (arr[left] &lt;= arr[right]) {\n            temp.push_back(arr[left]);\n            left++;\n        }\n        else {\n            temp.push_back(arr[right]);\n            right++;\n        }\n    }\n\n    // if elements on the left half are still left\n    while (left &lt;= mid) {\n        temp.push_back(arr[left]);\n        left++;\n    }\n\n    //  if elements on the right half are still left //\n    while (right &lt;= high) {\n        temp.push_back(arr[right]);\n        right++;\n    }\n\n    // transfering all elements from temporary to arr //\n    int z = 0;\n    for (int i = low; i &lt;= high; i++) {\n        arr[i] = temp[z];\n        z++;\n    }\n}\n\nvoid mergeSort(vector&lt;int&gt; &amp;arr, int low, int high){\n\n    if (low &gt;= high) return;\n    int mid = (low + high) / 2 ;\n\n    mergeSort(arr, low, mid);  // left half\n    mergeSort(arr, mid + 1, high); // right half\n    merge(arr, low, mid, high);  // merging sorted halves\n}\n\nint main() {\n\n    vector&lt;int&gt; arr = {9, 4, 7, 6, 3, 1, 5}  ;\n    int n = 7;\n\n    cout &lt;&lt; \"Before Sorting Array: \" &lt;&lt; endl;\n    for (int i = 0; i &lt; n; i++) {\n        cout &lt;&lt; arr[i] &lt;&lt; \" \"  ;\n    }\n    cout &lt;&lt; endl;\n\n    mergeSort(arr, 0, n - 1);\n\n    cout &lt;&lt; \"After Sorting Array: \" &lt;&lt; endl;\n    for (int i = 0; i &lt; n; i++) {\n        cout &lt;&lt; arr[i] &lt;&lt; \" \"  ;\n    }\n    cout &lt;&lt; endl;\n\n    return 0 ;\n}\n</code></pre> <p>Time Complexity:</p> <ul> <li>Best Case: O(n log n), When the array is already sorted or nearly sorted.</li> <li>Average Case: O(n log n), When the array is randomly ordered.</li> <li>Worst Case: O(n log n), When the array is sorted in reverse order.</li> </ul> <p>Reason: At each step, we divide the whole array, for that logn and we assume n steps are taken to get sorted array, so overall time complexity will be O(n log n)</p> <p>Space complexity: O(n)</p> <p>Reason: We are using a temporary array to store elements in sorted order.</p> <p>Auxiliary Space Complexity: O(n)</p>"},{"location":"dsa/sorting/sorting_techniques/quick_sort/","title":"Quick Sort Algorithm","text":"<p>Quick Sort is a sorting algorithm based on the Divide and Conquer algorithm that picks an element as a pivot and partitions the given array around the picked pivot by placing the pivot in its correct position in the sorted array.</p> <ul> <li>This algorithm does not use any extra array for sorting(it uses an auxiliary stack space). So, from that perspective, Quick sort is slightly better than Merge sort.</li> </ul> <p>This algorithm is basically a repetition of two simple steps that are the following:</p> <ul> <li> <p>Pick a pivot and place it in its correct place in the sorted array.</p> </li> <li> <p>Shift smaller elements(i.e. Smaller than the pivot) on the left of the pivot and larger ones to the right.</p> </li> </ul> <p>Now, let\u2019s discuss the steps in detail considering the array {4,6,2,5,7,9,1,3}:</p> <ul> <li> <p>Step 1: The first thing is to choose the pivot. A pivot is basically a chosen element of the given array. The element or the pivot can be chosen by our choice. So, in an array a pivot can be any of the following:</p> <ul> <li> <p>The first element of the array</p> </li> <li> <p>The last element of the array</p> </li> <li> <p>Median of array</p> </li> <li> <p>Any Random element of the array</p> </li> </ul> </li> </ul> <p>After choosing the pivot(i.e. the element), we should place it in its correct position(i.e. The place it should be after the array gets sorted) in the array. For example, if the given array is {4,6,2,5,7,9,1,3}, the correct position of 4 will be the 4<sup>th</sup> position.</p> <p>Note: Here in this tutorial, we have chosen the first element as our pivot. You can choose any element as per your choice.</p> <ul> <li>Step 2: In step 2, we will shift the smaller elements(i.e. Smaller than the pivot) to the left of the pivot and the larger ones to the right of the pivot. In the example, if the chosen pivot is 4, after performing step 2 the array will look like: {3, 2, 1, 4, 6, 5, 7, 9}. </li> </ul> <p>From the explanation, we can see that after completing the steps, pivot 4 is in its correct position with the left and right subarray unsorted. Now we will apply these two steps on the left subarray and the right subarray recursively. And we will continue this process until the size of the unsorted part becomes 1(as an array with a single element is always sorted).</p> <p>So, from the above intuition, we can get a clear idea that we are going to use recursion in this algorithm.</p> <p>To summarize, the main intention of this process is to place the pivot, after each recursion call, at its final position, where the pivot should be in the final sorted array.</p> <p>Approach:</p> <p>The algorithm steps are the following for the <code>quickSort()</code> function.</p> <ul> <li> <p>Initially, the low points to the first index and the high points to the last index(as the range is n i.e. the size of the array).</p> </li> <li> <p>After that, we will get the index(where the pivot should be placed after sorting) while shifting the smaller elements on the left and the larger ones on the right using a partition() function discussed later.Now, this index can be called the partition index as it creates a partition between the left and the right unsorted subarrays.</p> </li> <li> <p>After placing the pivot in the partition index(within the partition() function specified), we need to call the function quickSort() for the left and the right subarray recursively. So, the range of the left subarray will be [low to (partition index - 1)] and the range of the right subarray will be [(partition index + 1) to high].</p> </li> <li> <p>This is how the recursion will continue until the range becomes 1.</p> Pseudocode of <code>quickSort()</code> function <pre><code>void quickSort(vector&lt;int&gt; &amp;arr, int low, int high) {\n\n    if (low &lt; high) {\n\n        int pIndex = partition(arr, low, high);\n        quickSort(arr, low, pIndex - 1);\n        quickSort(arr, pIndex + 1, high);\n    }\n}\n</code></pre> </li> </ul> <p>The algorithm steps are the following for the <code>partition()</code> function to get the partition index.</p> <ol> <li> <p>Inside the function, we will first select the pivot (i.e. arr[low] in our case).</p> </li> <li> <p>Now, we will again take two-pointers i and j. The i pointer points to low and the j points to high.</p> </li> <li> <p>Now, the pointer i will move forward and find the first element that is greater than the pivot. Similarly, the pointer j will move backward and find the first element that is smaller than the pivot.Here, we need to add some checks like i &lt;= high-1 and j &gt;= low+1. Because it might happen that i is standing at high and trying to proceed or j is standing at low and trying to exceed.</p> </li> <li> <p>Once we find such elements i.e. arr[i] &gt; pivot and arr[j] &lt; pivot, and i &lt; j, we will swap arr[i] and arr[j].</p> </li> <li> <p>We will continue step 3 and step 4, until j becomes smaller than i.</p> </li> <li> <p>Finally, we will swap the pivot element (i.e. arr[low]) with arr[j] and will return the index j i.e. the partition index.</p> Pseudocode of <code>partition()</code> function <pre><code>int partition(vector&lt;int&gt; &amp;arr, int low, int high) {\n    int pivot = arr[low];\n    int i = low;\n    int j = high;\n\n    while (i &lt; j) {\n        while (arr[i] &lt;= pivot &amp;&amp; i &lt;= high - 1) {\n            i++;\n        }\n\n        while (arr[j] &gt; pivot &amp;&amp; j &gt;= low + 1) {\n            j--;\n        }\n        if (i &lt; j) swap(arr[i], arr[j]);\n    }\n\n    swap(arr[low], arr[j]);\n    return j;\n}\n</code></pre> </li> </ol> <p>Code</p> Practice question <ul> <li>Quick Sort (gfg)</li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nint partition(vector&lt;int&gt; &amp;arr, int low, int high) {\n    int pivot = arr[low];\n    int i = low;\n    int j = high;\n\n    while (i &lt; j) {\n        while (arr[i] &lt;= pivot &amp;&amp; i &lt;= high - 1) {\n            i++;\n        }\n\n        while (arr[j] &gt; pivot &amp;&amp; j &gt;= low + 1) {\n            j--;\n        }\n        if (i &lt; j) swap(arr[i], arr[j]);\n    }\n    swap(arr[low], arr[j]);\n    return j;\n}\n\nvoid qs(vector&lt;int&gt; &amp;arr, int low, int high) {\n    if (low &lt; high) {\n        int pIndex = partition(arr, low, high);\n        qs(arr, low, pIndex - 1);\n        qs(arr, pIndex + 1, high);\n    }\n}\n\nvector&lt;int&gt; quickSort(vector&lt;int&gt; arr){\n    qs(arr, 0, arr.size() - 1);\n    return arr;\n}\n\nint main(){\n\n    vector&lt;int&gt; arr = {4, 6, 2, 5, 7, 9, 1, 3};\n    int n = arr.size();\n\n    cout &lt;&lt; \"Before Using quick Sort: \" &lt;&lt; endl;\n    for (int i = 0; i &lt; n; i++){\n        cout &lt;&lt; arr[i] &lt;&lt; \" \";\n    }\n    cout &lt;&lt; endl;\n\n    arr = quickSort(arr);\n\n    cout &lt;&lt; \"After Using quick sort: \" &lt;&lt; \"\\n\";\n    for (int i = 0; i &lt; n; i++){\n        cout &lt;&lt; arr[i] &lt;&lt; \" \";\n    }\n    cout &lt;&lt; \"\\n\";\n\n    return 0;\n}\n</code></pre> <p>Time Complexity:</p> <ul> <li> <p>Best Case : \u03a9 (N log (N)) The best-case scenario for quicksort occur when the pivot chosen at the each step divides the array into roughly equal halves. In this case, the algorithm will make balanced partitions, leading to efficient Sorting.</p> </li> <li> <p>Average Case: \u03b8( N log (N)) Quicksort\u2019s average-case performance is usually very good in practice, making it one of the fastest sorting Algorithm.</p> </li> <li> <p>Worst Case: O(N^2) The worst-case Scenario for Quicksort occur when the pivot at each step consistently results in highly unbalanced partitions. When the array is already sorted and the pivot is always chosen as the smallest or largest element. To mitigate the worst-case Scenario, various techniques are used such as choosing a good pivot (e.g., median of three) and using Randomized algorithm (Randomized Quicksort ) to shuffle the element before sorting.</p> </li> </ul> <p>Space Complexity: O(1) + O(N) auxiliary stack space.</p>"},{"location":"dsa/sorting/sorting_techniques/selection_sort/","title":"Selection Sort Algorithm","text":"<p>The algorithm repeatedly selects the smallest (or largest) element from the unsorted portion of the list and swaps it with the first element of the unsorted part. This process is repeated for the remaining unsorted portion until the entire list is sorted.</p> <p></p> <p>The algorithm steps are as follows:</p> <ul> <li> <p>First, we will select the range of the unsorted array using a loop (say i) that indicates the starting index of the range. The loop will run forward from 0 to n-1. The value i = 0 means the range is from 0 to n-1, and similarly, i = 1 means the range is from 1 to n-1, and so on.(Initially, the range will be the whole array starting from the first index.)</p> </li> <li> <p>Now, in each iteration, we will select the minimum element from the range of the unsorted array using an inner loop.</p> </li> <li> <p>After that, we will swap the minimum element with the first element of the selected range(in step 1).</p> </li> <li> <p>Finally, after each iteration, we will find that the array is sorted up to the first index of the range.</p> </li> </ul> <p>Note: Here, after each iteration, the array becomes sorted up to the first index of the range. That is why the starting index of the range increases by 1 after each iteration. This increment is achieved by the outer loop and the starting index is represented by variable i in the following code. And the inner loop(i.e. j) helps to find the minimum element of the range [i\u2026..n-1].</p> Practice question <ul> <li>Selection Sort (gfg)</li> </ul> <pre><code>#include&lt;bits/stdc++.h&gt;\nusing namespace std;\n\nvoid selection_sort(int arr[], int n){\n\n  for (int i = 0; i &lt; n - 1; i++) {\n    for (int j = i + 1; j &lt; n; j++){\n      if (arr[j] &lt; arr[i]){\n        swap(arr[i],arr[j]);\n      }\n    }\n  }\n}\n\nint main(){\n\n  int arr[] = {13,46,24,52,20,9};\n  int n = sizeof(arr) / sizeof(arr[0]);\n\n   cout &lt;&lt; \"Before selection sort: \";\n   for(int i = 0; i &lt; n; i++){\n    cout &lt;&lt; arr[i] &lt;&lt; \" \";\n  }\n  cout &lt;&lt; \"\\n\";\n\n  selection_sort(arr, n);\n\n  cout &lt;&lt; \"After selection sort: \";\n  for(int i = 0; i &lt; n; i++){\n    cout &lt;&lt; arr[i] &lt;&lt; \" \";\n  }\n  cout &lt;&lt; \"\\n\";\n\n  return 0;\n}\n</code></pre> <p>Time complexity: O(N^2) (where N = size of the array), for the best, worst, and average cases.</p> <p>Space Complexity: O(1)</p>"},{"location":"dsa/stack_queue/","title":"Stack And Queue","text":""},{"location":"dsa/stack_queue/#contents","title":"Contents","text":""},{"location":"dsa/stack_queue/categorize/queue/","title":"Queue Data Structure","text":""},{"location":"dsa/stack_queue/categorize/queue/#what-is-queue","title":"What is Queue ?","text":"<p>A Queue is a linear data structure that follows the FIFO(First-In-First-Out) principle. It operates like a line where elements are added at one end (rear) and removed from the other end (front).</p> <p></p>"},{"location":"dsa/stack_queue/categorize/queue/#operations-on-queue","title":"Operations on Queue :","text":"<ul> <li>Enqueue (Insert): Adds an element to the rear of the queue.</li> <li>Dequeue (Delete): Removes and returns the element from the front of the queue.</li> <li>Peek: Returns the element at the front of the queue without removing it.</li> <li>Empty: Checks if the queue is empty.</li> <li>Full: Checks if the queue is full.</li> </ul>"},{"location":"dsa/stack_queue/categorize/queue/#applications-of-queue","title":"Applications of Queue :","text":"<ul> <li>Task scheduling in operating systems.</li> <li>Data transfer in network communication.</li> </ul>"},{"location":"dsa/stack_queue/categorize/queue/#queue-in-c-stl","title":"Queue in C++ STL","text":"<pre><code>queue&lt;data_type&gt; name;\n</code></pre> <ul> <li>push(element) \u2013 It pushes the value at the end of the queue \u2013 Time Complexity : O(1)</li> <li>pop() \u2013 It deletes the first element from the queue \u2013 Time Complexity : O(1)</li> <li>size() \u2013 It tells us the size of the queue \u2013 Time Complexity : O(1) </li> <li>front() \u2013 It returns the first element of the queue \u2013 Time Complexity : O(1) </li> <li>back() \u2013 It returns the last element of the queue \u2013 Time Complexity : O(1) </li> <li>empty() \u2013 It tells us whether the queue is empty or not \u2013 Time Complexity : O(1)  </li> </ul>"},{"location":"dsa/stack_queue/categorize/queue/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Implement Queue using Arrays <ul> <li>Implement Queue using Arrays (gfg)</li> </ul> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nstruct Queue {\n    int front, rear, capacity;\n    int* queue;\n    Queue(int c){\n        front = rear = 0;\n        capacity = c;\n        queue = new int[c];\n    }\n\n    ~Queue() { delete[] queue; }\n\n    // function to insert an element\n    void queueEnqueue(int data){\n        // check queue is full or not\n        if (capacity == rear) {\n            printf(\"\\nQueue is full\\n\");\n            return;\n        }\n\n        // insert element at the rear\n        else {\n            queue[rear] = data;\n            rear++;\n        }\n        return;\n    }\n\n    // function to delete an element\n    void queueDequeue(){\n        // if queue is empty\n        if (front == rear) {\n            printf(\"\\nQueue is  empty\\n\");\n            return;\n        }\n\n        // shift all the elements from index 2 till rear\n        // to the left by one\n        else {\n            for (int i = 0; i &lt; rear - 1; i++) {\n                queue[i] = queue[i + 1];\n            }\n\n            // decrement rear\n            rear--;\n        }\n        return;\n    }\n\n    // print front of queue\n    void queueFront(){\n        if (front == rear) {\n            printf(\"\\nQueue is Empty\\n\");\n            return;\n        }\n        printf(\"\\nFront Element is: %d\", queue[front]);\n        return;\n    }\n};\n\nint main(void){\n\n    Queue q(4);\n\n    // inserting elements in the queue\n    q.queueEnqueue(20);\n    q.queueEnqueue(30);\n    q.queueEnqueue(40);\n    q.queueEnqueue(50);\n\n    // insert element in the queue\n    q.queueEnqueue(60);\n\n    q.queueDequeue();\n    q.queueDequeue();\n\n\n    // print front of the queue\n    q.queueFront();\n\n    return 0;\n}\n</code></pre> Implement Queue using Stacks <ul> <li>Implement Queue using Stacks (leetcode)</li> </ul> <p>Approach :</p> <ul> <li> <p>For \"push\" function create two stacks (input and output), at every insertion transfer all elements from the stack \"input\" to \"output\" first then insert that element to the stack \"input\" and then transfer all elements from the stack \"output\" to \"input\".</p> </li> <li> <p>And now perform all the operation on the stack \"input\" for desired output.</p> </li> </ul> <p>See the below code implementation.</p> <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\nstruct Queue {\n\n    stack &lt; int &gt; input, output;\n\n    // Push elements in queue\n    void Push(int data) {\n        // Pop out all elements from the stack input\n        while (!input.empty()) {\n        output.push(input.top());\n        input.pop();\n        }\n        // Insert the desired element in the stack input\n        cout &lt;&lt; \"The element pushed is \" &lt;&lt; data &lt;&lt; endl;\n        input.push(data);\n        // Pop out elements from the stack output and push them into the stack input\n        while (!output.empty()) {\n        input.push(output.top());\n        output.pop();\n        }\n    }\n    // Pop the element from the Queue\n    int Pop() {\n        if (input.empty()) {\n        cout &lt;&lt; \"Stack is empty\";\n        exit(0);\n        }\n        int val = input.top();\n        input.pop();\n        return val;\n    }\n    // Return the Topmost element from the Queue\n    int Top() {\n        if (input.empty()) {\n        cout &lt;&lt; \"Stack is empty\";\n        exit(0);\n        }\n        return input.top();\n    }\n    // Return the size of the Queue\n    int size() {\n        return input.size();\n    }\n};\nint main() {\n\n    Queue q;\n\n    q.Push(3);\n    q.Push(4);\n    cout &lt;&lt; \"The element poped is \" &lt;&lt; q.Pop() &lt;&lt; endl;\n    q.Push(5);\n    cout &lt;&lt; \"The top of the queue is \" &lt;&lt; q.Top() &lt;&lt; endl;\n    cout &lt;&lt; \"The size of the queue is \" &lt;&lt; q.size() &lt;&lt; endl;\n}\n</code></pre> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"dsa/stack_queue/categorize/stack/","title":"Stack Data Structure","text":""},{"location":"dsa/stack_queue/categorize/stack/#what-is-stack","title":"What is Stack ?","text":"<p>A Stack is a linear data structure that follows a particular order in which the operations are performed. The order may be LIFO(Last In First Out) or FILO(First In Last Out). LIFO implies that the element that is inserted last, comes out first and FILO implies that the element that is inserted first, comes out last.</p> <p></p>"},{"location":"dsa/stack_queue/categorize/stack/#operations-on-stack","title":"Operations on Stack :","text":"<ul> <li>Push: Adds an element to the top of the stack.</li> <li>Pop: Removes the top element from the stack.</li> <li>Top: Returns the top element without removing it.</li> <li>IsEmpty: Checks if the stack is empty.</li> <li>IsFull: Checks if the stack is full (in case of fixed-size arrays).</li> </ul>"},{"location":"dsa/stack_queue/categorize/stack/#applications-of-stack","title":"Applications of Stack :","text":"<ul> <li>Depth-First Search (DFS)</li> <li>Undo/Redo Operations</li> <li>Browser History</li> </ul>"},{"location":"dsa/stack_queue/categorize/stack/#stack-in-c-stl","title":"Stack in C++ STL","text":"<pre><code>stack&lt;data_type&gt; name;\n</code></pre> <ul> <li>empty() \u2013 Returns whether the stack is empty \u2013 Time Complexity : O(1) </li> <li>size() \u2013 Returns the size of the stack \u2013 Time Complexity : O(1) </li> <li>top() \u2013 Returns a reference to the top most element of the stack \u2013 Time Complexity : O(1) </li> <li>push(g) \u2013 Adds the element \u2018g\u2019 at the top of the stack \u2013 Time Complexity : O(1) </li> <li>pop() \u2013 Deletes the most recent entered element of the stack \u2013 Time Complexity : O(1) </li> </ul>"},{"location":"dsa/stack_queue/categorize/stack/#questions","title":"Questions","text":"<p>\ud83d\udca1 First try with yourself, if you are unable to solve the question then see the solution.</p> Implement Stack using Arrays <ul> <li>Implement Stack using Arrays (gfg)</li> </ul> <pre><code>#include&lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Stack {\n    int size;\n    int * arr;\n    int top;\n    public:\n        Stack() {\n        top = -1;\n        size = 1000;\n        arr = new int[size];\n        }\n    void push(int x) {\n        top++;\n        arr[top] = x;\n    }\n    int pop() {\n        int x = arr[top];\n        top--;\n        return x;\n    }\n    int Top() {\n        return arr[top];\n    }\n    int Size() {\n        return top + 1;\n    }\n};\nint main() {\n\n    Stack s;\n    s.push(6);\n    s.push(3);\n    s.push(7);\n    cout &lt;&lt; \"Top of stack is before deleting any element \" &lt;&lt; s.Top() &lt;&lt; endl;\n    cout &lt;&lt; \"Size of stack before deleting any element \" &lt;&lt; s.Size() &lt;&lt; endl;\n    cout &lt;&lt; \"The element deleted is \" &lt;&lt; s.pop() &lt;&lt; endl;\n    cout &lt;&lt; \"Size of stack after deleting an element \" &lt;&lt; s.Size() &lt;&lt; endl;\n    cout &lt;&lt; \"Top of stack after deleting an element \" &lt;&lt; s.Top() &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre> Implement Stack using Queues <ul> <li>Implement Stack using Queues (leetcode)</li> </ul> <p>Approach :</p> <ul> <li>Take a single queue.</li> <li>push(x): Push the element in the queue.</li> <li>Use a for loop of size()-1, remove element from queue and again push back to the queue, hence the most recent element becomes the most former element and vice versa.</li> <li>pop(): remove the element from the queue.</li> <li>top(): show the element at the top of the queue.</li> <li>size(): size of the current queue.</li> </ul> <p>Repeat \"step 3\" at every insertion of the element.</p> <pre><code>#include&lt;bits/stdc++.h&gt;\nusing namespace std;\n\nclass Stack {\n    queue &lt; int &gt; q;\n    public:\n        void Push(int x) {\n        int s = q.size();\n        q.push(x);\n        for (int i = 0; i &lt; s; i++) {\n\n            q.push(q.front());\n            q.pop();\n        }\n        }\n    int Pop() {\n        int n = q.front();\n        q.pop();\n        return n;\n    }\n    int Top() {\n        return q.front();\n    }\n    int Size() {\n        return q.size();\n    }\n};\n\nint main() {\n\n    Stack s;\n\n    s.Push(3);\n    s.Push(2);\n    s.Push(4);\n    s.Push(1);\n    cout &lt;&lt; \"Top of the stack: \" &lt;&lt; s.Top() &lt;&lt; endl;\n    cout &lt;&lt; \"Size of the stack before removing element: \" &lt;&lt; s.Size() &lt;&lt; endl;\n    cout &lt;&lt; \"The deleted element is: \" &lt;&lt; s.Pop() &lt;&lt; endl;\n    cout &lt;&lt; \"Top of the stack after removing element: \" &lt;&lt; s.Top() &lt;&lt; endl;\n    cout &lt;&lt; \"Size of the stack after removing element: \" &lt;&lt; s.Size();\n\n}\n</code></pre> Valid Parentheses <ul> <li>Valid Parentheses (leetcode)</li> </ul> <pre><code>bool isValid(string s) {\n\n    stack&lt;char&gt; st;\n\n    for(int i = 0 ; i &lt; s.length() ; i++){\n        if(s[i] == '(' || s[i] == '[' || s[i] == '{'){\n            st.push(s[i]);\n        }\n        else{\n            if(st.empty()){\n                return false;\n            }\n\n            char ch = st.top();\n            if(ch == '(' &amp;&amp; s[i] == ')' || ch == '{' &amp;&amp; s[i] == '}' || ch == '[' &amp;&amp; s[i] == ']'){\n                st.pop();\n            }\n            else{\n                return false;\n            }\n\n        }\n    }\n\n    if(!st.empty()){\n        return false;\n    }\n    return true;\n}\n</code></pre> Implement Min Stack <ul> <li>Implement Min Stack (leetcode)</li> </ul> <pre><code>class MinStack {\npublic:\n\n    stack&lt;pair&lt;int,int&gt;&gt; st;\n\n    MinStack() {\n\n    }\n\n    void push(int val) {\n        if(st.empty()){\n            st.push({val,val});\n        }\n        else{\n            st.push({val , min(st.top().second , val)});\n        }\n    }\n\n    void pop() {\n        st.pop();\n    }\n\n    int top() {\n        int val = st.top().first;\n        return val;\n    }\n\n    int getMin() {\n        return st.top().second;\n    }\n};\n</code></pre> Infix to Postfix Conversion <p>Try below expression on pen and paper using below algorithm \ud83e\udd48 \ud83e\udd47</p> <p></p> <p>Approach: To convert Infix expression to Postfix</p> <ol> <li> <p>Scan the infix expression from left to right.</p> </li> <li> <p>If the scanned character is an operand, add it to the answer. </p> </li> <li> <p>Else, </p> <ul> <li>If the precedence of the scanned operator is greater than the precedence of the operator in the stack or the stack is empty or the stack contains a \"(\", push the character into the stack. </li> <li>Else, Pop all the operators from the stack and add it to answer which are greater than or equal to the precedence than that of the scanned operator. After doing that Push the scanned operator to the stack. </li> </ul> </li> <li> <p>If the scanned character is an \"(\", push it into the stack. </p> </li> <li> <p>If the scanned character is an \")\", pop the stack and output it until a \"(\" is encountered, and discard both the parenthesis. </p> </li> <li> <p>Repeat steps 2-5 until the entire infix expression is scanned. </p> </li> <li> <p>Pop and add it to the answer from the stack until it is not empty.</p> </li> </ol> Infix to Prefix Conversion <p>Try examples on pen and paper using below algorithm \ud83e\udd48 \ud83e\udd47</p> <p></p> <p></p> Prefix to Infix Conversion <p>Try examples on pen and paper using below algorithm \ud83e\udd48 \ud83e\udd47</p> <p></p> <p></p> Prefix to Postfix Conversion <p>Try examples on pen and paper using below algorithm \ud83e\udd48 \ud83e\udd47</p> <p></p> <p></p> Postfix to Prefix Conversion <p>Try examples on pen and paper using below algorithm \ud83e\udd48 \ud83e\udd47</p> <p></p> <p></p> Postfix to Infix Conversion <p>Try examples on pen and paper using below algorithm \ud83e\udd48 \ud83e\udd47</p> <p></p> <p></p> <p>\ud83e\udd47 \ud83e\udd47 \ud83e\udd47</p>"},{"location":"dsa/stack_queue/categorize/stack/#other-important-questions-list","title":"Other Important Questions List","text":"Important Questions List <ul> <li> <p>Next Greater Element I (leetcode)</p> </li> <li> <p>Next Greater Element II (leetcode)</p> </li> <li> <p>Nearest Smaller Element (interviewbit)</p> </li> <li> <p>Trapping Rain Water (leetcode)</p> </li> <li> <p>Sum of Subarray Minimums (leetcode)</p> </li> <li> <p>Asteroid Collision (leetcode)</p> </li> <li> <p>Sum of Subarray Ranges (leetcode)</p> </li> <li> <p>Remove K Digits (leetcode)</p> </li> <li> <p>Largest Rectangle in Histogram (leetcode)</p> </li> <li> <p>Maximal Rectangle (leetcode)</p> </li> </ul> <p>\ud83d\udcaf \ud83d\udd25 \ud83d\ude80</p>"},{"location":"operating_system/","title":"Welcome to Operating System","text":"<p>An operating system (OS) is a software that manages a computer's resources and acts as an interface between the user and the computer's hardware.</p> <p></p>"},{"location":"operating_system/introduction/","title":"Introduction to Operating System","text":""},{"location":"operating_system/introduction/#what-is-an-application-software","title":"what is an Application software?","text":"<p>The term \u201capplication software\u201d refers to software that performs specific functions for a user. When a user interacts directly with a piece of software, it is called application software. The sole purpose of application software is to assist the user in doing specified tasks. Microsoft Word and Excel, as well as popular web browsers like Firefox and Google Chrome, are examples of application software.</p>"},{"location":"operating_system/introduction/#what-is-system-software","title":"what is System software?","text":"<p>System software operates and controls the computer system and provides a platform to run application software.Examples of system software include operating systems.</p>"},{"location":"operating_system/introduction/#why-os","title":"Why OS?","text":"<p>What if there is no OS?</p> <p>a. Bulky and complex app.(Hardware interaction code must be in app\u2019s code base) b. Resource exploitation by 1 App. c. No memory protection.</p>"},{"location":"operating_system/introduction/#an-operating-system-functions","title":"An operating system functions","text":"<ul> <li>Access to the computer hardware.</li> <li>interface between the user and the computer hardware</li> <li>Resource management (Aka, Arbitration) (memory, device, file, security, process etc)</li> <li>Hides the underlying complexity of the hardware. (Aka, Abstraction)</li> <li>facilitates execution of application programs by providing isolation and protection.</li> </ul> <p><code>The operating system provides the means for proper use of the resources in the operation of the computer system.</code></p>"},{"location":"operating_system/introduction/#os-goals","title":"OS goals","text":"<ul> <li>Maximum CPU utilization</li> <li>Less process starvation</li> <li>Higher priority job execution</li> </ul>"},{"location":"operating_system/components_and_system_call/","title":"Components &amp; System Calls","text":""},{"location":"operating_system/components_and_system_call/#contents","title":"Contents","text":""},{"location":"operating_system/components_and_system_call/components_of_os/","title":"Components of OS","text":""},{"location":"operating_system/components_and_system_call/components_of_os/#components-of-os_1","title":"Components of OS","text":"<ol> <li> <p>Kernel :- A kernel is that part of the operating system which interacts directly with the hardware and performs the most crucial tasks.</p> <ul> <li>Heart of OS/Core component</li> <li>Very first part of OS to load on start-up.</li> </ul> </li> <li> <p>User space :- Where application software runs, apps don\u2019t have privileged access to the underlying hardware. It interacts with kernel.</p> <ul> <li>GUI</li> <li>CLI</li> </ul> </li> </ol> <p>shell/ Command Interpreter</p> <p>A shell, also known as a command interpreter, is that part of the operating system that <code>receives commands from the users and gets them executed.</code></p>"},{"location":"operating_system/components_and_system_call/components_of_os/#cpu-execution-modes","title":"CPU execution modes \ud83d\udea6","text":"<p>There are two modes in which CPU can execute code:</p> <ol> <li> <p>User mode</p> <ul> <li>In user mode, the CPU executes application-level code (non-privileged code).</li> <li>Programs running in this mode have limited access to system resources and hardware.</li> <li>If a program needs to access hardware resources or perform privileged operations (e.g., writing to disk), it makes a request to the operating system via system calls.</li> </ul> </li> <li> <p>Kernel mode</p> <ul> <li>In kernel mode, the CPU executes code with full access to all hardware resources.</li> <li>The operating system (OS) and low-level system processes run in kernel mode, where they can control hardware directly, manage memory, schedule processes, etc.</li> <li>Code running in kernel mode can execute any CPU instruction and reference any memory address.</li> </ul> </li> </ol> <p>Kernel mode</p> <p>When you are typing <code>mkdir newDir</code> in terminal, the <code>mkdir</code> command is running in user mode, but the <code>mkdir</code> command is calling the <code>mkdir</code> system call which is running in kernel mode.</p> <ul> <li>CPU execution switches from <code>user mode</code> to <code>kernel mode</code>.</li> <li>This is done by system interrupts.</li> <li>The switching takes some time, so it's not good to switch frequently.</li> </ul> Non-privileged code means  <p>In non-privileged mode, the code :-</p> <ul> <li>Cannot directly access hardware devices (e.g., disks, network cards).</li> <li>Cannot modify critical system data or configuration.</li> <li>Cannot directly access memory regions that are protected by the OS.</li> <li>Must rely on the OS to manage resources, schedule tasks, and handle exceptions.</li> </ul>"},{"location":"operating_system/components_and_system_call/components_of_os/#functions-of-kernel","title":"Functions of Kernel","text":"<p>1. Process management</p> <ul> <li>Scheduling processes and threads on the CPUs.</li> <li>Creating &amp; deleting both user and system process.</li> <li>Suspending and resuming processes</li> <li>Providing mechanisms for process synchronization or process communication.</li> </ul> <p>2. Memory management</p> <ul> <li>Allocating and deallocating memory space as per need.</li> <li>Keeping track of which part of memory are currently being used and by which process.</li> </ul> <p>3. File management</p> <ul> <li>Creating and deleting files.</li> <li>Creating and deleting directories to organize files.</li> <li>Mapping files into secondary storage.</li> <li>Backup support onto a stable storage media.</li> </ul> <p>4. I/O management</p> <ul> <li>to manage and control I/O operations and I/O devices</li> <li>Buffering (data copy between two devices), caching and spooling.<ul> <li>Within differing speed two jobs.</li> <li>Eg. Print spooling and mail spooling.</li> </ul> </li> <li>Buffering<ul> <li>Within one job.</li> <li>Eg. Youtube video buffering</li> </ul> </li> <li>Caching<ul> <li>Memory caching, Web caching etc.</li> </ul> </li> </ul> what is spooling? <ul> <li>Spooling is a process in which data is temporarily held to be used and executed by a device, program or the system. It is a place where data is stored to be processed or printed later.</li> <li>In modern systems, spooling is often used when data needs to be transferred from a program to a peripheral (such as a printer).</li> </ul>"},{"location":"operating_system/components_and_system_call/components_of_os/#types-of-kernels","title":"Types of Kernels \ud83e\udd16","text":""},{"location":"operating_system/components_and_system_call/components_of_os/#1-monolithic-kernel","title":"1. Monolithic Kernel","text":"<ul> <li>All functions are in kernel itself. <pre><code>- Bulky in size.\n- Memory required to run is high.\n- Less reliable, one module crashes -&gt; whole kernel is down.\n+ High performance as communication is fast. (Less user mode, kernel mode overheads)\n</code></pre></li> <li>Eg. Linux, Unix, MS-DOS.</li> </ul>"},{"location":"operating_system/components_and_system_call/components_of_os/#2-micro-kernel","title":"2. Micro Kernel","text":"<ul> <li>Only major functions are in kernel.<ul> <li>Memory management.</li> <li>Process management.</li> </ul> </li> <li>File management and IO management are in User-space. <pre><code>+ smaller in size.\n+ More Reliable\n+ More stable\n- Performance is slow (bcoz of switching between user mode and kernel mode)\n- Overhead switching b/w user mode and kernel mode.\n</code></pre></li> <li>Eg. L4 Linux, Symbian OS, MINIX etc.</li> </ul>"},{"location":"operating_system/components_and_system_call/components_of_os/#3-hybrid-kernel","title":"3. Hybrid Kernel","text":"<ul> <li>Advantages of both worlds. (File management. in User space and rest in Kernel space. ) <pre><code>+ Combined approach.\n+ Speed and design of mono.\n+ Modularity and stability of micro.\n</code></pre></li> <li>Eg. MacOS, Windows NT/7/10</li> <li>IPC also happens but lesser overheads</li> </ul>"},{"location":"operating_system/components_and_system_call/components_of_os/#4-exo-kernels","title":"4. Exo kernels","text":"<ul> <li>Smallest in size.</li> <li>Only basic functions.</li> <li>Rest in user space. <pre><code>- has fewest hardware abstractions as possible.\n- It allocates physical resources to applications.\n</code></pre></li> </ul>"},{"location":"operating_system/components_and_system_call/components_of_os/#5-nano-kernel","title":"5. Nano Kernel","text":"<ul> <li>It is the type of kernel that offers hardware abstraction but without system services.</li> <li>Micro Kernel also does not have system services therefore the Micro Kernel and Nano Kernel have become analogous.</li> <li>The main difference between the two is that the Nano Kernel is designed to be as small as possible.</li> <li><code>Micro kernels</code> which actually are micro in size are also called <code>nano kernels</code>.</li> </ul> Nano/Exo kernels <p>a type of operating system kernel that has a minimal and streamlined design, with a focus on minimalism and efficiency. The goal of a nano kernel is to provide only the essential functions required for the operation of a system while delegating other functions to user-space processes.</p>"},{"location":"operating_system/components_and_system_call/components_of_os/#communication-bw-user-mode-and-kernel-mode","title":"Communication b/w User mode and Kernel mode \ud83d\udce1","text":"Q. How will communication happen between user mode and kernel mode? <ul> <li>Inter process communication (IPC). This can be done in two ways:<ul> <li>Shared memory: <ul> <li>A region of memory that is shared between two processes.</li> <li>One process writes to the shared memory and the other process reads from it.</li> </ul> </li> <li>Message passing: <ul> <li>A logical channel is established between two processes.</li> <li>A process sends a message to another process and the other process receives it.</li> <li>Eg. pipes, sockets, message queues, signals, semaphores, shared memory, and message passing.</li> </ul> </li> </ul> </li> </ul>"},{"location":"operating_system/components_and_system_call/system_calls/","title":"System Calls","text":"<p>How do apps interact with Kernel?</p> <p>using system calls.</p>"},{"location":"operating_system/components_and_system_call/system_calls/#what-are-system-calls","title":"What are system calls?","text":"<ul> <li>System calls are special functions that allow user-level programs to request services or resources from the operating system's kernel. Since programs running in user space don't have direct access to hardware or core system resources, they rely on system calls to perform tasks that require privileged access, like reading files, allocating memory, or communicating with hardware.</li> <li><code>System Calls are the only way through which a process can go into kernel mode from user mode.</code></li> <li>Transitions from <code>UserMode</code> to <code>KernelMode</code> done by software interrupts.</li> <li>System Calls are implemented in C and Assembly language.</li> </ul>"},{"location":"operating_system/components_and_system_call/system_calls/#example","title":"Example:","text":"<ul> <li> <p>Eg. <code>mkdir my_dir</code></p> <ul> <li>Mkdir indirectly calls kernel and asked the file mgmt. module to create a new directory.</li> <li>Mkdir is just a wrapper of actual system calls.</li> <li>Mkdir interacts with kernel using system calls.   </li> </ul> </li> <li> <p>Eg. <code>Creating a process</code></p> <ul> <li>User executes a process. (User space)</li> <li>Gets system call. (US)</li> <li>Exec system call to create a process. (KS)</li> <li>Return to user space.</li> </ul> </li> </ul>"},{"location":"operating_system/components_and_system_call/system_calls/#types-of-system-calls","title":"Types of System Calls:","text":""},{"location":"operating_system/components_and_system_call/system_calls/#faqs","title":"FAQs \ud83d\ude4b\u200d\u2642\ufe0f","text":"Q.1: What is the purpose of System Calls? <p>The purpose of the system calls is to allow user-level applications access of the services provided by the kernel. The user apps do not have the privilege to perform operations, so they make system calls which further requests a kernel to provide a specific service.</p> Q.2: How do device management System Calls work? <p>Device management system calls work by allowing a certain process or a device interact and get access to other hardware resources and perform various operations.</p> Q.3: What is user mode and kernel mode? <p>User mode and kernel modes are two different privilege modes of a Computer System, that separates the execution of operations by the user applications and the kernel on hardware. This separation provides security, stability, and a level of control over system resources.</p> Q.4: What happens when a System Call is executed? <p>When a system call is executed, a context switch occurs and the computer system switches from user mode to kernel mode and now the kernel performs the desired operation.</p> Q.5: What is a software interrupt? <p>A software interrupt is a mechanism through which the OS performs a context switch and transition from user mode to kernel mode. A software interrupt use is not limited only to the system calls but it can also be made when a high priority task is required to be executed by the CPU.</p>"},{"location":"operating_system/concurrency_and_deadlocks/","title":"Concurrency &amp; Deadlocks","text":""},{"location":"operating_system/concurrency_and_deadlocks/#contents","title":"Contents","text":""},{"location":"operating_system/concurrency_and_deadlocks/Conditional_variable_Semaphore/","title":"Conditional variable &amp; Semaphores","text":""},{"location":"operating_system/concurrency_and_deadlocks/Conditional_variable_Semaphore/#thread-synchronization-problem-with-current-approach","title":"Thread synchronization problem with current approach","text":"<p>So until of now, we have seen couple of approaches, like using flag boolean value, peterson's solution, and mutex.</p> <ul> <li>The biggest problem with mutex is of busy waiting. Until the lock is acquired, another thread has to be in a repetitive while loop of checking if the lock is free or not. So, it's basically wasting CPU clocks. These CPU clocks could have been used by a more meaningful app.</li> </ul> <p>Busy Waiting</p> <p>Busy waiting, also known as busy looping or spinning, is a process synchronization technique in computer science and software engineering where a process repeatedly checks if a condition is true before executing. For example, a process might check if a lock is available.</p> <p>To account for this, some new methods were introduced like:</p> <ul> <li>Conditional Variables</li> <li>Semaphores</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Conditional_variable_Semaphore/#conditional-variables","title":"Conditional Variables","text":"<ul> <li> <p>Condition variables are synchronization primitives that enable threads to wait until a particular condition occurs.</p> </li> <li> <p>There are two types of actions that can be performed with condition variables:</p> <ul> <li>wait</li> <li>signal</li> </ul> </li> <li> <p>We use the wait instruction in a thread if we want to halt the execution of that thread till a certain condition is met.</p> </li> <li> <p>We use the signal instruction if we want to continue executing the leading thread in the waiting queue.</p> </li> <li> <p>Contention is not here, as after critical section work is done, we will notify others, and they don't have to check every now-and-than and waste CPU cycles.</p> </li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Conditional_variable_Semaphore/#semaphores","title":"Semaphores","text":"<ul> <li>Suppose we have a printer that itself has 3 sub-printers, and hence it can print 3 documents at once, so it can execute 3 process at once.</li> <li>Semaphore is a synchronization method, in which we have a number which is equal to the number of resources.</li> <li>Multiple threads can go and execute <code>critical section</code> concurrently.</li> <li>Allows multiple program threads to access the finite instance of resources whereas mutex allows multiple threads to access a single shared resource one at a time.</li> </ul> <ul> <li>Binary semaphore: value can be 0 or 1.<ul> <li>Aka, mutex locks</li> </ul> </li> <li>Counting semaphore<ul> <li>Can range over an unrestricted domain.</li> <li>Can be used to control access to a given resource consisting of a finite number of instances.</li> </ul> </li> </ul> <p>Semaphore process</p> <p></p> <ul> <li> <p>To overcome the need for busy waiting, we can modify the definition of the wait () and signal () semaphore operations. When a process executes the wait () operation and finds that the semaphore value is not positive, it must wait. However, rather than engaging in busy waiting, the process car block itself. The block- operation places a process into a waiting queue associated with the semaphore, and the state of the process is switched to the Waiting state. Then control is transferred to the CPU scheduler, which selects another process to execute.</p> </li> <li> <p>A process that is blocked, waiting on a semaphore S, should be restarted when some other process executes a signal () operation. The process is restarted by a wakeup() operation, which changes the process from the waiting state to the ready state. The process is then placed in the ready queue.</p> </li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/","title":"Critical section &amp; Race condition \ud83c\udfce\ufe0f","text":""},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/#critical-section","title":"Critical Section","text":"<p>The critical section refers to the segment of code where processes/threads access shared resources, such as common variables and files, and perform write operations on them.</p> <ul> <li>Since processes/threads execute concurrently, any process can be interrupted mid-execution.</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/#race-condition","title":"Race Condition","text":"<ul> <li>A race condition occurs when two or more threads can access shared data and they try to change it at the same time.</li> <li>Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data.</li> <li>Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e., both threads are \"racing\" to access/change the data.</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/#solution-to-race-condition","title":"Solution to Race Condition","text":"<p>Solutions of Race condition</p> <ul> <li>Atomic operations: Make Critical code section an atomic operation, i.e., Executed in one CPU cycle.</li> <li>Mutual Exclusion using <code>locks</code>. (MutEX)</li> <li>Semaphores</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/#what-are-the-conditions-to-be-full-filled-to-be-a-solution-to-race-condition","title":"What are the conditions to be full-filled to be a solution to race condition?","text":"<p>Conditions required</p> <ol> <li>Mutual exclusion (<code>only one thread goes inside critical section at once</code>)</li> <li>Progress (<code>No thread should stop another thread from entering into critical section, if it's not in the critical section itself</code>).</li> <li>Bounded Waiting (<code>no indefinite waiting</code>)</li> </ol> <p>Though we typically don't bother much about <code>condition-3</code>, but <code>1 &amp; 2 condition</code> are must.</p>"},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/#can-we-use-a-simple-flag-variable-to-solve-the-problem-of-race-condition","title":"Can we use a simple flag variable to solve the problem of race condition?","text":"<ul> <li>No</li> </ul> Explanation <ul> <li>Let's say, we have a flag <code>turn</code>, and two threads are executing.</li> <li>For thread-1, it will be in <code>while loop until turn is not false (0)</code>; and for thread-2, it will be in <code>while loop until turn is not true (1)</code>.</li> <li>Once while loop breaks, it will go into critical section, and once done with critical section, it will modify the flag, so that other threads can enter in critical section.</li> <li>So, mutual exclusion is achieved.</li> <li>But, the problem is, which thread will execute first, depends on the initial value of <code>turn</code> flag. If it is false by default, thread-1 will execute first, and if thread-2 reaches first, it will still have to wait until thread-1 is done.</li> <li>So, second-condition of being a solution is not full-filled.</li> <li>That's why, <code>single flag can't be used as solution for critical section</code>. </li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/#petersons-solution","title":"Peterson\u2019s solution","text":"<ul> <li>Peterson's solution can be used to avoid race condition for only 2 processes/ threads.</li> </ul> Detailed description of Peterson's solution to avoid race condition <ul> <li>We create a bool <code>turn</code>, and a boolean array <code>flag</code> of size 2.</li> <li>flag denotes, if \\(i^{th}\\) thread/process can enter critical section or not.</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Critical_section_Race_condition/#mutexlocks","title":"Mutex/Locks","text":"<ul> <li>Locks can be used to implement mutual exclusion and avoid race condition by allowing only one thread/process to access critical section.</li> </ul> <p>Disadvantages</p> <ul> <li>Contention: one thread has acquired the lock, other threads will be busy waiting, what if thread that had acquired the lock dies, then all other threads will be in infinite waiting.</li> <li>Deadlocks (<code>one process has locked one critical section, and another process has locked another critical section, and both are waiting for each other to release their part so that they can continue and complete</code>)</li> <li>Debugging (<code>it's tedious to debug mutex codes</code>)</li> <li>Starvation of high priority (<code>a low priority process might have locked critical section, and a high priority process will starve</code>)</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/","title":"Introduction to Concurrency \ud83d\ude0e","text":""},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/#concurrency","title":"Concurrency \ud83e\udd14","text":"<ul> <li>Concurrency is the execution of the multiple instruction sequences at the same time.</li> <li>It happens in the operating system when there are several process threads running in parallel.</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/#thread","title":"Thread","text":"<ul> <li>Single sequence stream within a process.</li> <li>An independent path of execution in a process.</li> <li>Light-weight process.</li> <li>Used to achieve parallelism by dividing a process\u2019s tasks which are independent path of execution.</li> <li>E.g., Multiple tabs in a browser, text editor (When you are typing in an editor, spell checking, formatting of text and saving the text are done concurrently by multiple threads.)</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/#thread-scheduling","title":"Thread Scheduling","text":"<ul> <li>Threads are scheduled for execution based on their priority.</li> <li>Even though threads are executing within the runtime, all threads are assigned processor time slices by the operating system.</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/#threads-context-switching","title":"Threads context switching","text":"<ul> <li>OS saves current state of thread &amp; switches to another thread of same process.</li> <li>Doesn\u2019t includes switching of memory address space. (But Program counter, registers &amp; stack are included.)</li> <li>Fast switching as compared to process switching</li> <li>CPU\u2019s cache state is preserved.</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/#how-each-thread-get-access-to-the-cpu","title":"How each thread get access to the CPU?","text":"<ul> <li>Each thread has its own program counter.</li> <li>Depending upon the thread scheduling algorithm, OS schedule these threads.</li> <li>OS will fetch instructions corresponding to PC of that thread and execute instruction.</li> <li>I/O or TQ, based context switching is done here as well<ul> <li>We have TCB (Thread control block) like PCB for state storage management while performing context switching.</li> </ul> </li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/#will-single-cpu-system-would-gain-by-multi-threading-technique","title":"Will single CPU system would gain by multi-threading technique?","text":"<ul> <li>Never.</li> <li>As two threads have to context switch for that single CPU.</li> <li>This won\u2019t give any gain.</li> <li>for the CPU intensive tasks, there won't be gain, but for i/o or network related tasks, we will definitely benefit from using multithreading.</li> </ul>"},{"location":"operating_system/concurrency_and_deadlocks/Introduction_to_Concurrency/#benefits-of-multi-threading","title":"Benefits of Multi-threading","text":"<ul> <li>Responsiveness</li> <li>Resource sharing: Efficient resource sharing.</li> <li>Economy: It is more economical to create and context switch threads.<ul> <li>Also, allocating memory and resources for process creation is costly, so better to divide tasks into threads of same process.</li> </ul> </li> <li>Threads allow utilization of multiprocessor architectures to a greater scale and efficiency.</li> </ul>"},{"location":"operating_system/important_to_know/","title":"Important to Know","text":""},{"location":"operating_system/important_to_know/#contents","title":"Contents","text":""},{"location":"operating_system/important_to_know/_32bit_vs_64bit/","title":"32-bit &amp; 64-bit Operating System","text":""},{"location":"operating_system/important_to_know/_32bit_vs_64bit/#comparison","title":"Comparison \ud83d\ude08","text":"32-bit 64-bit A 32-bit OS has 32-bit registers, and it can access 2^32 unique memory addresses. i.e., 4GB of RAM. A 64-bit OS has 64-bit registers, and it can access 2^64 unique memory addresses. i.e., 17,179,869,184 GB of RAM. 32-bit CPU architecture can process 32 bits of data &amp; information. 64-bit CPU architecture can process 64 bits of data &amp; information."},{"location":"operating_system/important_to_know/_32bit_vs_64bit/#advantages-of-64-bit-os-over-32-bit-os","title":"Advantages of 64-bit OS over 32-bit OS \ud83e\udd29","text":"<ol> <li> <p>Addressable Memory: 32-bit CPU -&gt; 2^32 memory addresses, 64-bit CPU -&gt; 2^64 memory addresses.</p> </li> <li> <p>Resource usage: Installing more RAM on a system with a 32-bit OS doesn't impact performance. However, upgrade that system with excess RAM to the 64-bit version of Windows, and you'll notice a difference.</p> </li> <li> <p>Performance: <code>All calculations take place in the registers</code>. When you\u2019re performing math in your code, operands are loaded from memory into registers. So, having larger registers allow you to perform larger calculations at the same time.</p> <ul> <li>32-bit processor can execute 4 bytes of data in 1 instruction cycle while 64-bit means that processor can execute 8 bytes of data in 1 instruction cycle. (In 1 sec, there could be thousands to billions of instruction cycles depending upon a processor design, hence, <code>64-bit can process much more data in 1 sec than 32-bit</code>.)</li> </ul> </li> <li> <p>Compatibility: 64-bit CPU can run both 32-bit and 64-bit OS. While 32-bit CPU can only run 32-bit OS. (All the starting bits will be 0 in 64-bit CPU while working with 32-bit OS.)</p> </li> <li> <p>Better Graphics performance: 8-bytes graphics calculations make graphics-intensive apps run faster.</p> </li> </ol>"},{"location":"operating_system/important_to_know/different_storage_devices/","title":"Different STORAGES used in Computers","text":""},{"location":"operating_system/important_to_know/different_storage_devices/#memory-hierarchy","title":"Memory Hierarchy","text":"<ul> <li> <p>Register: Smallest unit of storage. It is a part of CPU itself.</p> <ul> <li>A register may hold an instruction, a storage address, or any data (such as bit sequence or individual characters).</li> <li>Registers are a type of computer memory used to quickly accept, store, and transfer data and instructions that are being used immediately by the CPU.</li> </ul> </li> <li> <p>Cache: Additional memory system that temporarily stores frequently used instructions and data for quicker processing by the CPU.</p> </li> <li> <p>Main Memory: <code>RAM</code>.</p> </li> <li>Secondary Memory: Storage media, on which computer can store data &amp; programs.</li> </ul>"},{"location":"operating_system/important_to_know/different_storage_devices/#comparison","title":"Comparison \ud83e\udd3a","text":"<ol> <li> <p>Cost:</p> <ul> <li>Primary storages are costly.</li> <li>Registers are most expensive due to expensive semiconductors &amp; labour.</li> <li>Secondary storages are cheaper than primary.</li> </ul> </li> <li> <p>Access Speed:</p> <ul> <li>Primary has higher access speed than secondary memory.</li> <li>Registers has highest access speed, then comes cache, then main memory.</li> </ul> </li> <li> <p>Storage size:</p> <ul> <li>Secondary has more space.</li> </ul> </li> <li> <p>Volatility:</p> <ul> <li>Primary memory is volatile. <code>(Data is lost when power is turned off.)</code></li> <li>Secondary is non-volatile. <code>(Data is retained even when power is turned off.)</code></li> </ul> </li> </ol>"},{"location":"operating_system/important_to_know/how_os_boots_up/","title":"How Operating System Boots up?","text":"<p>We can describe it in 5 steps:</p> <p></p> <ol> <li> <p>PC power On.</p> </li> <li> <p>CPU initializes itself and looks for a firmware program (BIOS) stored in BIOS Chip (Basic input-output system chip is a ROM chip found on mother board that allows to access &amp; setup computer system at most basic level.)</p> <ul> <li>In modern PCs, CPU loads UEFI (<code>Unified extensible firmware interface</code>)</li> </ul> </li> <li> <p>CPU runs the BIOS which tests and initializes system hardware. Bios loads configuration settings. If something is not appropriate (like missing RAM) error is thrown and boot process is stopped. This is called POST (Power on self-test) process. </p> <ul> <li>(UEFI can do a lot more than just initialize hardware; it\u2019s really a tiny operating system. For example, Intel CPUs have the Intel Management Engine. This provides a variety of features, including powering Intel\u2019s Active Management Technology, which allows for remote management of Business PCs.)</li> </ul> </li> <li> <p>BIOS will handoff responsibility for booting your PC to your OS\u2019s bootloader.</p> <ul> <li>BIOS looked at the MBR (Master Boot Record), a special boot sector at the beginning of a disk The MBR contains code that loads the rest of the OS, known as <code>bootloader</code>. The BIOS executes the bootloader, which takes it from there and begins booting the actual OS (windows or linux or mac).</li> <li>Typically, present at the <code>0th index</code> of the disk.</li> <li>In other words, BIOS or UEFI examines a storage device on your system to look for a small program, either in MBR or on an EFI system partition, and runs it.</li> </ul> </li> <li> <p>The bootloader is a small program that has the large task of booting the rest of the operating system (Boots Kernel then, User Space).</p> <ul> <li>Windows uses a bootloader named <code>Windows Boot Manager (Bootmgr.exe)</code>.</li> <li>most Linux systems use <code>GRUB</code>, and Macs use something called <code>boot.efi</code>.</li> </ul> </li> </ol>"},{"location":"operating_system/process_management/","title":"Process Management","text":""},{"location":"operating_system/process_management/#contents","title":"Contents","text":""},{"location":"operating_system/process_management/Swapping_ContextSwitching_Orphan_Zombie_Process/","title":"Swapping (MTS), Context Switching, Orphan and Zombie Process","text":""},{"location":"operating_system/process_management/Swapping_ContextSwitching_Orphan_Zombie_Process/#swapping-medium-term-scheduler-mts","title":"Swapping &amp; Medium-term scheduler (MTS) \u2653\ufe0f","text":"<p>Info</p> <ul> <li>Long-term scheduler (or job scheduler) selects which processes should be brought into the ready queue. It aims to select a good process mix of I/O-bound and CPU-bound processes.</li> <li>It anticipates their resource usages and then selects a good process mix. But its not perfect, and it may over-commit memory. </li> <li>Hence, we need to free up memory by removing some processes from memory. This is done by medium-term scheduler (MTS).</li> <li>medium-term scheduler (MTS) is a part of the operating system that decides which processes to swap in and out of memory. It is a part of the swapping function.</li> <li>Swapped-out processes are placed on the disk (in swap memory) and are swapped-in when memory becomes available.</li> <li>Swapping-out reduces the degree of multi-programming, and swapping-in increases it.</li> </ul> <p>Swapping is a mechanism in which a process can be swapped temporarily out of main memory (or move) to secondary storage (disk) and make that memory available to other processes. At some later time, the system swaps back the process from the secondary storage to main memory.</p>"},{"location":"operating_system/process_management/Swapping_ContextSwitching_Orphan_Zombie_Process/#context-switching","title":"Context Switching \ud83d\udd04","text":"<ul> <li>Switching the CPU to another process requires performing a state save of the current process and a state restore of a different process.</li> <li>When this occurs, <code>the kernel saves the context of the old process in its PCB and loads the saved context of the new process scheduled to run</code>.</li> <li>It is pure overhead, because the system does no useful work while switching.</li> <li>Speed varies from machine to machine, depending on the memory speed, the number of registers that must be copied etc.</li> </ul>"},{"location":"operating_system/process_management/Swapping_ContextSwitching_Orphan_Zombie_Process/#orphan-process","title":"Orphan process \ud83e\uddd2","text":"<ul> <li><code>Each process in the system has a parent process</code>. The root of the process tree is the <code>init process</code> (with PID=1).</li> <li>The process whose parent process has been terminated and it is still running.</li> <li>Orphan processes are adopted by init process.</li> <li>Init is the first process of OS. (PID = 1)</li> </ul> Practical on Orphan Process <ol> <li>Create a <code>orphan-script.sh</code> file and write the below code in it. <pre><code>#!/bin/bash\nsleep 200 &amp; # this will create a child process and detach it from the parent process.\n</code></pre></li> <li>Run the script using <code>./orphan-script.sh</code> command. (<code>chmod +x orphan-script.sh</code> if permission denied)</li> <li>In another terminal, check for the process <code>sleep</code> using <code>ps -al</code> command. Look for the <code>PPID</code> column. It should be <code>1</code> (init process).</li> </ol>"},{"location":"operating_system/process_management/Swapping_ContextSwitching_Orphan_Zombie_Process/#zombie-process-defunct-process","title":"Zombie process / Defunct process \ud83e\udddf","text":"<ul> <li>A zombie process is a process whose execution is completed but it still has an entry in the process table.</li> <li>Zombie processes usually occur for child processes, as the parent process still needs to read its child\u2019s exit status.</li> <li><code>Once this is done using the wait system call, the zombie process is eliminated from the process table. This is known as</code> reaping the zombie process.</li> <li>It is because parent process may call wait () on child process for a longer time duration and child process got terminated much earlier.</li> <li>As entry in the process table can only be removed, after the parent process reads the exit status of child process. Hence, the child process remains a zombie till it is removed from the process table.</li> </ul> Practical on Zombie Process <ol> <li>Create a <code>zombie-script.sh</code> file and write the below code in it. <pre><code>#!/bin/bash\nfor i in {1..100}\ndo\n    sleep 1&amp;\ndone\nexec sleep 100\n</code></pre></li> <li>Run the script using <code>./zombie-script.sh</code> command. (<code>chmod +x zombie-script.sh</code> if permission denied)</li> <li>In another terminal, check for the zombie process using <code>ps -elf | grep Z</code> command. There should be 100 zombie processes each with same <code>PPID</code> as <code>zombie-script.sh</code> process.</li> </ol>"},{"location":"operating_system/process_management/Swapping_ContextSwitching_Orphan_Zombie_Process/#limitations-of-process-table-in-os","title":"Limitations of <code>Process Table</code> in OS","text":"<ul> <li>Process table is a data structure maintained by the operating system to store information about the processes.</li> <li>Process table has a limited size, and it is not possible to keep all the processes in the memory all the time.</li> <li>Zombie processes could fill up the process table and prevent new processes from being created.</li> </ul> <p>Maximum number of process table entries</p> <ul> <li>Windows: Windows Operating System limits the number of process table entries to 65536.</li> <li>Linux: The maximum number of process table entries in Linux varies based on the distribution, architecture and kernel version. In general, it ranges from 32768 to 4194304.</li> </ul>"},{"location":"operating_system/process_management/introduction/","title":"Introduction to Process Management \ud83c\udff4\u200d\u2620\ufe0f","text":"<p>What is a program?</p> <p>Compiled code, that is ready to execute.</p> <p>What is a process?</p> <p>Program under execution.</p> <p>How OS creates a process? Converting program into a process.</p> <ul> <li>Load the program &amp; static data into memory.</li> <li>Allocate runtime stack.</li> <li>Heap memory allocation.</li> <li>IO tasks:<ul> <li>After allocating memory, OS then creates I/O descriptors for the process.</li> <li>These descriptors are used to interact with the I/O devices. They are:<ul> <li><code>input descriptor</code> (creates a handler that process will use when it needs to read from the input device)</li> <li><code>output descriptor</code> (creates a handler that process will use when it needs to write to the output device)</li> <li><code>error descriptor</code> (creates a handler that process will use when it needs to write to the error device)</li> </ul> </li> </ul> </li> <li>OS handoffs control to main ().</li> </ul> Why do we return 0 from main? <ul> <li>Every process in the OS is created as a child of the <code>init (root)</code> process.</li> <li>It is a convention to return 0 from main to indicate that the program has executed successfully.</li> <li>If the program has encountered an error, then we return a non-zero value.</li> <li>In case of an error, the OS can take necessary action based on the return value.</li> </ul>"},{"location":"operating_system/process_management/introduction/#architecture-of-a-process-in-ram","title":"Architecture of a Process in RAM \ud83c\udfd7\ufe0f","text":""},{"location":"operating_system/process_management/introduction/#attributes-of-a-process","title":"Attributes of a Process","text":"<ul> <li>OS maintains a Process table to keep track of all the processes.</li> <li>Each process in the table is called a Process Control Block (PCB).</li> <li>PCB contains all the information about the process.</li> </ul>"},{"location":"operating_system/process_management/introduction/#pcb-structure","title":"PCB structure \ud83d\udce6","text":"<ul> <li>Process ID (PID): Unique identifier for the process.</li> <li>Process State: Current state of the process. (Running, Ready, Blocked, etc.)</li> <li>Program Counter (PC): Microprocessors convert the code into sequence of instructions. PC keeps track of the next instruction to be executed.</li> <li>Registers: it is a data structure. When a processes is running and it's time slice expires, the current value of process specific registers would be stored in the PCB and the process would be swapped out. When the process is scheduled to be run, the register values is read from the PCB and written to the CPU registers. This is the main purpose of the registers in the PCB.</li> </ul>"},{"location":"operating_system/process_management/process_state_process_queue/","title":"Process State &amp; Process Queue \ud83d\udc6f","text":""},{"location":"operating_system/process_management/process_state_process_queue/#process-state","title":"Process State \ud83c\udfc3\ud83c\udffb","text":"<p>As process executes, it changes state. Each process may be in one of the following states:</p> <ul> <li> <p>New: OS is about to pick the program &amp; convert it into process. Or, the process is being created.</p> </li> <li> <p>Run: Instructions are being executed; CPU is allocated.</p> </li> <li> <p>Waiting: Waiting for IO.</p> </li> <li> <p>Ready: The process is in memory, waiting to be assigned to a processor.</p> </li> <li> <p>Terminated: The process has finished execution. PCB entry removed from process table.</p> </li> </ul> <p></p> <p>Process state</p> <ul> <li>Long-term scheduler: Selects which processes from a pool of <code>new</code> processes should be brought into the <code>ready</code> queue. It is called <code>long-term</code> because it is invoked infrequently (let's say after 1 second).</li> <li>When a process is in <code>ready state</code>, it is waiting to be assigned to a processor. Short-term scheduler selects a process from the <code>ready queue</code> and assigns it to the processor. It is called <code>short-term</code> because it is invoked very frequently (let's say after every 100 milliseconds).</li> <li>Waiting state is a temporary state. A process is moved to the waiting state if it needs to wait for a resource (like I/O) to become available. For example, if a process is waiting for user input, it will be in the waiting state. When the input is available, the process will be moved to the ready state and the short-term scheduler will pick a process from the ready queue and assign it to the processor.</li> <li>Terminated state is the final state. The process has finished its execution and is removed from the system.</li> <li>Interrupt is a signal to the OS that an event has occurred and needs immediate attention. It can be generated by the hardware or software. For example, an interrupt can be generated by a clock to indicate that a fixed interval of time has passed and the <code>running process</code> needs to be moved to the <code>ready queue</code> so that another process can be assigned to the processor.</li> </ul> Remember <ul> <li>Short-term scheduler: CPU Scheduler.</li> <li>Long-term scheduler: Job Scheduler.</li> </ul> What is Dispatcher? <ul> <li>It is the module that gives control of the CPU to the process selected by the short-term scheduler. It involves:<ul> <li>Switching context.</li> <li>Switching to user mode.</li> <li>Jumping to the proper location in the user program to restart that program.</li> </ul> </li> </ul> <p>Dispatch latency is the time taken to stop running process and run another process which was in the ready queue.</p>"},{"location":"operating_system/process_management/process_state_process_queue/#process-queue","title":"Process Queue \ud83d\udeb6\ud83c\udffb\u200d\u2642\ufe0f","text":"<ol> <li> <p>Job Queue:</p> <ul> <li>Processes in new state.</li> <li>Present in secondary memory.</li> <li><code>Job Schedular (Long term schedular (LTS)) picks process from the pool and loads them into memory for execution.</code></li> </ul> </li> <li> <p>Ready Queue:</p> <ul> <li>Processes in Ready state.</li> <li>Present in main memory.</li> <li><code>CPU Schedular (Short-term schedular) picks process from ready queue and dispatch it to CPU.</code></li> </ul> </li> <li> <p>Waiting Queue:</p> <ul> <li>Processes in Wait state.</li> </ul> </li> </ol>"},{"location":"operating_system/process_management/process_state_process_queue/#degree-of-multi-programming","title":"Degree of multi-programming \ud83d\udcca","text":"<ul> <li>The number of processes in the memory.</li> <li>The degree of multiprogramming describes the maximum number of processes that a single-processor system can accommodate efficiently.</li> </ul> <p>Who controls degree of multi-programming?</p> <p>LTS controls degree of multi-programming. Because it decides how many processes are to be loaded into the memory (ready queue) for execution.</p>"},{"location":"operating_system/process_management/process_scheduling/Comparison_between_different_scheduling_algorithms/","title":"Comparison between Process Scheduling Algorithms \ud83e\udd3c\u200d\u2642\ufe0f","text":"Design Preemption Convoy Effect Overhead <code>(context switching)</code> First come First Serve Simple No Yes No Shortest Job First Complex (how to find out <code>burst time</code>) No Yes No Pre-emptive Shortest Job First Complex Yes No Yes Priority Scheduling Complex (how to give suitable <code>priority</code>) No Yes No Pre-Emptive Priority Complex Yes Yes (low priority might never get CPU) Yes Round Robin Simple Yes No Yes Multi-level Queue Complex Yes Yes Yes Multi-level Feedback Queue Complex Yes Yes (though we try to reduce it using aging) Yes"},{"location":"operating_system/process_management/process_scheduling/Multi-Level_Queue_Multi-Level_Feedback_Queue/","title":"MLQ &amp; MLFQ (Multi-Level Queue &amp; Multi-Level Feedback Queue)","text":""},{"location":"operating_system/process_management/process_scheduling/Multi-Level_Queue_Multi-Level_Feedback_Queue/#multi-level-queue-scheduling-mlq","title":"Multi-level queue scheduling (MLQ)","text":"<ul> <li>Ready queue is divided into multiple queues depending upon priority.</li> <li>A process is permanently assigned to one of the queues (inflexible) based on some property of process, memory, size, process priority or process type.</li> <li>Each queue has its own scheduling algorithm. E.g., SP -&gt; RR, IP -&gt; RR &amp; BP -&gt; FCFS.<ul> <li>(SP: System process, IP: Interactive process, BP: Batch process)</li> <li>(RR: Round Robin, FCFS: First Come First Serve)</li> </ul> </li> </ul> more info <ul> <li>System process: Created by OS (Highest priority)</li> <li>Interactive process (Foreground process): Needs user input (I/O).</li> <li>Batch process (Background process): Runs silently, no user input required</li> </ul> <ul> <li>Scheduling among different sub-queues is implemented as fixed priority preemptive scheduling. E.g., foreground queue has absolute priority over background queue.</li> <li>If an interactive process comes &amp; batch process is currently executing. Then, batch process will be preempted.</li> </ul> <p>Problems with <code>multi-level queue scheduling</code>:</p> <ul> <li>Only after completion of all the processes from the top-level ready queue, the further level ready queues will be scheduled.</li> <li>Starvation for lower priority process.</li> <li>Convoy effect is present.</li> </ul>"},{"location":"operating_system/process_management/process_scheduling/Multi-Level_Queue_Multi-Level_Feedback_Queue/#multi-level-feedback-queue-scheduling-mlfq","title":"Multi-level feedback queue scheduling (MLFQ) \ud83e\udd77\ud83c\udffb","text":"<ul> <li> <p>The one which is actually used in practice in most of the systems.</p> </li> <li> <p>Multiple sub-queues are present.</p> </li> </ul> <p>what's new?</p> <ul> <li>Process can move between queues.</li> <li>If a process uses too much CPU time, it will be moved to lower priority queue (to account for other processes).</li> <li>If a process uses too much I/O, it will be moved to higher priority queue. (so that user can interact with it, else he will feel like system is hanging).</li> <li>Aging is used to prevent starvation. (Aging: If a process waits too much in a lower-priority queue, it may be moved to a higher priority queue).</li> </ul> <p>Advantages of MLFQ:</p> <ul> <li>Less starvation then MLQ. (doesn't mean, it's completely free from starvation).</li> <li>It is flexible.</li> <li>Can be configured to match a specific system design requirement.</li> </ul> <p></p>"},{"location":"operating_system/process_management/process_scheduling/SJF_PriorityScheduling_Round_Robin/","title":"SJF, Priority Scheduling &amp; Round Robin","text":""},{"location":"operating_system/process_management/process_scheduling/SJF_PriorityScheduling_Round_Robin/#shortest-job-first-sjf-scheduling","title":"Shortest Job First (SJF) Scheduling","text":"Non-Preemptive SJF Scheduling <p> - Process with least BT (burst time) will be dispatched to CPU first. - Must do estimation for BT for each process in ready queue beforehand, Correct estimation of BT is an impossible task (ideally). - Run lowest time process for all time then, choose job having lowest BT at that instance. - This will suffer from convoy effect as if the very first process which came is Ready state is having a large BT. - Process starvation might happen. (a shorter process might enter ready queue slightly later than a longer process, but it will wait for a long time before it gets CPU)</p> Preemptive SJF Scheduling <p></p> <ul> <li>Less starvation.</li> <li>No convoy effect.</li> <li>Gives average WT less for a given set of processes as scheduling short job before a long one <code>decreases the waiting time of short jobs more than it increases the waiting time of long ones</code>.</li> </ul>"},{"location":"operating_system/process_management/process_scheduling/SJF_PriorityScheduling_Round_Robin/#priority-scheduling","title":"Priority Scheduling","text":"Non-Preemptive Priority Scheduling <ul> <li>Priority is assigned to a process when it is created.</li> <li>SJF is a special case of general priority scheduling with priority inversely proportional to BT.</li> </ul> Preemptive Priority Scheduling <ul> <li>Current running process can be preempted if a new process arrives with higher priority than the currently running process.</li> </ul> Problem with Priority Scheduling <ul> <li>Starvation: Low priority processes may never execute.</li> </ul> <p>Solution \ud83d\ude0e</p> <p>Aging (increase priority of process as it waits in the system).</p> <ul> <li>e.g., increase priority by 1 after every 15 seconds</li> </ul>"},{"location":"operating_system/process_management/process_scheduling/SJF_PriorityScheduling_Round_Robin/#round-robin-scheduling","title":"Round Robin Scheduling","text":"Info <ul> <li>Most popular</li> <li>Like FCFS, but preemption is added to switch between processes.</li> <li>Designed especially for time-sharing systems.</li> <li>Criteria: AT (arrival time) and TQ (time quantum).</li> </ul> <p>Advantages</p> <ul> <li>Fairness: All processes get equal share of CPU.</li> <li>No process starvation.</li> <li>No convoy effect.</li> </ul> <p>Disadvantages</p> <ul> <li>Too much context switching.</li> <li>If TQ is too large, it becomes FCFS.</li> <li>If TQ is too small, too much context switching, and increases overhead.</li> </ul>"},{"location":"operating_system/process_management/process_scheduling/fcfs_convoy_effect/","title":"FCFS &amp; Convoy Effect","text":""},{"location":"operating_system/process_management/process_scheduling/fcfs_convoy_effect/#fcfs-first-come-first-serve","title":"FCFS (First Come First Serve) \ud83c\udfc1","text":"<ul> <li>FCFS is simplest of CPU Scheduling Algorithm</li> <li>Executes process that comes first.</li> <li>It is non-preemptive algorithm.</li> </ul> <p>Definition</p> <p>Process that comes in ready queue first gets to be executed by the CPU first, then second one, then third one, and so on. The arrival time of processes is deciding factor here. Ready queue acts like FIFO (First In First Out) queue.</p>"},{"location":"operating_system/process_management/process_scheduling/fcfs_convoy_effect/#convoy-effect","title":"Convoy Effect \ud83d\ude34","text":"<p>Convoy Effect</p> <ul> <li>Convoy effect is a situation where short processes are held up behind a long process.</li> <li>Shorter processes are made to wait for longer processes to complete.</li> <li>This is a problem in FCFS.</li> <li>The <code>average waiting time of different processes is very high</code>.</li> <li>Many process which require CPU for short time, are blocked by few processes which require CPU for long time.</li> </ul>"},{"location":"operating_system/process_management/process_scheduling/introduction/","title":"Introduction to Process Scheduling","text":""},{"location":"operating_system/process_management/process_scheduling/introduction/#process-scheduling","title":"Process Scheduling \ud83d\udd25","text":"<ul> <li>Basis of Multi-programming OS.</li> <li>By switching the CPU among processes, the OS can make the computer more productive.</li> <li>Many processes are kept in memory at a time, when a process must wait(I/O operations) or time quantum expires, the OS takes the CPU away from that process &amp; gives the CPU to another process &amp; this pattern continues.</li> </ul>"},{"location":"operating_system/process_management/process_scheduling/introduction/#terminologies","title":"Terminologies \ud83d\udcda","text":"<p>CPU Scheduler</p> <ul> <li>Whenever the CPU become ideal, OS must select one process from the ready queue to be executed.</li> <li>Done by STS (short-term scheduler).</li> </ul> <p>Non-Preemptive scheduling <code>(not emptied pre (before) - \u274c time quantum)</code></p> <ul> <li>Once CPU has been allocated to a process, the process keeps the CPU until it releases CPU either by terminating or by switching to wait-state (process is doing I/O).</li> <li><code>Starvation</code>, as a process with long burst time may starve less burst time process.</li> <li>Low CPU utilization.</li> </ul> <p>Preemptive scheduling <code>(emptied pre (before) - \u2705 time quantum)</code></p> <ul> <li>CPU is taken away from a process after time quantum expires along with terminating or switching to wait-state.</li> <li><code>Less Starvation</code></li> <li>High CPU utilization</li> </ul> <p>Terminologies associated with CPU scheduling</p> <ul> <li>Throughput: No. of processes completed per unit time.</li> <li>Arrival time (AT): Time when process is arrived at the ready queue.</li> <li>Burst time (BT): The time required by the process for its execution.</li> <li>Turn-around time (TAT): Time taken from first time process enters ready state till it terminates. (CT - AT)</li> <li>Wait time (WT): Time process spends waiting for CPU. (WT = TAT \u2013 BT)</li> <li>Response time: Time duration between process getting into ready queue and process getting CPU for the first time.</li> <li>Completion Time (CT): Time taken till process gets terminated.</li> </ul>"},{"location":"operating_system/process_management/process_scheduling/introduction/#goals-of-cpu-scheduling","title":"Goals of CPU scheduling \u26bd\ufe0f","text":"<ul> <li>Maximum CPU utilization</li> <li>Minimum Turnaround time (TAT).</li> <li>Min. Wait-time</li> <li>Min. response time.</li> <li>Max. throughput of system.</li> </ul>"},{"location":"operating_system/types_of_os/","title":"Types of operating systems","text":""},{"location":"operating_system/types_of_os/#contents","title":"Contents","text":""},{"location":"operating_system/types_of_os/introduction/","title":"Types of Operating Systems","text":"<p>An Operating System performs all the basic tasks like managing files, processes, and memory. Thus, the operating system acts as the manager of all the resources, i.e. resource manager. Thus, the operating system becomes an interface between the user and the machine. It is one of the most required software that is present in the device.</p> <p>Operating System is a type of software that works as an interface between the system program and the hardware.</p>"},{"location":"operating_system/types_of_os/introduction/#types-of-operating-systems_1","title":"Types of Operating Systems","text":"<p>There are several types of Operating Systems which are mentioned below.</p>"},{"location":"operating_system/types_of_os/introduction/#single-process-operating-system","title":"Single Process Operating System","text":""},{"location":"operating_system/types_of_os/introduction/#batch-operating-system","title":"Batch Operating System","text":""},{"location":"operating_system/types_of_os/introduction/#multi-programming-system","title":"Multi-Programming System","text":""},{"location":"operating_system/types_of_os/introduction/#multi-tasking-operating-system","title":"Multi-Tasking Operating System","text":""},{"location":"operating_system/types_of_os/introduction/#multi-processing-system","title":"Multi-Processing System","text":""},{"location":"operating_system/types_of_os/introduction/#distributed-operating-system","title":"Distributed Operating System","text":""},{"location":"operating_system/types_of_os/introduction/#real-time-operating-system","title":"Real-Time Operating System","text":""},{"location":"operating_system/types_of_os/multi_tasking_vs_multi_threading/","title":"Multi-Tasking vs Multi-Threading","text":""},{"location":"operating_system/types_of_os/multi_tasking_vs_multi_threading/#concept","title":"Concept \ud83d\udd75\ud83c\udffb\u200d\u2642\ufe0f","text":"<ul> <li> <p>Program :- A Program is an executable file which contains a certain set of instructions written to complete the specific job or operation on your computer.</p> <ul> <li>It\u2019s a compiled code. Ready to be executed.</li> <li>Stored in Disk</li> </ul> </li> <li> <p>Process :- <code>Program under execution.</code> -  Resides in Computer\u2019s primary memory (RAM).</p> </li> </ul> <p>Threads \ud83e\udea1\ud83e\uddf6</p> <ul> <li>An independent path of execution in a process.</li> <li>lightweight process. It is a smallest unit of processing.</li> <li>A thread is a single sequence stream within in a process.</li> <li>Used to achieve parallelism by dividing a process's tasks which are independent path of execution.</li> <li>Threads exist within a process \u2014 every process has at least one. Threads share the process\u2019s resources, including memory and open files.</li> <li>E.g., Multiple tabs in a browser, text editor (When you are typing in an editor, spell-checking, formatting of text and saving the text are done concurrently by multiple threads.)</li> </ul> Multi-Tasking Multi-Threading The execution of more than one task simultaneously A process is divided into several different sub-tasks called as threads, which has its own path of execution. This concept is called as multithreading. Concept of more than 1 processes being context switched. Concept of more than 1 thread. Threads are context switched. Isolation and memory protection exists. OS must allocate separate memory and resources to each program that CPU is executing. No isolation and memory protection, resources are shared among threads of that process. OS allocates memory to a process; multiple threads of that process share the same memory and resources allocated to the process. Analogy explanation of <code>multitasking</code> &amp; <code>multithreading</code> <p>Let's say there's one computer and a maintainer, and there are 5 people in a line waiting for their chance to use PC and do their work. Maintainer maintains a rule that no individual is allowed to work continuously for consecutive 5 minutes. If his/her work completes with in 5 minutes, they leave and the next one will get the PC, else, after 5 minutes, they will go back to the end of the line and again wait for their turn.</p> <p>This is multi-tasking, (time-sharing).</p> <p>Now, suppose a individual person needs to send some mail, research some topic, and download some pics. Either he can do one task after another, or he can perform a task for some time, let's say 1 minute and then move to another task. So, he is basically switching tasks in his own time frame.  This is multi-threading. Each individual task will be called an independent thread of execution.</p> <p>This is multi-threading.</p>"},{"location":"operating_system/types_of_os/multi_tasking_vs_multi_threading/#thread-scheduling","title":"Thread Scheduling","text":"<ul> <li>Threads are scheduled for execution based on their priority.</li> <li>Even though threads are executing within the runtime, all threads are assigned processor time slices by the operating system.</li> </ul>"},{"location":"operating_system/types_of_os/multi_tasking_vs_multi_threading/#thread-context-switching-vs-process-context-switching","title":"Thread Context Switching Vs Process Context Switching","text":"Thread Context Switching Process Context Switching OS saves current state of thread &amp; switches to another thread of same process. OS saves current state of process &amp; switches to another process by restoring its state. Doesn\u2019t includes switching of memory address space. (But Program counter, registers &amp; stack are included.) Includes switching of memory address space. Fast switching. Slow switching. CPU\u2019s cache state is preserved. CPU\u2019s cache state is flushed. If threads are so good concept, why don't we make 100s or 1000s of threads? <ul> <li>You can create as many threads as you want, but you will only get as much parallelism as the number of cores in your CPU.</li> <li>Threads are not free. <code>Each thread consumes memory for its stack and other data structures</code>. </li> <li>Threads also require time to create and destroy. </li> <li><code>If you have too many threads, the overhead of managing them can exceed the benefit of parallelism</code>.</li> </ul>"},{"location":"operating_system/types_of_os/os_types/batch_os/","title":"Batch Operating System","text":""},{"location":"operating_system/types_of_os/os_types/batch_os/#batch-operating-system_1","title":"Batch Operating System","text":"<p>In the 1970s, Batch processing was very popular.In batch processing, the operating system (OS) groups or batches together jobs of a similar type or nature for execution. This method is common in environments where a large number of jobs need to be processed, such as in early mainframe computers or modern-day high-performance computing.</p> <p>The main idea behind batch processing is to collect jobs with similar requirements (like CPU-bound jobs, I/O-bound jobs, or those that require similar types of resources) and execute them together. This grouping allows the OS to manage resources more efficiently, reduce the idle time of the CPU, and ensure that all jobs get the necessary system resources.</p> <p></p>"},{"location":"operating_system/types_of_os/os_types/batch_os/#key-features-of-os","title":"Key features of OS","text":"<ul> <li> <p>Job grouping: Similar types of jobs are batched together, typically based on their nature or resource requirements.</p> </li> <li> <p>Automatic job execution: Once submitted, the jobs are executed automatically by the OS without manual intervention.</p> </li> <li> <p>Efficiency: By grouping similar tasks, the OS can optimize resource usage, such as CPU and I/O devices, improving throughput.</p> </li> <li> <p>Queueing system: Jobs are queued up in the batch, and the OS executes them sequentially or in parallel (in modern systems).</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/batch_os/#advantages-of-batch-os","title":"Advantages of Batch OS","text":"<ul> <li>Multiple users can share the batch systems.</li> <li>The idle time for the batch system is very less.</li> <li>It is easy to manage large work repeatedly in batch systems.</li> </ul>"},{"location":"operating_system/types_of_os/os_types/batch_os/#disadvantages-of-batch-os","title":"Disadvantages of Batch OS","text":"<ul> <li>Batch systems are hard to debug.</li> <li>It is sometimes costly.</li> <li>The other jobs will have to wait for an unknown time if any job fails.</li> <li>There are five jobs J1, J2, J3, J4, and J5, present in the batch. If the execution time of J1 is very high, then the other four jobs will never be executed, or they will have to wait for a very long time. Hence the other processes get starved.</li> </ul> <p>In traditional batch processing systems, the process of batching jobs was typically done by a system administrator or a job scheduler. Here's how it usually worked:</p> <ol> <li>System Administrator or Operator (Manual Batching):</li> </ol> <p>In early computing systems, operators would manually collect jobs submitted by users (such as punched cards or submitted scripts). These jobs were then grouped or \"batched\" together based on their resource requirements or processing characteristics (such as CPU-bound or I/O-bound). The administrator would then feed these batches into the system for processing.</p> <ol> <li>Job Scheduler (Automated Batching):</li> </ol> <p>In more advanced systems, the operating system's job scheduler automatically handled the batching process. Users would submit their jobs, and the job scheduler would analyze the requirements of each job (such as memory, CPU, and I/O needs) and group similar jobs together into batches. These batches would be executed sequentially or in parallel, depending on system capabilities and job priority.</p> <p>Modern operating systems, especially in environments like high-performance computing (HPC) or distributed systems, use batch job scheduling systems like:</p> <ul> <li>SLURM (Simple Linux Utility for Resource Management)</li> <li>PBS (Portable Batch System)</li> <li>IBM's LoadLeveler</li> </ul>"},{"location":"operating_system/types_of_os/os_types/distributed/","title":"Distributed Operating System","text":""},{"location":"operating_system/types_of_os/os_types/distributed/#distributed-operating-system_1","title":"Distributed Operating System","text":"<p>A Distributed Operating System (DOS) is a software system that manages a collection of independent, networked computers and presents them as a single unified system to the user. In this setup, the distributed OS controls and coordinates multiple machines (nodes) working together, allowing tasks to be executed across multiple computers transparently, as if they were on one machine.</p> <ul> <li>Loosely connected autonomous, interconnected nodes</li> <li><code>&gt;= 1 CPU, &gt;= 1 memory, &gt;= 1 GPU, etc.</code></li> <li>Collection of independent, networked, communicating, and physically separate computational nodes.</li> </ul> <p></p>"},{"location":"operating_system/types_of_os/os_types/distributed/#key-features-of-a-distributed-os","title":"Key Features of a Distributed OS","text":"<ol> <li> <p>Resource Sharing :- Resources like CPU, memory, storage, and peripherals are shared across multiple machines. Distributed OS allows for efficient load balancing by distributing tasks among available nodes to ensure optimal resource utilization.</p> </li> <li> <p>Concurrent Processing :- A distributed OS enables parallel processing by dividing tasks into subtasks and assigning them to different nodes. This leads to faster processing and greater computational power by using multiple machines in parallel.</p> </li> <li> <p>Scalability :- Distributed OSs are highly scalable, meaning that as more nodes are added to the system, overall performance improves. This allows organizations to increase their computing capacity by adding more machines without major changes to the software architecture.</p> </li> <li> <p>Fault Tolerance :- If one node in the distributed system fails, the OS can reroute tasks to other nodes, continuing execution without disrupting the entire system. Data replication across nodes also ensures redundancy, increasing the system\u2019s overall reliability.</p> </li> <li> <p>Networked Architecture :- The underlying system comprises multiple networked nodes (computers), which communicate via a high-speed network. Each node may run its own OS, but the distributed OS orchestrates their cooperation as a unified system.</p> </li> <li> <p>Security :- Distributed OSs need advanced security mechanisms for authentication, authorization, encryption, and ensuring that users and processes on one node cannot interfere with others across the network.</p> </li> </ol>"},{"location":"operating_system/types_of_os/os_types/distributed/#application-of-distributed-o","title":"Application of Distributed O","text":"<ul> <li> <p>Cloud Computing :- Distributed OSs are used in cloud environments to manage multiple virtual or physical machines distributed across data centers. This is critical for Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) models.</p> </li> <li> <p>Supercomputing and Grid Computing :- Distributed OSs manage the resources of supercomputing clusters where multiple machines work together on highly complex calculations, like weather simulations, scientific research, or cryptography.</p> </li> <li> <p>Peer-to-Peer Networks :- In P2P systems, distributed OS principles can be used to manage decentralized systems where tasks and resources are shared among peers without a central server.</p> </li> <li> <p>Distributed Databases :- Distributed OSs are used to manage databases that span multiple locations, ensuring data consistency and availability across a network of machines.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/multi_processing/","title":"Multi-Processing Operating System","text":""},{"location":"operating_system/types_of_os/os_types/multi_processing/#multi-processing-operating-system_1","title":"Multi-Processing Operating System","text":"<p>A Multi-processing Operating System is designed to support systems with multiple processors or CPU cores that can execute multiple processes simultaneously. Unlike multitasking, which switches between tasks on a single processor, multi-processing uses multiple CPUs to execute different tasks in parallel, providing true concurrent execution.</p> <ul> <li>More than 1 CPU in a single computer</li> <li>Increases reliability, if 1 CPU fails, the other is still running. Better throughput</li> <li>Lesser process starvation (if 1 process is running on 1 CPU, another process can run on another CPU)</li> </ul> <p></p>"},{"location":"operating_system/types_of_os/os_types/multi_processing/#key-features-of-a-multi-processing-os","title":"Key Features of a Multi-processing OS","text":"<ol> <li> <p>Multiple CPUs/Processors :- The system contains more than one CPU, allowing it to process multiple tasks at the same time. Each CPU can work on a different process or task independently.</p> </li> <li> <p>Parallel Execution :- In a multi-processing OS, tasks can be processed simultaneously by different CPUs. This results in true parallelism, where multiple processes are actually running at the same time on different processors.</p> </li> <li> <p>Increased Throughput :- Because multiple CPUs can process tasks concurrently, the system can handle more jobs in a shorter amount of time, leading to increased overall throughput and performance.</p> </li> <li> <p>Concurrency :- Like multi-tasking, multi-processing also supports concurrency, but in a more efficient manner because multiple processes can run in parallel across different CPUs rather than switching between them on a single CPU.</p> </li> <li> <p>Process Scheduling :- The OS uses advanced scheduling algorithms to distribute tasks across multiple CPUs, ensuring that each processor is utilized efficiently. The load balancing ensures that no CPU is overloaded while others remain idle.</p> </li> <li> <p>Reliability and Fault Tolerance :- In some multi-processing systems, if one CPU fails, others can continue to work, making the system more reliable. The failure of a single CPU does not necessarily bring down the entire system.</p> </li> </ol>"},{"location":"operating_system/types_of_os/os_types/multi_processing/#advantages-of-multi-processing-os","title":"Advantages of Multi-processing OS","text":"<ul> <li> <p>Increased Performance :- By distributing tasks across multiple processors, the system can handle more tasks simultaneously, reducing the time needed to complete complex computations or run multiple applications.</p> </li> <li> <p>Efficient Resource Utilization :- Multi-processing ensures that all available CPUs are utilized, which is especially beneficial for computationally intensive tasks like scientific simulations, large-scale data processing, or running multiple services on a server.</p> </li> <li> <p>Enhanced System Reliability :- Fault tolerance is improved in some multi-processing systems, as the failure of one processor can often be handled without affecting the entire system.</p> </li> <li> <p>True Parallelism :- Unlike multi-tasking, where tasks are rapidly switched in and out of the CPU, multi-processing allows multiple processes to actually run at the same time on different processors.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/multi_processing/#types-of-multi-processing-os","title":"Types of Multi-processing OS","text":""},{"location":"operating_system/types_of_os/os_types/multi_processing/#1-symmetric-multi-processing-smp","title":"1. Symmetric Multi-processing (SMP)","text":"<p>In SMP, all processors share the same memory space and have equal access to I/O devices. The OS assigns tasks to whichever processor is available, and each CPU operates independently but shares the workload evenly. Most modern operating systems, like Windows and Linux, use SMP.</p>"},{"location":"operating_system/types_of_os/os_types/multi_processing/#2-asymmetric-multi-processing-amp","title":"2. Asymmetric Multi-processing (AMP)","text":"<p>In AMP, one processor (the \"master\") controls the system and assigns tasks to other processors (the \"slaves\"). The slave processors typically handle specific tasks and do not communicate with each other directly.</p>"},{"location":"operating_system/types_of_os/os_types/multi_processing/#application-of-multi-processing-os","title":"Application of Multi-processing OS","text":"<ul> <li> <p>Servers: Multi-processing OSs are commonly used in servers, where multiple processors handle many user requests, ensuring high availability and fast response times. Web servers, database servers, and cloud infrastructure are typical examples.</p> </li> <li> <p>High-Performance Computing (HPC): Supercomputers and HPC clusters rely on multi-processing OSs to perform parallel processing tasks, such as scientific simulations, weather forecasting, and large-scale data analysis.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/multi_processing/#multi-processing-vs-multi-tasking","title":"Multi-processing vs. Multi-tasking","text":""},{"location":"operating_system/types_of_os/os_types/multi_programming/","title":"Multi-Programming operating system","text":""},{"location":"operating_system/types_of_os/os_types/multi_programming/#multi-programming-operating-system_1","title":"Multi-Programming operating system","text":"<p>Multi-programming OS maintains a ready queue and increases CPU utilization by keeping multiple jobs(code and data) in the memory so that the CPU always has one to execute in case some job gets busy with I/O.This is basically used for better utilization of resources.</p> <ul> <li>Single CPU</li> <li>Context switching for processes.</li> <li>Switching happens when current process goes to wait state or I/O.</li> <li>When context switching happens, the running program writes/saves details in PCB (process control block).</li> <li>CPU idle time reduced.</li> </ul> <p></p>"},{"location":"operating_system/types_of_os/os_types/multi_programming/#benefits-of-multi-programming-os","title":"Benefits of Multi-Programming OS","text":"<ul> <li>Increased CPU utilization: The CPU does not remain idle when a process is waiting for I/O, as it can execute another process.</li> <li>Throughput: More jobs can be completed in a given period because the system is always executing some process.</li> <li>Better resource utilization: Efficient use of memory, I/O devices, and other resources.</li> </ul>"},{"location":"operating_system/types_of_os/os_types/multi_tasking/","title":"Multi-Tasking Operating System","text":""},{"location":"operating_system/types_of_os/os_types/multi_tasking/#multi-tasking-operating-system_1","title":"Multi-Tasking Operating System","text":"<p>A Multi-tasking Operating System is an OS that allows multiple tasks (or processes) to run simultaneously by sharing CPU time among them. It achieves this by rapidly switching between tasks, giving the illusion that multiple tasks are being executed at the same time, even though, in reality, the CPU can only execute one task at any given moment (in a single-core system).</p> <ul> <li>Almost similar to Multi-programming OS + time-sharing</li> <li>Each process is executed for a maximum fixed interval of time, then another program is sent to the CPU.</li> <li>It is also known as time-sharing systems.</li> </ul> <p></p>"},{"location":"operating_system/types_of_os/os_types/multi_tasking/#key-features-of-a-multitasking-os","title":"Key Features of a Multitasking OS","text":"<ol> <li> <p>Multiple Tasks at the Same Time :- Multi-tasking allows the CPU to handle several tasks at once by switching between them frequently.</p> </li> <li> <p>Time-sharing :- Each task is assigned a small unit of time (called a time slice or quantum). The OS rapidly switches between tasks during these time slices, ensuring that each task gets CPU time. This switching is so fast that users experience it as if all tasks are running simultaneously.</p> </li> <li> <p>Preemptive vs. Cooperative Multi-tasking :-</p> <ul> <li>Preemptive Multi-tasking :- The OS can forcibly take control of the CPU from a running process after its time slice is over and give it to another process. Modern operating systems like Linux, Windows, and macOS use preemptive multi-tasking.</li> <li>Cooperative Multi-tasking :- In this older method, the OS relies on each process to voluntarily give up control of the CPU. This method was used in early versions of operating systems like Windows 3.x.</li> </ul> </li> <li> <p>Context Switching :- When the OS switches between tasks, it saves the state of the current task (e.g., registers, program counter) and loads the state of the next task to resume its execution. This is called context switching. This happens so fast that users do not notice the switch.</p> </li> <li> <p>Task Prioritization :- The OS assigns priority to tasks. High-priority tasks get more CPU time or are executed before low-priority tasks. This ensures that critical tasks are not delayed by less important ones.</p> </li> <li> <p>Concurrency :- Multi-tasking introduces concurrency by overlapping the execution of multiple tasks. However, it doesn't mean tasks are truly running in parallel (unless on a multi-core processor). Instead, tasks share CPU resources in quick succession.</p> </li> </ol>"},{"location":"operating_system/types_of_os/os_types/multi_tasking/#types-of-multi-tasking-os","title":"Types of Multi-tasking OS","text":""},{"location":"operating_system/types_of_os/os_types/multi_tasking/#1-single-core-multi-tasking","title":"1. Single-core Multi-tasking","text":"<p>In a single-core processor, multi-tasking is achieved by time-sharing where the CPU switches between different processes very quickly.</p>"},{"location":"operating_system/types_of_os/os_types/multi_tasking/#2-multi-core-multi-tasking","title":"2. Multi-core Multi-tasking","text":"<p>In a system with multiple cores, multi-tasking can involve parallel execution, where different processes are run on separate CPU cores, allowing true simultaneous execution of multiple tasks.</p>"},{"location":"operating_system/types_of_os/os_types/multi_tasking/#multi-tasking-vs-multi-programming","title":"Multi-tasking vs. Multi-programming","text":"<ul> <li> <p>Multi-tasking: Focuses on the illusion of simultaneous task execution by switching between tasks very quickly (time-sharing). It often operates in systems where users interact with applications in real-time.</p> </li> <li> <p>Multi-programming: Focuses on maximizing CPU utilization by keeping multiple programs in memory and switching between them when one is waiting (like for I/O). It was mainly used in older batch processing systems.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/real_time/","title":"Real-Time Operating System","text":""},{"location":"operating_system/types_of_os/os_types/real_time/#real-time-operating-system_1","title":"Real-Time Operating System","text":"<p>A Real-Time Operating System (RTOS) is a specialized operating system designed to process data and execute tasks within a strict and deterministic time frame, often in systems where timing is crucial. These systems are used in applications where a delay or failure to meet timing constraints can lead to serious consequences, such as in industrial control systems, automotive electronics, medical devices ect...</p> <p></p>"},{"location":"operating_system/types_of_os/os_types/real_time/#key-concepts-in-real-time-os","title":"Key Concepts in Real-Time OS","text":"<ul> <li> <p>Jitter :- Jitter refers to the variation in task execution time. A real-time system should have minimal jitter, meaning tasks should consistently complete within the same time window.</p> </li> <li> <p>Latency :- This refers to the time it takes the system to respond to an external event (such as an interrupt). An RTOS aims to minimize latency to ensure fast and timely responses.</p> </li> <li> <p>Task Priority :- Tasks in an RTOS are often assigned priorities. Higher-priority tasks are given preference in execution over lower-priority ones. Preemptive multitasking ensures that critical tasks can interrupt less important ones.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/real_time/#types-of-real-time-os","title":"Types of Real-Time OS","text":""},{"location":"operating_system/types_of_os/os_types/real_time/#1-hard-real-time-systems","title":"1. Hard Real-Time Systems","text":"<ul> <li> <p>In hard real-time systems, missing a deadline is unacceptable and can result in catastrophic consequences. These systems are used in mission-critical environments such as:</p> <ul> <li>Aircraft control systems (e.g., autopilot)</li> <li>Medical devices (e.g., pacemakers)</li> <li>Industrial automation (e.g., robot controllers)</li> </ul> </li> <li> <p>A task\u2019s deadline must be met every single time, and system failure is not tolerated.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/real_time/#2-soft-real-time-systems","title":"2. Soft Real-Time Systems","text":"<ul> <li> <p>In soft real-time systems, deadlines are important but not as strict. Occasionally missing a deadline might result in degraded performance, but the system can still continue to operate.</p> <ul> <li>Examples include multimedia streaming, online gaming, and telecommunications systems.</li> </ul> </li> <li> <p>While performance and responsiveness are crucial, missing a deadline occasionally is acceptable, though undesirable.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/real_time/#applications-of-real-time-o","title":"Applications of Real-Time O","text":"<ul> <li> <p>Aerospace and Defense :- In applications like aircraft control systems, missile guidance, or military communication systems, hard real-time constraints are crucial for system success.</p> </li> <li> <p>Medical Devices :- Medical equipment such as pacemakers, infusion pumps, and MRI machines rely on RTOSs to ensure timely responses to critical events.</p> </li> <li> <p>Telecommunication Systems :- RTOSs are used in telecommunication systems to manage network traffic, ensure low-latency communications, and prioritize critical tasks in real time.</p> </li> </ul>"},{"location":"operating_system/types_of_os/os_types/single_process/","title":"Single Process Operating System","text":""},{"location":"operating_system/types_of_os/os_types/single_process/#single-process-operating-system_1","title":"Single Process Operating System","text":"<p>A Single Process Operating System is a type of operating system that can run only one program (or process) at a time. It focuses entirely on executing that single task before moving on to the next one. This means the CPU will handle one task until it is completed, and no other programs can run simultaneously.</p> <ul> <li>Only one task is executed at any given time.</li> <li>The system waits until the current task finishes before starting another.</li> <li>Early computers, like those in the 1950s and 1960s, used single-process OS designs.</li> <li>It is simple but not efficient, as it can't perform multitasking (running multiple tasks at once).</li> </ul> <p>Example :- Early versions of <code>MS-DOS</code> were single-process operating systems.</p>"},{"location":"system_design/","title":"Welcome to System Design","text":"<p>System Design is defined as a process of creating an architecture for different components, interfaces, and modules of the system and providing corresponding data helpful in implementing such elements in systems.</p> <p></p>"},{"location":"system_design/architecture/","title":"Architecture of a System","text":""},{"location":"system_design/architecture/#contents","title":"Contents","text":""},{"location":"system_design/architecture/introduction/","title":"Introduction to System Architecture","text":""},{"location":"system_design/architecture/introduction/#architecture-of-a-system","title":"Architecture of a System?","text":"<p>Architecture is a critical aspect of designing a system, as it sets the foundation for how the system will function and be built. It is the process of making high-level decisions about the organization of a system, including the selection of hardware and software components, the design of interfaces, and the overall system structure.</p>"},{"location":"system_design/architecture/introduction/#components-consider-when-designing-the-architecture-of-a-system","title":"Components consider when designing the architecture of a system","text":"<p>In order to design a good system architecture, it is important to consider all these components and to make decisions based on the specific requirements and constraints of the system. It is also important to consider the long-term maintainability of the system and to make sure that the architecture is flexible and scalable enough to accommodate future changes and growth.</p> <p></p> <ul> <li> <p>Hardware Platform: Hardware platform includes the physical components of the system such as servers, storage devices, and network infrastructure. The hardware platform must be chosen based on the specific requirements of the system, such as the amount of storage and processing power needed, as well as any specific technical constraints.</p> </li> <li> <p>Software Platform: Software platform includes the operating system, application servers, and other software components that run on the hardware. The software platform must be chosen based on the programming languages and frameworks used to build the system, as well as any specific technical constraints.</p> </li> <li> <p>System interfaces: System interfaces include the APIs and user interfaces used to interact with the system. Interfaces must be designed to be easy to use and understand and must be able to handle the expected load of users and requests.</p> </li> <li> <p>System Structure: System structure includes the overall organization of the system, including the relationship between different components and how they interact with each other. The system structure must be designed to be modular and scalable so that new features and components can be added easily.</p> </li> <li> <p>Security: Security is an important aspect of system architecture. It must be designed to protect the system and its users from malicious attacks and unauthorized access.</p> </li> </ul>"},{"location":"system_design/architecture/introduction/#types-of-architecture-in-system-design","title":"Types of Architecture in system design","text":"<ol> <li>Monolithic architecture</li> <li>Microservices architecture</li> <li>Event-driven architecture</li> <li>Serverless architecture</li> </ol>"},{"location":"system_design/architecture/microservices/","title":"Microservices Architecture","text":""},{"location":"system_design/architecture/microservices/#what-is-a-microservices-architecture","title":"What is a Microservices Architecture?","text":"<p>In a microservices architecture, an application is built as a collection of small, independent services, each representing a specific business capability. These services are loosely coupled and communicate with each other over a network, often using lightweight protocols like HTTP or messaging queues.</p> <ul> <li> <p>Each service is responsible for a single functionality or feature of the application and can be developed, deployed, and scaled independently.</p> </li> <li> <p>The Microservice architecture has a significant impact on the relationship between the application and the database.</p> </li> <li> <p>Instead of sharing a single database with other microservices, each microservice has its own database. It often results in duplication of some data, but having a database per microservice is essential if you want to benefit from this architecture, as it ensures loose coupling.</p> </li> </ul> <p></p>"},{"location":"system_design/architecture/microservices/#advantages-of-using-a-microservices-architecture","title":"Advantages of using a Microservices Architecture","text":"<ul> <li> <p>Scalability: Microservices allow for individual components of an application to be scaled independently based on demand. This means that you can scale only the parts of your application that need to handle more traffic, rather than scaling the entire application.</p> </li> <li> <p>Flexibility: Microservices enable teams to use different technologies and programming languages for different services based on their specific requirements. This flexibility allows teams to choose the best tool for the job, rather than being limited to a single technology stack.</p> </li> <li> <p>Resilience: Since microservices are decoupled from each other, a failure in one service does not necessarily impact the entire application. This improves the overall resilience of the application and reduces the risk of downtime.</p> </li> <li> <p>Agility: Microservices enable teams to independently develop, test, deploy, and scale services, allowing for faster development cycles and quicker time-to-market for new features.</p> </li> <li> <p>Easier Maintenance: With microservices, it\u2019s easier to understand, update, and maintain the codebase since each service is smaller and focused on a specific functionality. This can lead to faster development and debugging times.</p> </li> <li> <p>Technology Diversity: Different services in a microservices architecture can use different technologies, frameworks, and databases based on their specific requirements. This allows for greater flexibility and innovation in technology choices.</p> </li> </ul>"},{"location":"system_design/architecture/microservices/#disadvantages-of-using-a-microservices-architecture","title":"Disadvantages of using a Microservices Architecture","text":"<ul> <li> <p>Complexity: Managing a large number of microservices can be complex. It requires careful coordination between teams and can result in a more complex deployment and monitoring environment.</p> </li> <li> <p>Increased Overhead: With microservices, there is overhead associated with managing the communication between services, such as network latency and serialization/deserialization of data. This can impact the performance of the application.</p> </li> <li> <p>Deployment Complexity: Deploying and managing a large number of microservices can be complex. It requires a robust deployment pipeline and automated tools to ensure that updates are deployed smoothly and without downtime.</p> </li> <li> <p>Monitoring and Debugging: Monitoring and debugging microservices can be more challenging compared to monolithic applications. Since each service is independent, tracing issues across multiple services can be complex.</p> </li> <li> <p>Cost: While microservices offer scalability and flexibility, they can also increase costs, especially in terms of infrastructure and operational overhead. Managing a large number of services can require more resources and investment in tools and infrastructure.</p> </li> <li> <p>Testing: Testing microservices can be more complex compared to monolithic applications. It requires a comprehensive testing strategy that covers integration testing between services, as well as unit testing within each service.</p> </li> </ul>"},{"location":"system_design/architecture/monolithic/","title":"Monolithic Architecture","text":""},{"location":"system_design/architecture/monolithic/#what-is-monolithic-architecture","title":"What is Monolithic Architecture?","text":"<p>Monolithic architecture, a traditional approach in system design, actually contains all components of an application into a single codebase.In this architecture, the entire application, including the user interface, business logic, and data access layers, is developed, deployed, and maintained as a single entity.</p> <p></p>"},{"location":"system_design/architecture/monolithic/#importanceadvantages-of-monolithic-systems","title":"Importance/Advantages of Monolithic Systems","text":"<ul> <li> <p>Simplicity: Monolithic architectures offer straightforward development and deployment processes. With all components bundled together, it\u2019s often easier for developers to understand the system as a whole and make changes.</p> </li> <li> <p>Cost-Effectiveness: For small to medium-sized projects or startups, monolithic architectures can be more cost-effective. They require less infrastructure overhead and simpler deployment setups compared to distributed systems.</p> </li> <li> <p>Performance: In some cases, monolithic systems can provide better performance due to reduced communication overhead between components, as everything is running within the same process.</p> </li> <li> <p>Security: With fewer inter-service communication points, monolithic systems may have a reduced attack surface, making them potentially more secure, especially if proper security measures are implemented.</p> </li> </ul>"},{"location":"system_design/architecture/monolithic/#characteristics-of-monolithic-architecture","title":"Characteristics of Monolithic Architecture","text":"<p>Monolithic architecture exhibits several defining characteristics:-</p> <ul> <li> <p>Single Codebase: All components of the application are developed and maintained within a single codebase, making it easier to manage and deploy.</p> </li> <li> <p>Tight Coupling: Components within the architecture are tightly integrated and interdependent, often sharing data and resources directly.</p> </li> <li> <p>Shared Memory: Monolithic applications typically share the same memory space, allowing components to communicate efficiently without the need for network overhead.</p> </li> <li> <p>Centralized Database: Data storage is centralized within the application, typically using a single database instance for all data storage needs.</p> </li> <li> <p>Layered Structure: Monolithic architectures often follow a layered structure, with distinct layers for presentation, business logic, and data access. While providing separation of concerns, this can lead to dependencies between layers.</p> </li> </ul>"},{"location":"system_design/architecture/monolithic/#challengesdisadvantages-in-deploying-monolithic-architecture","title":"Challenges/Disadvantages in deploying Monolithic Architecture","text":"<p>Deploying monolithic architecture poses several challenges, including:-</p> <ul> <li> <p>Long Deployment Cycles: Deploying a monolithic application typically involves deploying the entire codebase as a single unit. This can result in longer deployment times, as all components of the application need to be packaged, tested, and deployed together.</p> </li> <li> <p>Risk of Downtime: Deploying a monolithic application may require taking the entire system offline temporarily, especially if the deployment involves making significant changes or updates. This downtime can impact user experience and business operations.</p> </li> <li> <p>Limited Scalability: Scaling a monolithic application can be challenging, as scaling typically involves replicating the entire application stack. This can lead to inefficiencies and increased infrastructure costs, particularly during periods of high demand.</p> </li> <li> <p>Resource Consumption: Monolithic applications may consume more resources, such as memory and CPU, compared to more lightweight architectures like microservices. This can lead to higher infrastructure costs and reduced overall efficiency.</p> </li> </ul>"},{"location":"system_design/load_balancer/","title":"Load Balancer","text":""},{"location":"system_design/load_balancer/#contents","title":"Contents","text":""},{"location":"system_design/load_balancer/consistent_hashing/","title":"Consistent Hashing","text":""},{"location":"system_design/load_balancer/consistent_hashing/#introduction","title":"Introduction","text":"<p>We are living in a world where data is massively generated every day. In large corporations, it is practically impossible to store all the data on a single server. That is why we need horizontal scaling where every data part is stored on a separate server.</p>"},{"location":"system_design/load_balancer/consistent_hashing/#problem","title":"Problem","text":"<p>Imagine we have n data objects that need to be stored across k different servers. The configuration of servers can change over time:</p> <ul> <li>Any server can be shut down;</li> <li>A new server can be added to the system.</li> </ul> <p>Given these potential configuration changes, we have to design a system that can rapidly retrieve required data blocks and transfer data between servers in the case of configuration changes.</p>"},{"location":"system_design/load_balancer/consistent_hashing/#naive-implementation","title":"Naive implementation","text":"<p>The naive implementation includes the distribution of data across different servers based on a hash function. For instance, when we need to add a new data block to our system, we plug its key into the hash function that outputs the server number to which this block will belong to.</p> <p></p> <p><code>Data distribution based on a hash function. The data is stored on servers with respect to corresponding hash values.</code></p> <p>When we need to retrieve information from a given key, we calculate its hash value to find out on which server the information associated with this key is stored.</p> <p>This system works well until we make changes to it. For example, imagine that from the example above, the server S3 is shut down: we can no longer access its data and new data that will hash to its bucket will not be added.</p> <p></p> <p><code>Whenever any of the servers is shut down, its data is no longer accessible.</code></p> <p>The only possible solution is to redistribute all the data blocks onto the servers again. Since we now have k-1 servers, we should not forget that the remainder in the hash function has to be reduced by 1. The analogous scenario would occur if a new server was added to the system.</p> <p></p> <p><code>In the case of any system configuration changes, all the data needs to be redistributed again.</code></p> <p>Unfortunately, data redistribution is a resource-consuming operation. In the case of large data volumes and frequent changes in configuration, this storage system becomes very inefficient.</p>"},{"location":"system_design/load_balancer/consistent_hashing/#consistent-hashing_1","title":"Consistent hashing","text":"<p>Consistent hashing is a great alternative to the system above with much more resilience in case of any configuration changes.</p> <p>Consistent hashing consists of hashing not only data but servers as well. The data keys and servers are hashed to the same set of values [0, n]. To make it easier to understand and visualise, let us imagine that all of the hash values are located on a ring (or clock). Each server has its own hash range.</p> <p><code>A hash range of a server is defined as an interval of all hash values located on the hash ring before the server\u2019s hash value and after the hash value of another closest server located in the counter-clockwise direction.</code></p> <p>To determine to which server a certain key belongs, we need to go into the clockwise direction starting from the hash value of the key until we reach the hash value corresponding to one of the servers. That server will store the data for this key.</p> <p></p> <p><code>Hash ring example. The hash range for server S1 is depicted in blue.</code></p> <p>The hashed values for servers should be stored elsewhere in ascending order, so they can be rapidly accessed. Using binary search, this gives the ability to find a server storing a given key in O(log S) time (S is the number of servers).</p> <p></p> <p><code>Using consistent hashing, the server number associated with a given key can be found in O(log S) time, where S is the total number of servers.</code></p>"},{"location":"system_design/load_balancer/consistent_hashing/#shutting-down-a-server","title":"Shutting down a server","text":"<p>If any of the servers is shut down, then we simply need to delete the associated hash value of the server and transfer only the data from that server to the next server in the clockwise direction. That is a great advantage of consistent hashing in comparison to simple hashing since we no longer need to redistribute all the data as it was before.</p> <p></p> <p><code>Shutting down server S1 from the example above requires only transferring data previously stored on that server.</code></p> <p></p> <p><code>After shutting down S1, the server S2 has expanded its hash range.</code></p>"},{"location":"system_design/load_balancer/consistent_hashing/#adding-a-new-server","title":"Adding a new server","text":"<p>If there is a need to add a new server to the system, then we only need to transfer all of the data associated with hash values located between the new server\u2019s hash value and the hash value of the nearest server in the counter-clockwise direction.</p> <p></p> <p><code>Adding a new server S4 to the system. Only part of the data stored on S0 has to be transferred to S4.</code></p> <p></p> <p><code>After adding S4, it took a part of associated hash values which previously belonged to S0.</code></p>"},{"location":"system_design/load_balancer/consistent_hashing/#uneven-distributions","title":"Uneven distributions","text":"<p>While consistent hashing seems to be resilient to various configuration changes, there might come a moment in time when the data is distributed unevenly between servers.</p> <ul> <li>First of all, this might happen due to the chosen hash function. In reality, we cannot guarantee that it will uniformly generate keys for data. As a result, this can lead to a scenario when servers have very disproportional hash range lengths.</li> </ul> <p></p> <ul> <li>Even if data is evenly distributed at a given moment of, with various configuration changes, it can sooner change drastically becoming uneven again.</li> </ul> <p></p> <p>With more uneven distributions, the average response time becomes proportionally longer.</p> <p>One of the possible methods to mitigate this issue is to periodically redistribute all the data (possibly with another hash function) in the system when the distribution becomes skewed. While sometimes this might be a solution, it is still not optimal when having millions or billions of data objects.</p>"},{"location":"system_design/load_balancer/consistent_hashing/#virtual-nodes","title":"Virtual nodes","text":"<p>Virtual nodes are an extension of consisting hashing which makes the system more resilient to uneven data distributions. The idea consists of hashing each server several times (with different hash functions). The total hash range of every server is defined as the union of hash ranges associated with all of its keys.</p> <p></p> <p><code>Consistent hashing with virtual nodes. Every unique color on the hash ring corresponds to one server.</code></p> <ul> <li> <p>Shutting down a server implies the deletion of all virtual nodes associated with the server. All of the data from that server will be transferred to other multiple servers.</p> </li> <li> <p>When adding a new server, all hash values for its virtual nodes should be calculated through the hash functions used before for other servers.</p> </li> </ul> <p><code>In reality, the number of virtual nodes is usually much greater than in the example above.</code></p> <p><code>On one hand, with the increase in the number of virtual nodes, hash ranges become on average more aligned. On the other hand, it takes more time to perform standard operations related to changes in configuration. Furthermore, additional metadata about virtual nodes needs to be stored.</code></p> <p>In most situations, it is better to choose the number of virtual nodes, based on a given problem, the number of available servers and data quantity. When it is difficult to estimate a good number, it is recommended to tune this parameter to find the perfect trade-off.</p>"},{"location":"system_design/load_balancer/consistent_hashing/#applications","title":"Applications","text":"<p>Consistent hashing has a wide range of applications. Most of the time, it is used in distributed applications, especially in databases storing massive amounts of data on many servers. Some of the most popular examples are:</p> <ul> <li>Apache Cassandra \u2014 distributed NoSQL column database;</li> <li>Amazon Dynamo DB \u2014 distributed NoSQL key-value database;</li> <li>Discord \u2014 video and chat application.</li> </ul>"},{"location":"system_design/load_balancer/introduction/","title":"Introduction to Load Balancer","text":""},{"location":"system_design/load_balancer/introduction/#what-is-a-load-balancer","title":"What is a Load Balancer?","text":"<p>Load Balancer is defined as a networking device or software application that distributes and balances the incoming traffic among the servers to provide high availability, efficient utilization of servers, and high performance.</p> <ul> <li>Load balancers are highly used in cloud computing domains, data centers, and large-scale web applications where traffic flow needs to be managed.</li> <li>The primary goal of using a load balancer is, not to overburden with huge incoming traffic which may lead to server crashes or high latency.</li> </ul> <p></p>"},{"location":"system_design/load_balancer/introduction/#what-will-happen-if-there-is-no-load-balancer","title":"What will happen if there is NO Load Balancer?","text":"<p>Before understanding how a load balancer works, let\u2019s understand what problem will occur without the load balancer through an example.</p> <p></p> <p>There are two main problems with this model:</p> <ul> <li> <p>Single Point of Failure: If the server goes down or something happens to the server the whole application will be interrupted and it will become unavailable for the users for a certain period. It will create a bad experience for users which is unacceptable for service providers.</p> </li> <li> <p>Overloaded Servers: There will be a limitation on the number of requests that a web server can handle. If the business grows and the number of requests increases the server will be overloaded.</p> </li> </ul>"},{"location":"system_design/load_balancer/introduction/#key-characteristics-of-load-balancers","title":"Key characteristics of Load Balancers:","text":"<ol> <li> <p>Traffic Distribution: Load balancers evenly distribute incoming requests among multiple servers, preventing any single server from being overloaded.</p> </li> <li> <p>High Availability: By distributing traffic across multiple servers, load balancers enhance the availability and reliability of applications. If one server fails, the load balancer redirects traffic to healthy servers.</p> </li> <li> <p>Scalability: Load balancers facilitate horizontal scaling by easily accommodating new servers or resources to handle increasing traffic demands.</p> </li> <li> <p>Optimization: Load balancers optimize resource utilization, ensuring efficient use of server capacity and preventing bottlenecks.</p> </li> <li> <p>Health Monitoring: Load balancers often monitor the health of servers, directing traffic away from servers experiencing issues or downtime.</p> </li> </ol>"},{"location":"system_design/load_balancer/introduction/#how-load-balancer-works","title":"How Load Balancer Works?","text":"<p>Lets understand how Load Balancer works through the above discussed example:</p> <p>To solve the above issue and to distribute the number of requests we can add a load balancer in front of the web servers and allow our services to handle any number of requests by adding any number of web servers in the network.</p> <ul> <li>We can spread the request across multiple servers.</li> <li>For some reason, if one of the servers goes offline the service will be continued.</li> <li>Also, the latency on each request will go down because each server is not bottlenecked on RAM/Disk/CPU anymore.</li> </ul> <p></p> <p>Load balancers minimize server response time and maximize throughput. Load balancer ensures high availability and reliability by sending requests only to online servers Load balancers do continuous health checks to monitor the server\u2019s capability of handling the request. Depending on the number of requests or demand load balancers add or remove the number of servers.</p>"},{"location":"system_design/load_balancer/reverse_proxy/","title":"Reverse Proxy","text":""},{"location":"system_design/load_balancer/reverse_proxy/#what-is-reverse-proxy","title":"What is Reverse Proxy?","text":"<p>A reverse proxy is a server that sits between client devices and backend servers, acting as an intermediary for requests from clients. When a client sends a request for a resource, such as a web page or an application, the reverse proxy receives the request on behalf of the backend servers. It then forwards the request to the appropriate backend server based on predefined rules or configurations.</p> <p></p> <ul> <li> <p>One of the key functions of a reverse proxy is to enhance security by serving as a barrier between the internet and backend servers. It can filter out malicious traffic, such as hacking attempts or spam, before it reaches the servers, thus protecting them from direct exposure to potential threats.</p> </li> <li> <p>Additionally, a reverse proxy can improve the performance of web applications by caching static content, such as images, CSS files, and JavaScript.</p> </li> <li> <p>By storing copies of frequently accessed content, the reverse proxy can serve these resources quickly to clients without needing to request them from the backend servers every time.</p> </li> <li> <p>This reduces latency and server load, improving overall performance for users.</p> </li> </ul>"},{"location":"system_design/load_balancer/reverse_proxy/#what-are-the-differences-between-reverse-proxy-and-load-balancer","title":"What are the differences between Reverse Proxy and Load Balancer?","text":"<p>Below are the differences between a reverse proxy and a load balancer:</p> <p></p> <p></p>"},{"location":"system_design/load_balancer/reverse_proxy/#best-scenarios-for-reverse-proxy-and-load-balancer","title":"Best Scenarios for Reverse Proxy and Load Balancer","text":""},{"location":"system_design/scalability/","title":"Scalability","text":""},{"location":"system_design/scalability/#contents","title":"Contents","text":""},{"location":"system_design/scalability/horizontal/","title":"Horizontal Scaling","text":""},{"location":"system_design/scalability/horizontal/#what-is-horizontal-scaling","title":"What is Horizontal Scaling?","text":"<p>Horizontal scaling, also known as scaling out, refers to the process of increasing the capacity or performance of a system by adding more machines or servers to distribute the workload across a larger number of individual units.</p> <p>Example - MongoDB, YouTube, Yahoo, Facebook, Amazon</p> <p></p> <p></p>"},{"location":"system_design/scalability/horizontal/#advantages-of-horizontal-scaling","title":"Advantages of horizontal scaling","text":"<ul> <li> <p>Increased capacity: More nodes or instances can handle a larger number of incoming requests.</p> </li> <li> <p>Improved performance: Load can be balanced across multiple nodes or instances, reducing the likelihood of any one server becoming overwhelmed.</p> </li> <li> <p>Increased fault tolerance: If one node fails, incoming requests can be redirected to another node, reducing the risk of downtime.</p> </li> </ul>"},{"location":"system_design/scalability/horizontal/#disadvantages-of-horizontal-scaling","title":"Disadvantages of horizontal scaling","text":"<ul> <li> <p>Increased complexity: Managing multiple nodes or instances can be more complex than managing a single node.</p> </li> <li> <p>Increased cost: Adding more nodes or instances will typically increase the cost of the system.</p> </li> </ul>"},{"location":"system_design/scalability/introduction/","title":"Introduction to Scalability","text":""},{"location":"system_design/scalability/introduction/#what-is-scalabilty","title":"What is Scalabilty?","text":"<p>Scalability refers to the ability of a system to handle increasing amounts of workload or requests without sacrificing performance or incurring excessive costs.</p> <p></p>"},{"location":"system_design/scalability/introduction/#importance-of-scalability-in-system-design","title":"Importance of Scalability in System Design","text":"<p>Scalability is crucial in system design for several reasons:</p> <ul> <li> <p>Handle Growth: Scalability ensures that a system can handle growth in terms of user base, data volume, and traffic without experiencing a significant decrease in performance or reliability. This is essential for businesses that aim to expand their operations and reach a larger audience over time.</p> </li> <li> <p>Improve Performance: Scalability can improve the overall performance of a system by distributing the workload across multiple resources or servers. This can reduce response times, increase throughput, and enhance the user experience.</p> </li> <li> <p>Ensure Availability: Scalability can improve the availability of a system by ensuring that it can withstand failures or spikes in traffic without becoming unavailable. This is critical for mission-critical systems that need to be available 24/7.</p> </li> <li> <p>Optimize Costs: Scalability can help optimize costs by allowing resources to be scaled up or down based on demand. This can reduce the need for over-provisioning resources, leading to cost savings.</p> </li> </ul>"},{"location":"system_design/scalability/introduction/#types-of-scalability","title":"Types of scalability","text":"<p>There are two main types of scalability:</p> <ul> <li>Vertical scaling or Scale-up</li> <li>Horizontal scaling or Scale-out</li> </ul>"},{"location":"system_design/scalability/vertical/","title":"Vertical Scaling","text":""},{"location":"system_design/scalability/vertical/#what-is-vertical-scaling","title":"What is Vertical Scaling?","text":"<p>Vertical scaling, also known as scaling up, refers to the process of increasing the capacity or capabilities of an individual hardware or software component within a system. You can add more power to your machine by adding better processors, increasing RAM, or other power-increasing adjustments.</p> <p>Example - MySQL, Amazon RDS</p> <p></p> <p></p>"},{"location":"system_design/scalability/vertical/#advantages-of-vertical-scaling","title":"Advantages of vertical scaling","text":"<ul> <li> <p>Increased capacity: Upgrading the hardware of a server can improve its performance and increase its capacity to handle incoming requests.</p> </li> <li> <p>Easier management: Vertical scaling typically involves upgrading a single node, which can be less complex than managing multiple nodes.</p> </li> </ul>"},{"location":"system_design/scalability/vertical/#disadvantages-of-vertical-scaling","title":"Disadvantages of vertical scaling:","text":"<ul> <li> <p>Limited scalability: Vertical scaling is limited by the physical constraints of the hardware, whereas horizontal scaling can be easily expanded by adding more nodes.</p> </li> <li> <p>Increased cost: Upgrading the hardware of a server can be more expensive than adding more nodes. Single point of failure: All incoming requests are still directed to a single server, which increases the risk of downtime if the server fails.</p> </li> </ul>"}]}